{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.9"
    },
    "colab": {
      "name": "py_tensorflow_multiclass_fruits_360_images_take1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wm7TgCNRzYpJ"
      },
      "source": [
        "# Multi-Class Image Classification Deep Learning Model for Fruits-360 Images Using TensorFlow Take 1\n",
        "### David Lowe\n",
        "### July 1, 2021\n",
        "\n",
        "Template Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery. [https://machinelearningmastery.com/]\n",
        "\n",
        "SUMMARY: This project aims to construct a predictive model using a TensorFlow convolutional neural network (CNN) and document the end-to-end steps using a template. The Fruits-360 Images dataset is a multi-class classification situation where we attempt to predict one of several (for this dataset 131) possible outcomes.\n",
        "\n",
        "INTRODUCTION: This dataset contains 131 fruits and vegetables with 67692 training images and 22688 test images. All images have a resolution of 100 X 100 X 3 colors in the JPEG format. Each dataset includes 131 subdirectories, one for each type of fruit or vegetable.\n",
        "\n",
        "In this Take1 iteration, we will construct a CNN model based on the InceptionV3 architecture to predict the fruit or vegetable name for the image.\n",
        "\n",
        "ANALYSIS: In this Take1 iteration, the InceptionV3 model's performance achieved an accuracy score of 99.46% after five epochs using the validation dataset. The same model processed the test dataset with an accuracy score of 98.03%.\n",
        "\n",
        "CONCLUSION: In this iteration, the InceptionV3-based CNN model appeared to be suitable for modeling this dataset. We should consider experimenting with TensorFlow for further modeling.\n",
        "\n",
        "Dataset Used: Fruits-360: A dataset of images containing fruits and vegetables.\n",
        "\n",
        "Dataset ML Model: Multi-class image classification with numerical attributes\n",
        "\n",
        "Dataset Reference: https://github.com/Horea94/Fruit-Images-Dataset\n",
        "\n",
        "One potential source of performance benchmarks: https://www.researchgate.net/publication/321475443_Fruit_recognition_from_images_using_deep_learning\n",
        "\n",
        "A deep-learning image classification project generally can be broken down into five major tasks:\n",
        "\n",
        "1. Prepare Environment\n",
        "2. Load and Prepare Images\n",
        "3. Define and Train Models\n",
        "4. Evaluate and Optimize Models\n",
        "5. Finalize Model and Make Predictions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yjz77tzczYpL"
      },
      "source": [
        "# Task 1 - Prepare Environment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yymMW8D4zYpM"
      },
      "source": [
        "# Install the packages to support accessing environment variable and SQL databases\n",
        "# !pip install python-dotenv PyMySQL boto3"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WTBLbPj6zYpP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "856c5c4b-45cd-4b91-ebd9-cb2d783ffdf5"
      },
      "source": [
        "# Retrieve GPU configuration information from Colab\n",
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "    print('Select the Runtime → \"Change runtime type\" menu to enable a GPU accelerator, ')\n",
        "    print('and then re-execute this cell.')\n",
        "else:\n",
        "    print(gpu_info)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mon Jun 28 23:46:02 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 465.27       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla V100-SXM2...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   42C    P0    25W / 300W |      0MiB / 16160MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NPBJM3QLzYpR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9c496dde-6490-43d7-d092-b1f3c36351cc"
      },
      "source": [
        "# Retrieve memory configuration information from Colab\n",
        "from psutil import virtual_memory\n",
        "ram_gb = virtual_memory().total / 1e9\n",
        "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
        "\n",
        "if ram_gb < 20:\n",
        "    print('To enable a high-RAM runtime, select the Runtime → \"Change runtime type\"')\n",
        "    print('menu, and then select High-RAM in the Runtime shape dropdown. Then, ')\n",
        "    print('re-execute this cell.')\n",
        "else:\n",
        "    print('You are using a high-RAM runtime!')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Your runtime has 13.6 gigabytes of available RAM\n",
            "\n",
            "To enable a high-RAM runtime, select the Runtime → \"Change runtime type\"\n",
            "menu, and then select High-RAM in the Runtime shape dropdown. Then, \n",
            "re-execute this cell.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rt62MLGBzYpV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "864eec2f-a027-4939-9ae6-ba0c788662fe"
      },
      "source": [
        "# Retrieve CPU information from the system\n",
        "ncpu = !nproc\n",
        "print(\"The number of available CPUs is:\", ncpu[0])"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The number of available CPUs is: 2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JU6CoUSHzYpX"
      },
      "source": [
        "## 1.a) Load libraries and modules"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5vLXzBGlzYpX"
      },
      "source": [
        "# Set the random seed number for reproducible results\n",
        "RNG_SEED = 888"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7OPrZkvnzYpZ"
      },
      "source": [
        "# Load libraries and packages\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "import os\n",
        "import sys\n",
        "from datetime import datetime\n",
        "import zipfile\n",
        "import h5py\n",
        "# import boto3\n",
        "# from dotenv import load_dotenv\n",
        "from sklearn import preprocessing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import classification_report\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j_DlsgItzYpb"
      },
      "source": [
        "## 1.b) Set up the controlling parameters and functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YidrXfyszYpc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b4e3e360-ee6e-49b6-9351-e2dde415d1f0"
      },
      "source": [
        "# Begin the timer for the script processing\n",
        "start_time_script = datetime.now()\n",
        "\n",
        "# Set up the number of CPU cores available for multi-thread processing\n",
        "N_JOBS = 1\n",
        "\n",
        "# Set up the flag to stop sending progress emails (setting to True will send status emails!)\n",
        "NOTIFY_STATUS = False\n",
        "\n",
        "# Set the percentage sizes for splitting the dataset\n",
        "# VAL_SET_RATIO = 0.3\n",
        "# TEST_SET_RATIO = 0.5\n",
        "\n",
        "# Set various default modeling parameters\n",
        "DEFAULT_LOSS = 'categorical_crossentropy'\n",
        "DEFAULT_METRICS = ['accuracy']\n",
        "DEFAULT_OPTIMIZER = tf.keras.optimizers.Adam(learning_rate=0.0001)\n",
        "DEFAULT_INITIALIZER = tf.keras.initializers.RandomNormal(seed=RNG_SEED)\n",
        "CLASSIFIER_ACTIVATION = 'softmax'\n",
        "MAX_EPOCHS = 5\n",
        "BATCH_SIZE = 32\n",
        "RAW_IMAGE_SIZE = (100, 100)\n",
        "TARGET_IMAGE_SIZE = (100, 100)\n",
        "INPUT_IMAGE_SHAPE = (TARGET_IMAGE_SIZE[0], TARGET_IMAGE_SIZE[1], 3)\n",
        "\n",
        "NUM_CLASSES = 131\n",
        "# CLASS_LABELS = []\n",
        "# CLASS_NAMES = []\n",
        "\n",
        "# Define the labels to use for graphing the data\n",
        "train_metric = \"accuracy\"\n",
        "validation_metric = \"val_accuracy\"\n",
        "train_loss = \"loss\"\n",
        "validation_loss = \"val_loss\"\n",
        "\n",
        "# Define the directory locations and file names\n",
        "STAGING_DIR = 'staging/'\n",
        "TRAIN_DIR = 'staging/Fruit-Images-Dataset-master/Training/'\n",
        "# VALID_DIR = ''\n",
        "TEST_DIR = 'staging/Fruit-Images-Dataset-master/Test/'\n",
        "# TRAIN_DATASET = ''\n",
        "# VALID_DATASET = ''\n",
        "# TEST_DATASET = ''\n",
        "# TRAIN_LABELS = ''\n",
        "# VALID_LABELS = ''\n",
        "# TEST_LABELS = ''\n",
        "# OUTPUT_DIR = 'staging/'\n",
        "# SAMPLE_SUBMISSION_CSV = 'sample_submission.csv'\n",
        "# FINAL_SUBMISSION_CSV = 'submission.csv'\n",
        "\n",
        "# Check the number of GPUs accessible through TensorFlow\n",
        "print('Num GPUs Available:', len(tf.config.list_physical_devices('GPU')))\n",
        "\n",
        "# Print out the TensorFlow version for confirmation\n",
        "print('TensorFlow version:', tf.__version__)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Num GPUs Available: 1\n",
            "TensorFlow version: 2.5.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W-a57IMqzYph"
      },
      "source": [
        "# Set up the email notification function\n",
        "def status_notify(msg_text):\n",
        "    access_key = os.environ.get('SNS_ACCESS_KEY')\n",
        "    secret_key = os.environ.get('SNS_SECRET_KEY')\n",
        "    aws_region = os.environ.get('SNS_AWS_REGION')\n",
        "    topic_arn = os.environ.get('SNS_TOPIC_ARN')\n",
        "    if (access_key is None) or (secret_key is None) or (aws_region is None):\n",
        "        sys.exit(\"Incomplete notification setup info. Script Processing Aborted!!!\")\n",
        "    sns = boto3.client('sns', aws_access_key_id=access_key, aws_secret_access_key=secret_key, region_name=aws_region)\n",
        "    response = sns.publish(TopicArn=topic_arn, Message=msg_text)\n",
        "    if response['ResponseMetadata']['HTTPStatusCode'] != 200 :\n",
        "        print('Status notification not OK with HTTP status code:', response['ResponseMetadata']['HTTPStatusCode'])"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gCnz7I5wzYpi"
      },
      "source": [
        "if NOTIFY_STATUS: status_notify('(TensorFlow Multi-Class) Task 1 - Prepare Environment has begun on ' + datetime.now().strftime('%A %B %d, %Y %I:%M:%S %p'))"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-b-SwoTszYpk"
      },
      "source": [
        "# Reset the random number generators\n",
        "def reset_random(x=RNG_SEED):\n",
        "    random.seed(x)\n",
        "    np.random.seed(x)\n",
        "    tf.random.set_seed(x)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "TkZYm2ZmzYpl"
      },
      "source": [
        "if NOTIFY_STATUS: status_notify('(TensorFlow Multi-Class) Task 1 - Prepare Environment completed on ' + datetime.now().strftime('%A %B %d, %Y %I:%M:%S %p'))"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "CMKAG-YIzYpn"
      },
      "source": [
        "# Task 2 - Load and Prepare Images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "xHtS66j4zYpo"
      },
      "source": [
        "if NOTIFY_STATUS: status_notify('(TensorFlow Multi-Class) Task 2 - Load and Prepare Images has begun on ' + datetime.now().strftime('%A %B %d, %Y %I:%M:%S %p'))"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iI1RPsfzzYpr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5ad63647-86b4-4662-c919-b74d1b342c73"
      },
      "source": [
        "!rm -rf staging/\n",
        "!mkdir staging/\n",
        "!rm Fruit-Images-Dataset-master.zip\n",
        "!wget https://dainesanalytics.com/datasets/kaggle-fruits-360-images/Fruit-Images-Dataset-master.zip"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "rm: cannot remove 'Fruit-Images-Dataset-master.zip': No such file or directory\n",
            "--2021-06-28 23:46:06--  https://dainesanalytics.com/datasets/kaggle-fruits-360-images/Fruit-Images-Dataset-master.zip\n",
            "Resolving dainesanalytics.com (dainesanalytics.com)... 13.35.24.102, 13.35.24.74, 13.35.24.127, ...\n",
            "Connecting to dainesanalytics.com (dainesanalytics.com)|13.35.24.102|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 798281939 (761M) [application/zip]\n",
            "Saving to: ‘Fruit-Images-Dataset-master.zip’\n",
            "\n",
            "Fruit-Images-Datase 100%[===================>] 761.30M  25.1MB/s    in 31s     \n",
            "\n",
            "2021-06-28 23:46:37 (24.9 MB/s) - ‘Fruit-Images-Dataset-master.zip’ saved [798281939/798281939]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oFS8xhMSZn-m"
      },
      "source": [
        "dataset_zip = 'Fruit-Images-Dataset-master.zip'\n",
        "zip_ref = zipfile.ZipFile(dataset_zip, 'r')\n",
        "zip_ref.extractall(STAGING_DIR)\n",
        "zip_ref.close()"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oTDVdDpybkPn",
        "outputId": "24ecf7d4-3416-4286-c30a-6152e2aa4afb"
      },
      "source": [
        "datagen_kwargs = dict(rescale=1./255)\n",
        "training_datagen = ImageDataGenerator(**datagen_kwargs)\n",
        "# validation_datagen = ImageDataGenerator(**datagen_kwargs)\n",
        "dataflow_kwargs = dict(class_mode=\"categorical\")\n",
        "\n",
        "do_data_augmentation = False\n",
        "if do_data_augmentation:\n",
        "    training_datagen = ImageDataGenerator(rotation_range=90,\n",
        "                                          horizontal_flip=True,\n",
        "                                          vertical_flip=True,\n",
        "                                          **datagen_kwargs)\n",
        "\n",
        "print('Loading and pre-processing the training images...')\n",
        "training_generator = training_datagen.flow_from_directory(directory=TRAIN_DIR,\n",
        "                                                          target_size=TARGET_IMAGE_SIZE,\n",
        "                                                          shuffle=True,\n",
        "                                                          seed=RNG_SEED,\n",
        "                                                          **dataflow_kwargs)\n",
        "print('Number of image batches per epoch of modeling:', len(training_generator))\n",
        "\n",
        "# print('Loading and pre-processing the validation images...')\n",
        "# validation_generator = validation_datagen.flow_from_directory(directory=VALID_DIR,\n",
        "#                                                               target_size=TARGET_IMAGE_SIZE,\n",
        "#                                                               shuffle=False,\n",
        "#                                                               **dataflow_kwargs)\n",
        "# print('Number of image batches per epoch of modeling:', len(validation_generator))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading and pre-processing the training images...\n",
            "Found 67692 images belonging to 131 classes.\n",
            "Number of image batches per epoch of modeling: 2116\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_C7U2LGuzYp7"
      },
      "source": [
        "if NOTIFY_STATUS: status_notify('(TensorFlow Multi-Class) Task 2 - Load and Prepare Images completed on ' + datetime.now().strftime('%A %B %d, %Y %I:%M:%S %p'))"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q1zN_4yTzYp8"
      },
      "source": [
        "# Task 3 - Define and Train Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Do8vW0SIzYp9"
      },
      "source": [
        "if NOTIFY_STATUS: status_notify('(TensorFlow Multi-Class) Task 3 - Define and Train Models has begun on ' + datetime.now().strftime('%A %B %d, %Y %I:%M:%S %p'))"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TxzTYyrwzYp-"
      },
      "source": [
        "# Define the function for plotting training results for comparison\n",
        "def plot_metrics(history):\n",
        "    fig, axs = plt.subplots(1, 2, figsize=(24, 15))\n",
        "    metrics =  [train_loss, train_metric]\n",
        "    for n, metric in enumerate(metrics):\n",
        "        name = metric.replace(\"_\",\" \").capitalize()\n",
        "        plt.subplot(2,2,n+1)\n",
        "        plt.plot(history.epoch, history.history[metric], color='blue', label='Train')\n",
        "        # plt.plot(history.epoch, history.history['val_'+metric], color='red', linestyle=\"--\", label='Val')\n",
        "        plt.xlabel('Epoch')\n",
        "        plt.ylabel(name)\n",
        "        if metric == train_loss:\n",
        "            plt.ylim([0, plt.ylim()[1]])\n",
        "        else:\n",
        "            plt.ylim([0.5, 1.1])\n",
        "        plt.legend()"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M2nXRu9mzYqA"
      },
      "source": [
        "# Define the baseline model for benchmarking\n",
        "def create_nn_model(input_param=INPUT_IMAGE_SHAPE, output_param=NUM_CLASSES, classifier_activation=CLASSIFIER_ACTIVATION,\n",
        "                    loss_param=DEFAULT_LOSS, opt_param=DEFAULT_OPTIMIZER, metrics_param=DEFAULT_METRICS):\n",
        "    base_model = keras.applications.InceptionV3(include_top=False, weights='imagenet', input_shape=input_param, pooling='avg')\n",
        "    nn_model = keras.models.Sequential()\n",
        "    nn_model.add(base_model)\n",
        "    nn_model.add(keras.layers.Flatten())\n",
        "    nn_model.add(keras.layers.Dense(output_param, activation=classifier_activation))\n",
        "    nn_model.compile(loss=loss_param, optimizer=opt_param, metrics=metrics_param)\n",
        "    return nn_model"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OcVElo2TzYqC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ee2d45b-0346-47ba-fb48-3425fcade3b3"
      },
      "source": [
        "# Initialize the neural network model and get the training results for plotting graph\n",
        "start_time_module = datetime.now()\n",
        "# learning_rate_reduction = ReduceLROnPlateau(monitor='val_accuracy', patience = 3, verbose=1, factor=0.5, min_lr=0.000001)\n",
        "reset_random()\n",
        "nn_model_0 = create_nn_model()\n",
        "nn_model_history = nn_model_0.fit(training_generator,\n",
        "                                  epochs=MAX_EPOCHS,\n",
        "                                #   validation_data=validation_generator,\n",
        "                                #   callbacks=[learning_rate_reduction],\n",
        "                                  verbose=1)\n",
        "print('Total time for model fitting:', (datetime.now() - start_time_module))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "87916544/87910968 [==============================] - 4s 0us/step\n",
            "Epoch 1/5\n",
            "2116/2116 [==============================] - 143s 57ms/step - loss: 0.4320 - accuracy: 0.9146\n",
            "Epoch 2/5\n",
            "2116/2116 [==============================] - 117s 56ms/step - loss: 0.0422 - accuracy: 0.9893\n",
            "Epoch 3/5\n",
            "2116/2116 [==============================] - 118s 56ms/step - loss: 0.0308 - accuracy: 0.9920\n",
            "Epoch 4/5\n",
            "2116/2116 [==============================] - 117s 55ms/step - loss: 0.0271 - accuracy: 0.9936\n",
            "Epoch 5/5\n",
            "2116/2116 [==============================] - 116s 55ms/step - loss: 0.0226 - accuracy: 0.9946\n",
            "Total time for model fitting: 0:10:22.337074\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B3TrVKk4zYqE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "83829f97-d7a0-4b92-b48c-3c2ab443fc39"
      },
      "source": [
        "nn_model_0.summary()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "inception_v3 (Functional)    (None, 2048)              21802784  \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 131)               268419    \n",
            "=================================================================\n",
            "Total params: 22,071,203\n",
            "Trainable params: 22,036,771\n",
            "Non-trainable params: 34,432\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xPh-jQdtzYqF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 437
        },
        "outputId": "b7460840-7def-4a91-8979-5d5601d2d653"
      },
      "source": [
        "plot_metrics(nn_model_history)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAABW4AAAGkCAYAAAChCLzfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOzde7SdVX0v/O8kCYkGhApRbIJcLAooLUhERe1RQaugIPoKYcjVYzCYy7JqrXhabz09jmOvO2mEkh6ggm0MVjpQ0te3oD09grYE7KlEarmcauKpkAICilxi5vvH2pFtyGUn2WvPtfb+fMZYI+t51rP3/u4xYIw5vvllzlJrDQAAAAAA/WOP1gEAAAAAAPh5ilsAAAAAgD6juAUAAAAA6DOKWwAAAACAPqO4BQAAAADoM4pbAAAAAIA+o7gFAIABU0q5rJRybynltm18fngp5eullMdKKR8Y73wAAOw+xS0AAAyeK5K8YTuf359kSZLfH5c0AACMOcUtAAAMmFrr36dbzm7r83trrTcneWL8UgEAMJYUtwAAAAAAfWZq6wA7a//9968HH3xw6xgAAJPKLbfc8h+11lmtczD2SikXJLkgSWbOnHns4Ycf3jgRAMDksb119sAVtwcffHDWrFnTOgYAwKRSSvlu6wz0Rq310iSXJsncuXOrtTYAwPjZ3jrbVgkAAAAAAH1m4CZuAQBgsiul/GWSVyfZv5SyPslHk0xLklrrJaWUA5KsSfKMJJtKKe9NcmSt9aFGkQEA2EmKWwAAGDC11jN38PkPkswZpzgAAPSA4hYAYAeeeOKJrF+/Po8++mjrKD03Y8aMzJkzJ9OmTWsdBQCACc46e/sUtwAAO7B+/frsvffeOfjgg1NKaR2nZ2qtue+++7J+/foccsghreMAADDBWWdvn8PJAAB24NFHH81+++03oReTSVJKyX777TcpJh4AAGjPOnv7FLcAAKMw0ReTm02W3xMAgP4wWdafu/J7Km4BAPrcfffdl6OPPjpHH310DjjggMyePftn148//vh2v3bNmjVZsmTJOCUFAIDB0e/rbHvcAgD0uf322y//9E//lCT52Mc+lr322isf+MAHfvb5xo0bM3Xq1pd1c+fOzdy5c8clJwAADJJ+X2ebuAUAGEDnnXdeFixYkJe+9KX54Ac/mH/8x3/My1/+8hxzzDE5/vjj853vfCdJ8nd/93d505velKS7GH3nO9+ZV7/61Tn00EOzdOnSlr8CAAD0nX5aZ5u4BQAYUOvXr89NN92UKVOm5KGHHsr/+l//K1OnTs3111+fD3/4w/mrv/qrp3zNv/zLv+SrX/1qHn744bzgBS/IhRdemGnTpjVIDwAA/alf1tmKWwCAnfDe9ybD/5pqzBx9dPLHf7zzX/f2t789U6ZMSZI8+OCDOffcc3PHHXeklJInnnhiq19z8sknZ/r06Zk+fXqe9axn5Z577smcOXN2Jz4AAOw26+ynslUCAMCAmjlz5s/e//Zv/3Ze85rX5LbbbssXv/jFPProo1v9munTp//s/ZQpU7Jx48ae5wQAgEHSL+tsE7c7sGlTsod6GwAYtit/Yz8eHnzwwcyePTtJcsUVV7QNAwAAO8k6+6lUktuwYUPy0pcmV17ZOgkAwI598IMfzEUXXZRjjjnGFC0AAIyRluvsUmsd1x+4u+bOnVvXrFnT859Ta3LUUcmeeya33JKU0vMfCQD0qdtvvz1HHHFE6xjjZmu/bynlllrr3EaRGCfjtdYGAEiss5Ptr7NN3G5DKcmSJck3v5l87Wut0wAAAAAAk4nidjvOOit55jOToaHWSQAAAACAyURxux1Pf3oyf35yzTXJd7/bOg0AAAAAMFkobndg4cLutgnLl7dOAgC0NGjnAuyqyfJ7AgDQHybL+nNXfk/F7Q4ceGDy1rcmK1YkP/5x6zQAQAszZszIfffdN+EXlbXW3HfffZkxY0brKAAATALW2ds3tUd5JpROJ7n66uTKK5MFC1qnAQDG25w5c7J+/fps2LChdZSemzFjRubMmdM6BgAAk4B19vYpbkfh+OOTY49Nli5N3v3u7tYJAMDkMW3atBxyyCGtYwAAwIRinb19tkoYhVK6U7e335787d+2TgMAAAAATHSK21E6/fTk2c9OhoZaJwEAAAAAJjrF7ShNn97d33b16uRf/7V1GgAAAABgIlPc7oQFC5Jp05Jly1onAQAAAAAmMsXtTjjggGTevOSKK5IHH2ydBgAAAACYqBS3O6nTSX70o+Tyy1snAQAAAAAmKsXtTjr22OQVr+hul/DTn7ZOAwAAAABMRIrbXdDpJHffnVx3XeskAAAAAMBEpLjdBaedlhx4YDI01DoJAAAAADARKW53wdSpycKFyVe+knzrW63TAAAAAAATjeJ2F82fnzztacnSpa2TAAAAAAATjeJ2Fz3zmcnZZydXXZX8x3+0TgMAAAAATCSK292wZEny6KPJihWtkwAAAAAAE4nidje88IXJiScmy5cnTzzROg0AAAAAMFH0tLgtpbyhlPKdUsqdpZQPbee5t5VSaillbi/z9MKSJcn3v5984QutkwAAAAAAE0XPittSypQky5O8McmRSc4spRy5lef2TtJJ8g+9ytJLJ5+cPO95ydBQ6yQAAAAAwETRy4nb45LcWWu9u9b6eJKVSU7dynO/k+S/J3m0h1l6Zo89ksWLk69/Pbn55tZpAAAAAICJoJfF7ewk60Zcrx++9zOllBcnObDWel0Pc/Tc+ecne+9t6hYAAAAAGBvNDicrpeyR5A+TvH8Uz15QSllTSlmzYcOG3ofbSc94Rre8XbUq+fd/b50GAAAAABh0vSxuv5/kwBHXc4bvbbZ3khcl+btSyr8leVmSa7d2QFmt9dJa69xa69xZs2b1MPKuW7w42bgxueSS1kkAAAAAgEHXy+L25iSHlVIOKaXsmWRekms3f1hrfbDWun+t9eBa68FJvpHklFrrmh5m6plf+qXuQWWXXJI89ljrNAAAAADAIOtZcVtr3ZhkUZIvJ7k9yapa69pSyidKKaf06ue21Okk996brFzZOgkAAAAAMMim9vKb11pXJ1m9xb2PbOPZV/cyy3g44YTkhS/sHlJ2zjlJKa0TAQAAAACDqNnhZBNRKcmSJck3v5l87Wut0wAAAAAAg0pxO8bOOit55jO7U7cAAAAAALtCcTvGnv70ZP785Jprku9+t3UaAAAAAGAQKW574D3v6W6bsHx56yQAAAAAwCBS3PbAc5+bnHZasmJF8uMft04DAAAAAAwaxW2PdDrJD3+YXHll6yQAAAAAwKBR3PbIK16RvPjFydKlSa2t0wAAAAAAg0Rx2yOldKdub789+du/bZ0GAAAAABgkitseOuOM5NnP7k7dAgAAAACMluK2h6ZPTxYsSK67LrnjjtZpAAAAAIBBobjtsQULkmnTkmXLWicBAGCiKKVcVkq5t5Ry2zY+L6WUpaWUO0sp/1xKefF4ZwQAYPcobnvsgAOSefOSyy9PHnywdRoAACaIK5K8YTufvzHJYcOvC5JcPA6ZAAAYQ4rbcdDpJD/6Ube8BQCA3VVr/fsk92/nkVOTfKZ2fSPJvqWU54xPOgAAxoLidhwce2zyild0t0v46U9bpwEAYBKYnWTdiOv1w/cAABgQittx0ukkd9/dPagMAAD6RSnlglLKmlLKmg0bNrSOAwDAMMXtODnttOTAA5OhodZJAACYBL6f5MAR13OG7z1FrfXSWuvcWuvcWbNmjUs4AAB2bGrrAJPF1KnJwoXJhz6UfOtbyVFHtU4EAMAEdm2SRaWUlUlemuTBWuu/N84EAIxQ65OvTZt+/nqy3u+XTG9+c/LCF7b+L0RxO67e9a7k4x9Pli5NVqxonQYAgEFVSvnLJK9Osn8pZX2SjyaZliS11kuSrE5yUpI7kzyS5Pw2SQH638jCZtOmJ18jr7f3Wa+v/eyxve6XkpH+duCBittJZ7/9krPOSq68MvnkJ5P992+dCACAQVRrPXMHn9ckC8cpDtBjm8uejRu7B15v+erl/UH53rtT5DF6e+zx5KuUsbve1a+dOnXnnh/555avnb0/lt9rst3vx0xb3t9zz9b/t3UpbsfZkiXdadsVK5KLLmqdBgAAoD/VmtxxR/KjH/VHMdjyZw5KuThlSrdImzLl519buzea+3vuOfpnR5Z0rUrEifyzN5dZwPhS3I6zF70oOeGEZPny5AMfSKZNa50IAACgP9Sa3HJLcvXV3df/+T/j97P32GPnS8btPTt9+u5/j7HIMV7fYw9HnwOMOcVtA51OcsopyTXXJKef3joNAABAO1sra6dOTU48sXu487Of3fuicvNEIQD0E8VtAyefnDzvecnQkOIWAACYfLZX1v7WbyVveUvyzGe2TgkAbSluG9hjj2Tx4uS9703WrEnmzm2dCAAAoLeUtQCwc+xC08j55yd7792dugUAAJiIau0Oq3zwg91/dfiSlyR/+IfJC16Q/I//kdxzT/I3f5O8851KWwDYkonbRp7xjG55e/HFyac+lTznOa0TAQAA7L7Nk7WrVnUna//t30zWAsCuMHHb0OLFycaNySWXtE4CAACw60ZO1h56aHey9o/+KDn88OSyy0zWAsCuMHHb0C/9UvegsksuST784WT69NaJAAAARmdzWbt5z9qRk7Uf+Uhy6qlKWgDYHYrbxjqd5HWvS1auTM49t3UaAACAbVPWAsD4Udw2dsIJyZFHdg8pO+ecpJTWiQAAAJ60rbL2da9T1gJALyluGyslWbIkWbAg+drXkle9qnUiAABgslPWAkB7its+cPbZyUUXdaduFbcAAEALyloA6C+K2z7w9Kcn8+cnv//7yXe/mxx0UOtEAADAZLC5rF21Kvn855W1ANBP9mgdgK6FC7vbJixf3joJAAAwkdWa3Hxz8hu/kRx6aHLccckf/3FyxBHJZZcl99yTrF6dnH++0hYAWjJx2yee+9zktNOSFSuSj340mTmzdSIAAGCi2FzWXn31UydrP/rR7mTtL/xC65QAwEgmbvtIp5P88IfJVVe1TgIAAAy6WpN//MfuZO0hhyQvfemTk7WXX57ce293sva885S2ANCPTNz2kVe8Innxi5OlS5MLLuhunQAAADBaIydrr766e4bGtGndydqPfcxkLQAMEsVtHymlO3V77rnJ9dd3F1cAAADbo6wFgIlJcdtnzjgj+eAHk6EhxS0AALB1yloAmPgUt31m+vRkwYLk4x9P7rgjOeyw1okAAIB+sLmsXbWqe8CYshYAJjaHk/WhBQu6C7Bly1onAQAAWtp8wNgHPvDkAWNLlyYvfGH3gLF77kmuu84BYwAwEZm47UMHHJDMm9ddiP3O7yT77NM6EQAAMF42l7VXX/3UydqPfzw55RQlLQBMBiZu+1Snk/zoR93yFgAAmNhqTf7hH56crH3Zy56crL3iiicna889V2kLAJOFids+deyxyfHHd7dLWLw4mTKldSIAAGAsmawFALZHcdvHOp3kjDO6f7N+yimt0wAAALtrZFl79dXJ977XLWtf/3plLQDw8xS3fey005I5c5KhIcUtAAAMqu2VtZ/4RHLqqcm++7ZOCQD0G8VtH5s2LVm4MLnoouRb30qOOqp1IgAAYDQ2l7WrVnW3QVDWAgA7y+FkfW7+/ORpT+vudQsAAPSvzQeMvf/9ycEHdw8YW7asO4BxxRXJvfcmX/pS94AxpS0AsCMmbvvcfvslZ52VXHll8slPdq8BAID+YLIWAOgVE7cDYMmS5NFHkxUrWicBAABqTb7xja1P1v75n5usBQDGhonbAfCiFyUnnJAsX95dHE6b1joRAABMLpu3Qbj66qdO1v7O73QPE1bSAgBjSXE7IDqd7mLwmmuS009vnQYAACa+kWXt1Vcn69YpawGA8aO4HRAnn5w873nJ0JDiFgAAemVbZe2v/VryX/+rshYAGD+K2wGxxx7J4sXJe9+brFmTzJ3bOhEAAEwMm8vazQeMKWsBgH7gcLIBcv75yd57d6duAQCAXbf5gLH3vS856KDk5S/vninxK7/y5AFjX/xics45SlsAoA0TtwPkGc/olrcXX5x86lPJc57TOhEAAAyOrU3W7rlnd89ak7UAQL8xcTtgFi1KNm5MLrmkdRIAAOh/mzYlX//6tidr77nHZC0A0J9M3A6Yww5LTjqpW9x++MPJ9OmtEwEAQH/ZtOnJA8a2nKz93d/tTtbus0/rlAAA26e4HUCdTnfRuXJlcu65rdMAAEB7I8vaq69O1q9X1gIAg01xO4BOPDE58sjuIWXnnJOU0joRAACMv22Vtb/2a8l/+2/KWgBgsCluB1ApyZIlyYIFyY03Jq98ZetEAAAwPpS1AMBkobgdUGefnVx0UXfqVnELAMBEtrmsXbWqu2etshYAmAwUtwPq6U9P5s9P/uAPku99L3nuc1snAgCAsaOsBQAmuz1aB2DXLVzY/XP58rY5AABgLGzalNx0U/Lrv54cdFBy/PHJpz+dHHNM8pnPJPfem1x7bfdfnyltAYCJzsTtAHvuc5PTTktWrEg+8pFk5szWiQAAYOds2pR84xvd/WpN1gIAPElxO+A6ne4C96qrkne/u3UaAADYse2VtZ/8ZPLmNytrAQAUtwPuFa9IXvziZOnS5IILklJaJwIAgO1773uTZcuUtQAA26O4HXCldKduzz03uf765HWva50IAAC276yzkuOOU9YCAGyPw8kmgDPOSJ71rGRoqHUSAADYseOO65a3SlsAgG1T3E4A06cnCxYk112X3HFH6zQAAAAAwO5S3E4QF16YTJvW3SsMAAAAABhsitsJ4oADulsmXH558uCDrdMAAAAAALtDcTuBdDrJj37ULW8BAJi4SilvKKV8p5RyZynlQ1v5/KBSyg2llH8upfxdKWVOi5wAAOy6nha3o1hQLiilfKuU8k+llK+VUo7sZZ6Jbu7c5Pjju9sl/PSnrdMAANALpZQpSZYneWOSI5OcuZV19O8n+Uyt9ZeTfCLJJ8c3JQAAu6tnxe0oF5R/UWs9qtZ6dJJPJfnDXuWZLDqd5O67k9WrWycBAKBHjktyZ6317lrr40lWJjl1i2eOTPKV4fdf3crnAAD0uV5O3O5wQVlrfWjE5cwktYd5JoXTTkvmzEmGhlonAQCgR2YnWTfiev3wvZH+d5K3Dr8/LcnepZT9xiEbAABjpJfF7WgWlCmlLCyl3JXuxO2SHuaZFKZNSxYuTG64IbntttZpAABo5ANJ/lMp5ZtJ/lOS7yfZ6mZapZQLSilrSilrNmzYMJ4ZAQDYjuaHk9Val9dan5fkN5P81taesZjcOfPnJ097WrJ0aeskAAD0wPeTHDjies7wvZ+ptf7fWutba63HJPkvw/d+uLVvVmu9tNY6t9Y6d9asWb3KDADATuplcbvDBeUWViZ5y9Y+sJjcOfvtl5x1VnLllcl997VOAwDAGLs5yWGllENKKXsmmZfk2pEPlFL2L6VsXutflOSycc4IAMBu6mVxO5oF5WEjLk9OckcP80wqS5Ykjz6arFjROgkAAGOp1roxyaIkX05ye5JVtda1pZRPlFJOGX7s1Um+U0r51yTPTvK7TcICALDLpvbqG9daN5ZSNi8opyS5bPOCMsmaWuu1SRaVUk5M8kSSB5Kc26s8k82LXpSccEKyfHny/vd3974FAGBiqLWuTrJ6i3sfGfH+80k+P965AAAYOz0rbpNRLSg7vfz5k12nk5xySnLNNcnpp7dOAwAAAACMVvPDyeidk05KDj00GRpqnQQAAAAA2BmK2wlsypRk8eLkppuSNWtapwEAAAAARktxO8Gdf36y116mbgEAAABgkChuJ7h99umWt5/7XPLv/946DQAAAAAwGorbSWDx4mTjxuRP/7R1EgAAAABgNBS3k8Bhh3UPKrv44uSxx1qnAQAAAAB2RHE7SXQ6yb33drdMAAAAAAD6m+J2kjjxxOTII7uHlNXaOg0AAAAAsD2K20milGTJkuTWW5Mbb2ydBgAAAADYHsXtJHL22ckv/EJ36hYAAAAA6F+K20nk6U9P5s9Prrkm+d73WqcBAAAAALZFcTvJLFzY3eN2+fLWSQAAAACAbVHcTjLPfW5y2mnJihXJj3/cOg0AAAAAsDWK20mo00keeCC56qrWSQAAAACArVHcTkKvfGVyzDHJ0qXdbRMAAAAAgP6iuJ2ESulO3X7728n117dOAwAAAABsSXE7Sc2blzzrWcnQUOskAAAAAMCWFLeT1PTpyYIFyXXXJXfc0ToNAAAAADCS4nYSu/DCZNq05E/+pHUSAAAAAGAkxe0kdsAByRlnJJdfnjz0UOs0AAAAAMBmittJrtNJHn64W94CAAAAAP1BcTvJzZ2bHH98smxZ8tOftk4DAAAAACSKW9Kdur3rrmT16tZJAAAAAIBEcUuS005L5sxJhoZaJwEAAAAAEsUtSaZNSxYuTG64IbntttZpAAAAAADFLUmS+fOTGTOSpUtbJwEAAAAAFLckSfbbLznrrOTKK5P77mudBgAAAAAmN8UtP7NkSfLoo8mKFa2TAAAAAMDkprjlZ446Knnta5Ply5MnnmidBgAAAAAmL8UtP6fTSdavT665pnUSAAAAAJi8FLf8nJNPTg491CFlAAAAANCS4pafM2VKsnhxcuONyS23tE4DAAAAAJOT4panOP/8ZK+9kqGh1kkAAAAAYHJS3PIU++zTLW9Xrkx+8IPWaQAAAABg8lHcslWLFycbNyaXXNI6CQDAxFVKeXMpxZocAICnsEhkqw47LDnppOTii5PHHmudBgBgwjojyR2llE+VUg5vHQYAgP6huGWbOp3k3nuTz32udRIAgImp1npWkmOS3JXkilLK10spF5RS9m4cDQCAxhS3bNOJJyZHHNE9pKzW1mkAACamWutDST6fZGWS5yQ5LcmtpZTFTYMBANCU4pZtKiVZsiS59dbkxhtbpwEAmHhKKaeUUq5J8ndJpiU5rtb6xiS/kuT9LbMBANCW4pbtOvvsZN99u1O3AACMubcl+aNa61G11t+rtd6bJLXWR5L857bRAABoSXHLds2cmcyfn1xzTfK977VOAwAw4XwsyT9uviilPK2UcnCS1FpvaBMJAIB+oLhlhxYu7O5xu3x56yQAABPO1Uk2jbj+6fA9AAAmOcUtO3TQQclppyUrViQ//nHrNAAAE8rUWuvjmy+G3+/ZMA8AAH1CccuodDrJAw8kn/1s6yQAABPKhlLKKZsvSimnJvmPhnkAAOgTiltG5ZWvTI45Jlm6tLttAgAAY2JBkg+XUr5XSlmX5DeTvLtxJgAA+oDillEppTt1u3ZtcoNjMgAAxkSt9a5a68uSHJnkiFrr8bXWO1vnAgCgvVEVt6WUmaWUPYbfP7+UckopZVpvo9Fv5s1LnvWsZGiodRIAgImjlHJykvckeV8p5SOllI+0zgQAQHujnbj9+yQzSimzk/x/Sc5OckWvQtGfpk9PFixIrrsuudMcCADAbiulXJLkjCSLk5Qkb09yUNNQAAD0hdEWt6XW+kiStyb5dK317Ule2LtY9KsLL0ymTk2WLWudBABgQji+1npOkgdqrR9P8vIkz2+cCQCAPjDq4raU8vIk70hy3fC9Kb2JRD874IDkjDOSyy9PHnqodRoAgIH36PCfj5RSfjHJE0me0zAPAAB9YrTF7XuTXJTkmlrr2lLKoUm+2rtY9LMlS5KHH+6WtwAA7JYvllL2TfJ7SW5N8m9J/qJpIgAA+sLU0TxUa/2fSf5nkgwfUvYftdYlvQxG/3rJS5KXv7y7XcKiRckUs9cAADtteF19Q631h0n+qpTypSQzaq0PNo4GAEAfGNXEbSnlL0opzyilzExyW5Jvl1J+o7fR6GedTnLXXcnq1a2TAAAMplrrpiTLR1w/NtrStpTyhlLKd0opd5ZSPrSVz59bSvlqKeWbpZR/LqWcNIbRAQAYB6PdKuHIWutDSd6S5G+SHJLk7J6lou+99a3J7NnJ0FDrJAAAA+2GUsrbSilltF9QSpmSbuH7xiRHJjmzlHLkFo/9VpJVtdZjksxL8umxCgwAwPgYbXE7rZQyLd3i9tpa6xNJau9i0e+mTUsWLkxuuCG57bbWaQAABta7k1yd5LFSykOllIdLKTs6Ava4JHfWWu+utT6eZGWSU7d4piZ5xvD7fZL837EMDQBA7422uP3TdA9KmJnk70spByXZ0YKSCe6CC5IZM5KlS1snAQAYTLXWvWute9Ra96y1PmP4+hk7+LLZSdaNuF4/fG+kjyU5q5SyPsnqJIu39c1KKReUUtaUUtZs2LBhF34LAAB6YVTFba11aa11dq31pNr13SSv6XE2+tx++yVnnZVcdVVy332t0wAADJ5Syq9u7TUG3/rMJFfUWuckOSnJlcOHoT1FrfXSWuvcWuvcWbNmjcGPBgBgLIz2cLJ9Sil/uPlv4kspf5Du9C2T3JIlyU9+kvzZn7VOAgAwkH5jxOu3k3wx3WnZ7fl+kgNHXM8ZvjfSf06yKklqrV9PMiPJ/rsfFwCA8TLarRIuS/JwktOHXw8lubxXoRgcRx2VvPa1yfLlycaNrdMAAAyWWuubR7xel+RFSR7YwZfdnOSwUsohpZQ90z187NotnvlekhOSpJRyRLrFrX0QAAAGyGiL2+fVWj86fADC3bXWjyc5tJfBGBydTrJuXXLNNa2TAAAMvPVJjtjeA7XWjUkWJflyktuTrKq1ri2lfKKUcsrwY+9PMr+U8r+T/GWS82qtDhcGABggU0f53E9KKa+stX4tSUopr0jyk97FYpCcfHJy6KHJ0FDy9re3TgMAMDhKKcuSbC5U90hydJJbd/R1tdbV6R46NvLeR0a8/3aSV4xdUgAAxttoi9sFST5TStln+PqBJOf2JhKDZsqUZPHi5Nd/PbnlluTYY1snAgAYGGtGvN+Y5C9rrTe2CgMAQP8Y1VYJtdb/XWv9lSS/nOSXa63HJHltT5MxUM4/P9lrr+7ULQAAo/b5JFfVWv+81vrZJN8opTy9dSgAANob7R63SZJa60O11oeGL9/XgzwMqH326Za3K1cmP/hB6zQAAAPjhiRPG3H9tCTXN8oCANhxPUsAACAASURBVEAf2anidgtlzFIwISxalDzxRHLJJa2TAAAMjBm11h9tvhh+b+IWAIDdKm6dSsvPef7zk5NOSi6+OHnssdZpAAAGwo9LKS/efFFKOTYOAQYAIDs4nKyU8nC2XtCW/Pw/6YIkSaeT/NqvJZ/7XHLOOa3TAAD0vfcmubqU8n/TXWMfkOSMtpEAAOgH2y1ua617j1cQJobXvS454ojuIWVnn50UG2oAAGxTrfXmUsrhSV4wfOs7tdYnWmYCAKA/7M5WCfAUpSRLliS33prceGPrNAAA/a2UsjDJzFrrbbXW25LsVUp5T+tcAAC0p7hlzJ19drLvvsnSpa2TAAD0vfm11h9uvqi1PpBkfsM8AAD0CcUtY27mzGT+/OQLX0jWrWudBgCgr00p5cnNpUopU5Ls2TAPAAB9QnFLTyxcmNSaLF/eOgkAQF/7f5N8rpRyQinlhCR/meRvGmcCAKAPKG7piYMOSk47Lbn00uSRR1qnAQDoW7+Z5CtJFgy/vpXkaU0TAQDQF3pa3JZS3lBK+U4p5c5Syoe28vn7SinfLqX8cynlhlLKQb3Mw/jqdJIHHkiuuqp1EgCA/lRr3ZTkH5L8W5Ljkrw2ye0tMwEA0B96VtwO78+1PMkbkxyZ5MxSypFbPPbNJHNrrb+c5PNJPtWrPIy/V74yOeaY7iFltbZOAwDQP0opzy+lfLSU8i9JliX5XpLUWl9Ta/2TtukAAOgHvZy4PS7JnbXWu2utjydZmeTUkQ/UWr9aa938D+m/kWROD/MwzkrpTt2uXZvccEPrNAAAfeVf0p2ufVOt9ZW11mVJfto4EwAAfaSXxe3sJOtGXK8fvrct/zkOYphw5s1LnvWsZGiodRIAgL7y1iT/nuSrpZQVwweTlcaZAADoI31xOFkp5awkc5P83jY+v6CUsqaUsmbDhg3jG47dMn168u53J9ddl9x5Z+s0AAD9odb617XWeUkOT/LVJO9N8qxSysWllNe3TQcAQD/oZXH7/SQHjrieM3zv55RSTkzyX5KcUmt9bGvfqNZ6aa11bq117qxZs3oSlt658MJk6tRk2bLWSQAA+kut9ce11r+otb453fXyN5P8ZuNYAAD0gV4WtzcnOayUckgpZc8k85JcO/KBUsoxSf403dL23h5moaHnPCc5/fTk8suThx5qnQYAoD/VWh8YHlg4oXUWAADa61lxW2vdmGRRki8nuT3Jqlrr2lLKJ0oppww/9ntJ9kpydSnln0op127j2zHgOp3k4Ye75S0AAAAAsH1Te/nNa62rk6ze4t5HRrw/sZc/n/7xkpckL395d7uERYuSKVNaJwIAAACA/tUXh5MxOXQ6yV13JatX7/hZAAAAAJjMFLeMm7e+NZk9O1m6tHUSAAAAAOhvilvGzbRpycKFyfXXJ2vXtk4DAAAAAP1Lccu4uuCCZMYMU7cAAAAAsD2KW8bVfvslZ52VXHllcv/9rdMAAAAAQH9S3DLulixJfvKTZMWK1kkAAAAAoD8pbhl3Rx2VvPa1yfLlycaNrdMAAAAAQP9R3NJEp5OsW5dcc03rJAAAAADQfxS3NHHyyckhhyRDQ62TAAAAAED/UdzSxJQpyeLFyY03Jrfc0joNAAAAAPQXxS3NvPOdyV57mboFAAAAgC0pbmlmn32S885LVq5MfvCD1mkAAAAAoH8obmlq8eLkiSeSSy5pnQQAAAAA+ofilqae//zkpJOSiy9OHnusdRoAAAAA6A+KW5rrdJJ7701WrWqdBAAAAAD6g+KW5l73uuSII7qHlNXaOg0AAAAAtKe4pblSkiVLkltuSW66qXUaAAAAAGhPcUtfOPvsZN99u1O3AAAAADDZKW7pCzNnJvPnJ1/4QrJuXes0AAAAANCW4pa+sXBhd4/b5ctbJwEAAACAthS39I2DDkpOOy259NLkkUdapwEAAACAdhS39JUlS5IHHkiuuqp1EgAAAABoR3FLX3nVq5Kjj06WLu1umwAAAAAAk5Hilr5SStLpJGvXJjfc0DoNAAAAALShuKXvzJuXzJqVDA21TgIAAAAAbShu6TszZiQLFiTXXZfceWfrNAAAAAAw/hS39KULL0ymTk2WLWudBAAAAADGn+KWvvSc5ySnn55cfnny0EOt0wAAAADA+FLc0rc6neThh5MrrmidBAAAAADGl+KWvvWSlyQvf3l3u4RNm1qnAQAAAIDxo7ilr3U63QPKVq9unQQAAAAAxo/ilr721rcms2cnQ0OtkwAA9I9SyhtKKd8ppdxZSvnQVj7/o1LKPw2//rWU8sMWOQEA2HWKW/ratGnJwoXJ9dcna9e2TgMA0F4pZUqS5UnemOTIJGeWUo4c+Uyt9ddrrUfXWo9OsizJF8Y/KQAAu0NxS9+bPz+ZMSNZurR1EgCAvnBckjtrrXfXWh9PsjLJqdt5/swkfzkuyQAAGDOKW/re/vsn73hHcuWVyf33t04DANDc7CTrRlyvH773FKWUg5IckuQr45ALAIAxpLhlIHQ6yU9+kqxY0ToJAMBAmZfk87XWn27rgVLKBaWUNaWUNRs2bBjHaAAAbI/iloFw1FHJa16TLF+ebNzYOg0AQFPfT3LgiOs5w/e2Zl52sE1CrfXSWuvcWuvcWbNmjVFEAAB2l+KWgdHpJOvWJddc0zoJAEBTNyc5rJRySCllz3TL2Wu3fKiUcniSX0jy9XHOBwDAGFDcMjDe9KbkkEOSoaHWSQAA2qm1bkyyKMmXk9yeZFWtdW0p5ROllFNGPDovycpaa22REwCA3TO1dQAYrSlTksWLk/e9L7nlluTYY1snAgBoo9a6OsnqLe59ZIvrj41nJgAAxpaJWwbKO9+Z7LVXsnRp6yQAAAAA0DuKWwbKPvsk552XrFyZ3HNP6zQAAAAA0BuKWwbO4sXJ448nl1zSOgkAAAAA9IbiloHz/OcnJ52UXHxx8thjrdMAAAAAwNhT3DKQOp3uVgmrVrVOAgAAAABjT3HLQHrd65IjjkiGhpJaW6cBAAAAgLGluGUgldLd6/aWW5KbbmqdBgAAAADGluKWgXXOOcm++3anbgEAAABgIlHcMrBmzkze9a7kC19I1q1rnQYAAAAAxo7iloG2aFF3j9vly1snAQAAAICxo7hloB10UPKWtySXXpo88kjrNAAAAAAwNhS3DLxOJ3nggeSqq1onAQAAAICxobhl4L3qVcnRRydLl3a3TQAAAACAQae4ZeCV0p26Xbs2+cpXWqcBAAAAgN2nuGVCmDcvmTUrGRpqnQQAAAAAdp/ilglhxoxkwYLkS19K7rqrdRoAAAAA2D2KWyaMCy9Mpk5Nli1rnQQAAAAAdo/ilgnjOc9JTj89ueyy5KGHWqcBAAAAgF2nuGVC6XSShx9OrriidRIAAAAA2HWKWyaUl7wkednLutslbNrUOg0AAAAA7BrFLRNOp5PceWeyenXrJAAAAACwaxS3TDhve1sye3YyNNQ6CQAAAADsGsUtE860acl73pNcf32ydm3rNAAAAACw8xS3TEgXXJDMmJEsXdo6CQAAAADsPMUtE9L++yfveEdy5ZXJ/fe3TgMAAAAAO0dxy4TV6SQ/+UmyYkXrJAAAAACwcxS3TFhHHZW85jXJ8uXJxo2t0wAAAADA6ClumdA6nWTduuSv/7p1EgAAAAAYPcUtE9qb3pQcckgyNNQ6CQAAAACMnuKWCW3KlGTx4uRrX0tuvbV1GgAAAAAYHcUtE94735nstZepWwAAAAAGh+KWCW+ffZLzzktWrkzuuad1GgAAAADYMcUtk8KiRcnjjyeXXNI6CQAAAADsWE+L21LKG0op3yml3FlK+dBWPv/VUsqtpZSNpZT/p5dZmNxe8ILkjW9MLr44eeyx1mkAAAAAYPt6VtyWUqYkWZ7kjUmOTHJmKeXILR77XpLzkvxFr3LAZp1Od6uEVataJwEAAACA7evlxO1xSe6std5da308ycokp458oNb6b7XWf06yqYc5IEny+tcnhx/ePaSs1tZpAAAAAGDbelnczk6ybsT1+uF70EQpyZIlyS23JDfd1DoNAAAAAGzbQBxOVkq5oJSyppSyZsOGDa3jMMDOOSfZd9/u1C0AAAAA9KteFrffT3LgiOs5w/d2Wq310lrr3Frr3FmzZo1JOCanmTOTd70r+cIXknXrdvw8AAAAALTQy+L25iSHlVIOKaXsmWRekmt7+PNgVBYt6u5x++lPt04CAAAAAFvXs+K21roxyaIkX05ye5JVtda1pZRPlFJOSZJSyktKKeuTvD3Jn5ZS1vYqD2x20EHJW96SXHpp8sgjrdMAAAAAwFP1dI/bWuvqWuvza63Pq7X+7vC9j9Rarx1+f3OtdU6tdWatdb9a6wt7mQc263SS++9PPvvZ1kkAAAAA4KkG4nAyGGuvelVy9NHdQ8pqbZ0GAAAAAH6e4pZJqZTu1O3atclXvtI6DQAAAAD8PMUtk9a8ecmsWd2pWwAAAADoJ4pbJq0ZM5J3vzv50peSu+5qnQYAAAAAnqS4ZVK78MJkypRk2bLWSQAAAADgSYpbJrVf/MXk9NOTyy5LHnqodRoAAAAA6FLcMul1OsnDDydXXNE6CQAAAAB0KW6Z9I47LnnZy7rbJWza1DoNAAAAAChuIUl36vbOO5PVq1snAQAAAADFLSRJ3va2ZPbsZGiodRIAAAAAUNxCkmTatOQ970muvz759rdbpwEAAABgslPcwrALLkhmzEiWLm2dBABg+0opbyilfKeUcmcp5UPbeOb0Usq3SylrSyl/Md4ZAQDYPYpbGLb//sk73pF85jPJ/fe3TgMAsHWllClJlid5Y5Ijk5xZSjlyi2cOS3JRklfUWl+Y5L3jHhQAgN2iuIUROp3kJz9J/uzPWicBANim45LcWWu9u9b6eJKVSU7d4pn5SZbXWh9IklrrveOcEQCA3aS4hRGOOip5zWuSP/mTZOPG1mkAALZqdpJ1I67XD98b6flJnl9KubGU8o1SyhvGLR0AAGNCcQtb6HSSdeuSv/7r1kkAAHbZ1CSHJXl1kjOTrCil7Lu1B0spF5RS1pRS1mzYsGEcIwIAsD2KW9jCm96UHHJIMjTUOgkAwFZ9P8mBI67nDN8baX2Sa2utT9Ra/0+Sf023yH2KWuultda5tda5s2bN6klgAAB2nuIWtjBlSrJoUfK1ryW33to6DQDAU9yc5LBSyiGllD2TzEty7RbP/HW607Yppeyf7tYJd49nSAAAdo/iFrbine9MZs40dQsA9J9a68Yki5J8OcntSVbVWteWUj5RSjll+LEvJ7mvlPLtJF9N8hu11vvaJAYAYFdMbR0A+tG++ybnnZesWJF86lPJs5/dOhEAwJNqrauTrN7i3kdGvK9J3jf8AgBgAJm4hW1YvDh5/PHkkktaJwEAAABgslHcwja84AXJG9+YXHxx8thjrdMAAAAAMJkobmE7Op3knnuSVataJwEAAABgMlHcwna8/vXJ4Yd3DymrtXUaAAAAACYLxS1sRynJkiXJLbckX/966zQAAAAATBaKW9iBc85J9t23O3ULAAAAAONBcQs7MHNm8q53JX/1V8m6da3TAAAAADAZKG5hFBYt6u5x++lPt04CAAAAwGSguIVROOig5C1vSS69NHnkkdZpAAAAAJjoFLcwSkuWJPffn3z2s62TAAAAADDRKW5hlH71V5Nf+ZXuIWW1tk4DAAAAwESmuIVRKiXpdJK1a5OvfKV1GgAAAAAmMsUt7IQzz0xmzepO3QIAAABAryhuYSfMmJG8+93Jl76U3HVX6zQAAAAATFSKW9hJF16YTJmSLFvWOgkAAAAAE5XiFnbSL/5icvrpyWWXJQ891DoNAAAAABOR4hZ2QaeTPPxw8ud/3joJAAAAABOR4hZ2wXHHJS97WXe7hE2bWqcBAAAAYKJR3MIu6nSSO+5I/uZvWicBAAAAYKJR3MIuetvbktmzk6Gh1kkAAAAAmGgUt/z/7d1tjFzVfcfx38+7Y3sT/IhJSzDGifCbpE1oGtGHvImIKpE2sl9AhaM+hIiICgShUtUW+iJVUV/kSW1EglpRQiFplBCRtnIi8mDFUZuqDYEYh8QYJIs4iiMKGOy1DXS9u/73xb2THebM7N7Znbn3zt7vR7qaM/eeuXv277N7//7vnTNYplZLuvlmaf9+6cknqx4NAAAAAAAAVpPJqgcAjLMbb5TuvFO69VZp925pyxZp69bssbO9bl3VIwUAAAAAAMA4oXALrMC2bVnR9pOflA4c6N9vaqp3Qbdfu/24ebM0yU8pAAAAAABA41ASAlboE5+QPvpRaXpaeukl6eTJbFus/ZOfSAcPZu2XX178/Bs3Fi/4drY3bpTWsBgKAAAAAADAWKJwCwzBxERWMN26dfDXnjsnnTpVvOh75MhCe2am/3nXrMnu2O13N+9i7de/XrKXHw8AAAAAAACsDIVboGJr10pveEO2DerVV4sXfE+elI4dW2jPz/c/b6u1vLt8t2yR1q9fdigAAAAAAACQo3ALjLGpKemSS7JtEBHS2bPFi77PPbdwp+/0dPb6xca0nILvli2s5wsAAAAAANBGmQRoIFvasCHbLrtssNfOz2fF26J3+f70p9Ljj2fts2cXP/eGDYMv67B1K+v5AgAAAACA1YfCLYCBrGQ939nZhcJukaLvIOv5btq0dKG31z7W8wUAAAAAAHVE4RZAaVqtla3nW7Tg277Tt92em+t/3snJwZd1aLdZzxcAAAAAAIwKhVsAY2FqKtve+MbBXtdez3exQm/nvueek556KmufOrX4er7r1w+2rMPmzdK6ddkH0rVar32cnOTOXwAAAAAAsIDCLYBVrXM93x07Bnvt+fML6/kWvcv30KGsfebM4GNttdKCbq8ib7/HQfoO8/wUnAEAAAAAGD4KtwDQx5o1C3fLvvnNg712dja7Y7ezuHvqlHTuXHas87HXviJ9Xn65WN/Z2dHEp21ysryC8zD78oF2AAAAAIA6o3ALACPQakkXXZRtVYvI1vkdtFi80sJyv8dXXil+vlGamKi+eNzvNWvXLiyrsW7dQptiMwAAAAA0B4VbAFjl7IVlGMZJu+A8jGLxMPqcOVOs77lzo4tJq5UWdDu3XvsH6bucc7A+MwAAAACMBoVbAEAtdRacX/e6qkdTXIQ0P7/8wnJ7m5nJts72Yvs6958+vXj/ubnhfb92uYXiIvu5OxkAAADAakDhFgCAIbKzu1Ana3yFPX9+6eJvkf2D9D19eulzRAzve5ycrL6A3L2Pu5MBAAAADKLG/60EAACjsGaNtH59ttVFe2mMUReQu/e1707ud45R3Z08jELx1q3SzTcPb3wAAAAA6oXCLQAAqFzn0hgXXFD1aBb0ujt51HcrnzkjnTixeP8IaccOCrcAAADAakbhFgAAoI863508O1v1SAAAAACMEoVbAACAMdJ5dzIAAACA1YvPXAYAAAAAAACAmqFwCwAAAAAAAAA1Q+EWAAAAAAAAAGqGwi0AAAAAAAAA1AyFWwAAAAAAAACoGQq3AAAAAAAAAFAzFG4BAAAAAAAAoGYo3AIAAAAAAABAzVC4BQAAAAAAAICaoXALAAAAAAAAADVD4RYAAAAAAAAAaobCLQAAAAAAAADUzEgLt7avtv207aO2b+9xfJ3tB/Pjj9jeOcrxAAAAAKtBgTz7etsv2D6Ubx+qYpwAAABYvpEVbm1PSLpb0nslvUXS+22/pavbDZJORsTlkv5e0sdGNR4AAABgNSiYZ0vSgxFxRb7dW+ogAQAAsGKjvOP2SklHI+KZiDgn6UuS9nT12SPpgbz9kKT32PYIxwQAAACMuyJ5NgAAAMbcKAu3l0j6Wcfz4/m+nn0iYk7StKQLRzgmAAAAYNwVybMl6RrbT9h+yPal5QwNAAAAwzJZ9QCKsH2jpBvzp2dtP13il98m6USJX28cEJMUMUkRkxQx6Y24pIhJipikyo7JZSV+LazcVyV9MSJmbP+Jsne5XdWrY4W5Nj/XKWLSG3FJEZMUMUkRkxQxSRGT3sqMS988e5SF259L6vzL/vZ8X68+x21PStok6cXuE0XEPZLuGdE4F2X7sYh4ZxVfu66ISYqYpIhJipj0RlxSxCRFTFLEpNGWzLMjojOnvlfSx/udrKpcmzmcIia9EZcUMUkRkxQxSRGTFDHprS5xGeVSCY9K2mX7TbbXStoraV9Xn32SPpC3r5V0ICJihGMCAAAAxt2Sebbtizue7pZ0pMTxAQAAYAhGdsdtRMzZvkXSNyVNSLovIg7bvlPSYxGxT9JnJX3e9lFJLylLOgEAAAD0UTDP/rDt3ZLmlOXZ11c2YAAAACzLSNe4jYiHJT3cte8jHe3/k/T7oxzDEFSyREPNEZMUMUkRkxQx6Y24pIhJipikiEmDFciz75B0R9njGhBzOEVMeiMuKWKSIiYpYpIiJili0lst4mJWJgAAAAAAAACAehnlGrcAAAAAAAAAgGWgcCvJ9tW2n7Z91PbtPY6vs/1gfvwR2zvLH2X5CsTletsv2D6Ubx+qYpxlsX2f7edt/7jPcdu+K4/XE7bfUfYYy1YgJu+2Pd0xRz7Sq99qYvtS29+x/aTtw7Zv69GnUXOlYEyaOFfW2/6+7R/mcfmbHn0adf0pGJNGXXvabE/Yftz213oca9Q8wfgh106RZ6fItVPk2ily7RS5doo8O0We3V/d8+yRrnE7DmxPSLpb0u9IOi7pUdv7IuLJjm43SDoZEZfb3ivpY5KuK3+05SkYF0l6MCJuKX2A1bhf0mckfa7P8fdK2pVvvyHpH/LH1ex+LR4TSfpuRLyvnOHUwpykP4uIg7Y3SPqB7f1dPztNmytFYiI1b67MSLoqIs7abkn6L9tfj4jvdfRp2vWnSEykZl172m6TdETSxh7HmjZPMEbItVPk2X3dL3LtbveLXLsbuXaKXDtFnp0iz+6v1nk2d9xKV0o6GhHPRMQ5SV+StKerzx5JD+TthyS9x7ZLHGMVisSlUSLiP5V9KnM/eyR9LjLfk7TZ9sXljK4aBWLSOBHxbEQczNtnlF0ALunq1qi5UjAmjZP/+5/Nn7byrXvh+UZdfwrGpHFsb5f0e5Lu7dOlUfMEY4dcO0We3QO5dopcO0WunSLXTpFnp8izexuHPJvCbfYL7Wcdz48r/SX3iz4RMSdpWtKFpYyuOkXiIknX5G8/ecj2peUMrbaKxqxpfit/O8bXbb+16sGUKX8bxa9JeqTrUGPnyiIxkRo4V/K35RyS9Lyk/RHRd6405fpTICZS8649n5L0F5LO9zneuHmCsUKunSLPXp7G5k9LaFz+1EaunSLXXkCenSLP7qn2eTaFW6zEVyXtjIi3Sdqvhb9CAG0HJV0WEW+X9GlJ/17xeEpj+wJJX5H0pxFxuurx1MESMWnkXImI+Yi4QtJ2SVfa/pWqx1S1AjFp1LXH9vskPR8RP6h6LABK1ajfdVi2RuZPErl2L+Tar0WenSLPfq1xybMp3Eo/l9T5V4Tt+b6efWxPStok6cVSRledJeMSES9GxEz+9F5Jv17S2OqqyFxqlIg43X47RkQ8LKlle1vFwxq5fM2gr0j6QkT8a48ujZsrS8WkqXOlLSJOSfqOpKu7DjXx+iOpf0waeO15l6Tdto8pezv1Vbb/patPY+cJxgK5doo8e3kalz8tpan5E7l2ily7P/LsFHn2L4xFnk3hVnpU0i7bb7K9VtJeSfu6+uyT9IG8fa2kAxGx2tcCWTIuXesE7Va2lk6T7ZP0x878pqTpiHi26kFVyfYvt9d/sX2lst85q/pimH+/n5V0JCL+rk+3Rs2VIjFp6Fy5yPbmvD2l7ENqnurq1qjrT5GYNO3aExF3RMT2iNip7Fp8ICL+sKtbo+YJxg65doo8e3kalT8V0dD8iVy7C7l2ijw7RZ6dGpc8e7LML1ZHETFn+xZJ35Q0Iem+iDhs+05Jj0XEPmW/BD9v+6iyxeH3VjfichSMy4dt71b2KZYvSbq+sgGXwPYXJb1b0jbbxyX9tbIFvRUR/yjpYUm/K+mopFckfbCakZanQEyulXST7TlJr0rau5ovhrl3SfojST/K1w+SpL+StENq7FwpEpMmzpWLJT3g7NPF10j6ckR8reHXnyIxadS1p5+GzxOMEXLtFHl2b+TaKXLtnsi1U+TaKfLsFHl2QXWbJ17dP6sAAAAAAAAAMH5YKgEAAAAAAAAAaobCLQAAAAAAAADUDIVbAAAAAAAAAKgZCrcAAAAAAAAAUDMUbgEAAAAAAACgZijcAsCAbM/bPtSx3T7Ec++0/eNhnQ8AAAAYJ+TaALBgsuoBAMAYejUirqh6EAAAAMAqRK4NADnuuAWAIbF9zPbHbf/I9vdtX57v32n7gO0nbH/b9o58/y/Z/jfbP8y3385PNWH7n2wftv0t21OVfVMAAABADZBrA2giCrcAMLiprrdvXddxbDoiflXSZyR9Kt/3aUkPRMTbJH1B0l35/rsk/UdEvF3SOyQdzvfvknR3RLxV0ilJ14z4+wEAAADqglwbAHKOiKrHAABjxfbZiLigx/5jkq6KiGdstyT9b0RcaPuEpIsjYjbf/2xEbLP9gqTtETHTcY6dkvZHxK78+V9KakXE347+OwMAAACqRa4NAAu44xYAhiv6tAcx09GeF+uRAwAAABK5NoCGoXALAMN1Xcfj/+Tt/5a0N2//gaTv5u1vS7pJkmxP2N5U1iABAACAMUSuDaBR+MsSAAxuyvahjuffiIjb8/YW208o+0v++/N9t0r6Z9t/LukFSR/M998m6R7bNyj7a/9Nkp4d+egBAACA+iLXBoAca9wCwJDk6269MyJOVD0WAAAAYDUh1wbQRCyVAAAAAAAAAAA1wx23AAAAAAAAAFAz3HELAAAAAAAAADVD4RYAAAAAAAAAaobCLQAAAAAAAADUDIVbAAAAAAAAAKgZCrcAAAAAAAAAUDMUbaJi2wAAABBJREFUbgEAAAAAAACgZv4fWs4Svk6m1hsAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 1728x1080 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "QGtVTxNYzYqG"
      },
      "source": [
        "if NOTIFY_STATUS: status_notify('(TensorFlow Multi-Class) Task 3 - Define and Train Models completed on ' + datetime.now().strftime('%A %B %d, %Y %I:%M:%S %p'))"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bWEbAyjvzYqI"
      },
      "source": [
        "# Task 4 - Evaluate and Optimize Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "_8DuSNAtzYqI"
      },
      "source": [
        "if NOTIFY_STATUS: status_notify('(TensorFlow Multi-Class) Task 4 - Evaluate and Optimize Models has begun on ' + datetime.now().strftime('%A %B %d, %Y %I:%M:%S %p'))"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "79R9HvH-zYqK"
      },
      "source": [
        "# Not applicable for this iteration of modeling"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fF1O3KjHzYqO"
      },
      "source": [
        "if NOTIFY_STATUS: status_notify('(TensorFlow Multi-Class) Task 4 - Evaluate and Optimize Models completed on ' + datetime.now().strftime('%A %B %d, %Y %I:%M:%S %p'))"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MJJTdK-hzYqP"
      },
      "source": [
        "# Task 5 - Finalize Model and Make Predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PzeqrJJTzYqP"
      },
      "source": [
        "if NOTIFY_STATUS: status_notify('(TensorFlow Multi-Class) Task 5 - Finalize Model and Make Predictions has begun on ' + datetime.now().strftime('%A %B %d, %Y %I:%M:%S %p'))"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PZqto6MSfQf0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bb70c164-196b-468a-d44b-94fc4507750a"
      },
      "source": [
        "final_model = nn_model_0\n",
        "final_model.summary()"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "inception_v3 (Functional)    (None, 2048)              21802784  \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 131)               268419    \n",
            "=================================================================\n",
            "Total params: 22,071,203\n",
            "Trainable params: 22,036,771\n",
            "Non-trainable params: 34,432\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SEHPWfiAzYqR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4f8da6cb-7eef-43b3-b952-283b06a31bef"
      },
      "source": [
        "print('Loading and pre-processing the testing images...')\n",
        "testing_datagen = ImageDataGenerator(**datagen_kwargs)\n",
        "testing_generator = testing_datagen.flow_from_directory(directory=TEST_DIR,\n",
        "                                                        target_size=TARGET_IMAGE_SIZE,\n",
        "                                                        shuffle=False,\n",
        "                                                        **dataflow_kwargs)\n",
        "print('Number of image batches per epoch of modeling:', len(testing_generator))"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading and pre-processing the testing images...\n",
            "Found 22688 images belonging to 131 classes.\n",
            "Number of image batches per epoch of modeling: 709\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NwIwtk3sP6r-",
        "outputId": "5d7efe59-e521-4557-9ef2-5ee378567174"
      },
      "source": [
        "final_model.evaluate(testing_generator, verbose=1)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "709/709 [==============================] - 21s 27ms/step - loss: 0.0824 - accuracy: 0.9803\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.08240656554698944, 0.9802538752555847]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "COGCI66wzYqX"
      },
      "source": [
        "if NOTIFY_STATUS: status_notify('(TensorFlow Multi-Class) Task 5 - Finalize Model and Make Predictions completed on ' + datetime.now().strftime('%A %B %d, %Y %I:%M:%S %p'))"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OeNtc6N2zYqZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7edefca6-4c13-48d4-9c8a-242323dfd363"
      },
      "source": [
        "print ('Total time for the script:',(datetime.now() - start_time_script))"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total time for the script: 0:11:36.218807\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}