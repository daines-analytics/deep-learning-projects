{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-Class Classification Deep Learning Model for [PROJECT NAME] Using Keras Version 5\n",
    "### David Lowe\n",
    "### January 14, 2020\n",
    "\n",
    "Template Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery. [https://machinelearningmastery.com/]\n",
    "\n",
    "SUMMARY: The purpose of this project is to construct a predictive model using various machine learning algorithms and to document the end-to-end steps using a template. The [PROJECT NAME] dataset is a multi-class classification situation where we are trying to predict one of several (more than two) possible outcomes.\n",
    "\n",
    "INTRODUCTION: [Sample Paragraph - This is perhaps the best known database to be found in the pattern recognition literature. Fisher's paper is a classic in the field and is referenced frequently to this day. (See Duda & Hart, for example.) The data set contains three classes of 50 instances each, where each class refers to a type of iris plant. One class is linearly separable from the other two; the latter are NOT linearly separable from each other.]\n",
    "\n",
    "ANALYSIS: [Sample Paragraph - The baseline performance of the model achieved an average accuracy score of 92.02%. After tuning the hyperparameters, the best model processed the training dataset with an accuracy of 91.07%. Furthermore, the final model processed the test dataset with an accuracy of 97.36%, which was even better than the accuracy rate from model training.]\n",
    "\n",
    "CONCLUSION: For this dataset, the model built using Keras and TensorFlow achieved a satisfactory result and should be considered for future modeling activities.\n",
    "\n",
    "Dataset Used: [PROJECT NAME] Dataset\n",
    "\n",
    "Dataset ML Model: Multi-class classification with numerical attributes\n",
    "\n",
    "Dataset Reference: [https://archive.ics.uci.edu/ml/machine-learning-databases/iris/]\n",
    "\n",
    "One potential source of performance benchmarks: [https://machinelearningmastery.com/multi-class-classification-tutorial-keras-deep-learning-library/]\n",
    "\n",
    "Any deep-learning modeling project genrally can be broken down into about six major tasks:\n",
    "\n",
    "0. Prepare Environment\n",
    "1. Load Data\n",
    "2. Define Model\n",
    "3. Fit and Evaluate Model\n",
    "4. Optimize Model\n",
    "5. Finalize Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 0. Prepare Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the warning message filter\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the random seed number for reproducible results\n",
    "seedNum = 888"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load libraries and packages\n",
    "import random\n",
    "random.seed(seedNum)\n",
    "import numpy as np\n",
    "np.random.seed(seedNum)\n",
    "import tensorflow as tf\n",
    "tf.random.set_seed(seedNum)\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "import pandas as pd\n",
    "import math\n",
    "import os\n",
    "import sys\n",
    "import shutil\n",
    "import urllib.request\n",
    "import zipfile\n",
    "import smtplib\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "from email.message import EmailMessage\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  0\n"
     ]
    }
   ],
   "source": [
    "# Begin the timer for the script processing\n",
    "startTimeScript = datetime.now()\n",
    "\n",
    "# Set up the verbose flag to print detailed messages for debugging (setting to True will activate)\n",
    "# verbose = True\n",
    "# tf.debugging.set_log_device_placement(verbose)\n",
    "\n",
    "# Set up the number of CPU cores available for multi-thread processing\n",
    "n_jobs = -1\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "\n",
    "# Set up the flag to stop sending progress emails (setting to True will send status emails!)\n",
    "notifyStatus = False\n",
    "\n",
    "# Set the number of folds for cross validation\n",
    "n_folds = 5\n",
    "\n",
    "# Set the flag for splitting the dataset\n",
    "splitDataset = True\n",
    "splitPercentage = 0.25\n",
    "\n",
    "# Set various default Keras modeling parameters\n",
    "default_loss = 'categorical_crossentropy'\n",
    "default_metrics = ['accuracy']\n",
    "default_optimizer = tf.optimizers.Adam(learning_rate=0.001)\n",
    "default_kernel_init = tf.initializers.RandomNormal(seed=seedNum)\n",
    "default_epoch = 50\n",
    "default_batch = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the email notification function\n",
    "def email_notify(msg_text):\n",
    "    sender = os.environ.get('MAIL_SENDER')\n",
    "    receiver = os.environ.get('MAIL_RECEIVER')\n",
    "    gateway = os.environ.get('SMTP_GATEWAY')\n",
    "    smtpuser = os.environ.get('SMTP_USERNAME')\n",
    "    password = os.environ.get('SMTP_PASSWORD')\n",
    "    if sender==None or receiver==None or gateway==None or smtpuser==None or password==None:\n",
    "        sys.exit(\"Incomplete email setup info. Script Processing Aborted!!!\")\n",
    "    msg = EmailMessage()\n",
    "    msg.set_content(msg_text)\n",
    "    msg['Subject'] = 'Notification from Keras Multi-Class Classification Script'\n",
    "    msg['From'] = sender\n",
    "    msg['To'] = receiver\n",
    "    server = smtplib.SMTP(gateway, 587)\n",
    "    server.starttls()\n",
    "    server.login(smtpuser, password)\n",
    "    server.send_message(msg)\n",
    "    server.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset the random number generators\n",
    "def reset_random(x):\n",
    "    random.seed(x)\n",
    "    np.random.seed(x)\n",
    "    tf.random.set_seed(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (notifyStatus): email_notify(\"Phase 0 Prepare Environment completed! \"+datetime.now().strftime('%a %B %d, %Y %I:%M:%S %p'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 1. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (notifyStatus): email_notify(\"Phase 1 Load Data has begun! \"+datetime.now().strftime('%a %B %d, %Y %I:%M:%S %p'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.a) Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>targetVar</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5.4</td>\n",
       "      <td>3.9</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.4</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.3</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4.4</td>\n",
       "      <td>2.9</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_length  sepal_width  petal_length  petal_width    targetVar\n",
       "0           5.1          3.5           1.4          0.2  Iris-setosa\n",
       "1           4.9          3.0           1.4          0.2  Iris-setosa\n",
       "2           4.7          3.2           1.3          0.2  Iris-setosa\n",
       "3           4.6          3.1           1.5          0.2  Iris-setosa\n",
       "4           5.0          3.6           1.4          0.2  Iris-setosa\n",
       "5           5.4          3.9           1.7          0.4  Iris-setosa\n",
       "6           4.6          3.4           1.4          0.3  Iris-setosa\n",
       "7           5.0          3.4           1.5          0.2  Iris-setosa\n",
       "8           4.4          2.9           1.4          0.2  Iris-setosa\n",
       "9           4.9          3.1           1.5          0.1  Iris-setosa"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_path = 'https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data'\n",
    "# dest_file = os.path.basename(dataset_path)\n",
    "# if (os.path.isfile(dest_file) == False) :\n",
    "#     print('Downloading ' + dataset_path + ' as ' + dest_file)\n",
    "#     with urllib.request.urlopen(dataset_path) as in_resp, open(dest_file, 'wb') as out_file:\n",
    "#         shutil.copyfileobj(in_resp, out_file)\n",
    "#     print(dest_file + 'downloaded!')\n",
    "#     print('Unpacking ' + dest_file)\n",
    "#     with zipfile.ZipFile(dest_file, 'r') as zip_ref:\n",
    "#         zip_ref.extractall('.')\n",
    "#     print(dest_file + 'unpacked!')\n",
    "\n",
    "# inputFile = dest_file\n",
    "# attrNames = ['attr' + str(i).zfill(2) for i in range(1,10)]\n",
    "# colNames = ['id'] + attrNames + ['target']\n",
    "colNames = ['sepal_length', 'sepal_width', 'petal_length', 'petal_width', 'targetVar']\n",
    "Xy_original = pd.read_csv(dataset_path, names=colNames, sep=',', header=None, index_col=False, na_values=['?'])\n",
    "\n",
    "# Take a peek at the dataframe after the import\n",
    "Xy_original.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 150 entries, 0 to 149\n",
      "Data columns (total 5 columns):\n",
      "sepal_length    150 non-null float64\n",
      "sepal_width     150 non-null float64\n",
      "petal_length    150 non-null float64\n",
      "petal_width     150 non-null float64\n",
      "targetVar       150 non-null object\n",
      "dtypes: float64(4), object(1)\n",
      "memory usage: 6.0+ KB\n"
     ]
    }
   ],
   "source": [
    "Xy_original.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>150.000000</td>\n",
       "      <td>150.000000</td>\n",
       "      <td>150.000000</td>\n",
       "      <td>150.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5.843333</td>\n",
       "      <td>3.054000</td>\n",
       "      <td>3.758667</td>\n",
       "      <td>1.198667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.828066</td>\n",
       "      <td>0.433594</td>\n",
       "      <td>1.764420</td>\n",
       "      <td>0.763161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>4.300000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>5.100000</td>\n",
       "      <td>2.800000</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>0.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5.800000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.350000</td>\n",
       "      <td>1.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6.400000</td>\n",
       "      <td>3.300000</td>\n",
       "      <td>5.100000</td>\n",
       "      <td>1.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>7.900000</td>\n",
       "      <td>4.400000</td>\n",
       "      <td>6.900000</td>\n",
       "      <td>2.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       sepal_length  sepal_width  petal_length  petal_width\n",
       "count    150.000000   150.000000    150.000000   150.000000\n",
       "mean       5.843333     3.054000      3.758667     1.198667\n",
       "std        0.828066     0.433594      1.764420     0.763161\n",
       "min        4.300000     2.000000      1.000000     0.100000\n",
       "25%        5.100000     2.800000      1.600000     0.300000\n",
       "50%        5.800000     3.000000      4.350000     1.300000\n",
       "75%        6.400000     3.300000      5.100000     1.800000\n",
       "max        7.900000     4.400000      6.900000     2.500000"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xy_original.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sepal_length    0\n",
      "sepal_width     0\n",
      "petal_length    0\n",
      "petal_width     0\n",
      "targetVar       0\n",
      "dtype: int64\n",
      "Total number of NaN in the dataframe:  0\n"
     ]
    }
   ],
   "source": [
    "print(Xy_original.isnull().sum())\n",
    "print('Total number of NaN in the dataframe: ', Xy_original.isnull().sum().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.b) Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>targetVar</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5.4</td>\n",
       "      <td>3.9</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.4</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.3</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4.4</td>\n",
       "      <td>2.9</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_length  sepal_width  petal_length  petal_width    targetVar\n",
       "0           5.1          3.5           1.4          0.2  Iris-setosa\n",
       "1           4.9          3.0           1.4          0.2  Iris-setosa\n",
       "2           4.7          3.2           1.3          0.2  Iris-setosa\n",
       "3           4.6          3.1           1.5          0.2  Iris-setosa\n",
       "4           5.0          3.6           1.4          0.2  Iris-setosa\n",
       "5           5.4          3.9           1.7          0.4  Iris-setosa\n",
       "6           4.6          3.4           1.4          0.3  Iris-setosa\n",
       "7           5.0          3.4           1.5          0.2  Iris-setosa\n",
       "8           4.4          2.9           1.4          0.2  Iris-setosa\n",
       "9           4.9          3.1           1.5          0.1  Iris-setosa"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Standardize the class column to the name of targetVar if required\n",
    "# Xy_original = Xy_original.rename(columns={'old_name': 'targetVar'})\n",
    "\n",
    "# Dropping features\n",
    "# Xy_original.drop(columns=['attribute_name'], inplace=True)\n",
    "\n",
    "# Impute missing values\n",
    "# Xy_original['col_name'].fillna('someValue', inplace=True)\n",
    "# Xy_original['attribute_name'].fillna(value=Xy_original['attribute_name'].median(), inplace=True)\n",
    "\n",
    "# Convert columns from one data type to another\n",
    "# Xy_original.column_name = Xy_original.column_name.astype('int')\n",
    "# Xy_original.column_name = Xy_original.column_name.astype('category')\n",
    "\n",
    "# Convert features with Y/N levels into categorical feature of 1/0\n",
    "# def reClassSomecol(target):\n",
    "#     if (target == 'Y'): return 1\n",
    "#     else: return 0\n",
    "# Xy_original['targetVar'] = Xy_original['target'].apply(reClassSomecol)\n",
    "# Xy_original.drop(columns=['target'], inplace=True)\n",
    "\n",
    "# Take a peek at the dataframe after the cleaning\n",
    "Xy_original.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 150 entries, 0 to 149\n",
      "Data columns (total 5 columns):\n",
      "sepal_length    150 non-null float64\n",
      "sepal_width     150 non-null float64\n",
      "petal_length    150 non-null float64\n",
      "petal_width     150 non-null float64\n",
      "targetVar       150 non-null object\n",
      "dtypes: float64(4), object(1)\n",
      "memory usage: 6.0+ KB\n"
     ]
    }
   ],
   "source": [
    "Xy_original.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>150.000000</td>\n",
       "      <td>150.000000</td>\n",
       "      <td>150.000000</td>\n",
       "      <td>150.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5.843333</td>\n",
       "      <td>3.054000</td>\n",
       "      <td>3.758667</td>\n",
       "      <td>1.198667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.828066</td>\n",
       "      <td>0.433594</td>\n",
       "      <td>1.764420</td>\n",
       "      <td>0.763161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>4.300000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>5.100000</td>\n",
       "      <td>2.800000</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>0.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5.800000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.350000</td>\n",
       "      <td>1.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6.400000</td>\n",
       "      <td>3.300000</td>\n",
       "      <td>5.100000</td>\n",
       "      <td>1.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>7.900000</td>\n",
       "      <td>4.400000</td>\n",
       "      <td>6.900000</td>\n",
       "      <td>2.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       sepal_length  sepal_width  petal_length  petal_width\n",
       "count    150.000000   150.000000    150.000000   150.000000\n",
       "mean       5.843333     3.054000      3.758667     1.198667\n",
       "std        0.828066     0.433594      1.764420     0.763161\n",
       "min        4.300000     2.000000      1.000000     0.100000\n",
       "25%        5.100000     2.800000      1.600000     0.300000\n",
       "50%        5.800000     3.000000      4.350000     1.300000\n",
       "75%        6.400000     3.300000      5.100000     1.800000\n",
       "max        7.900000     4.400000      6.900000     2.500000"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xy_original.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sepal_length    0\n",
      "sepal_width     0\n",
      "petal_length    0\n",
      "petal_width     0\n",
      "targetVar       0\n",
      "dtype: int64\n",
      "Total number of NaN in the dataframe:  0\n"
     ]
    }
   ],
   "source": [
    "print(Xy_original.isnull().sum())\n",
    "print('Total number of NaN in the dataframe: ', Xy_original.isnull().sum().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.c) Feature Scaling and Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use variable totCol to hold the number of columns in the dataframe\n",
    "totCol = len(Xy_original.columns)\n",
    "\n",
    "# Set up variable totAttr for the total number of attribute columns\n",
    "totAttr = totCol-1\n",
    "\n",
    "# targetCol variable indicates the column location of the target/class variable\n",
    "# If the first column, set targetCol to 1. If the last column, set targetCol to totCol\n",
    "# If (targetCol <> 1) and (targetCol <> totCol), be aware when slicing up the dataframes for visualization\n",
    "targetCol = totCol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Xy_original.shape: (150, 5) X_original.shape: (150, 4) y_original.shape: (150,)\n"
     ]
    }
   ],
   "source": [
    "# We create attribute-only and target-only datasets (X_original and y_original)\n",
    "# for various visualization and cleaning/transformation operations\n",
    "\n",
    "if targetCol == totCol:\n",
    "    X_original = Xy_original.iloc[:,0:totAttr]\n",
    "    y_original = Xy_original.iloc[:,totAttr]\n",
    "else:\n",
    "    X_original = Xy_original.iloc[:,1:totCol]\n",
    "    y_original = Xy_original.iloc[:,0]\n",
    "\n",
    "print(\"Xy_original.shape: {} X_original.shape: {} y_original.shape: {}\".format(Xy_original.shape, X_original.shape, y_original.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the number of row and columns for visualization display. dispRow * dispCol should be >= totAttr\n",
    "dispCol = 4\n",
    "if totAttr % dispCol == 0 :\n",
    "    dispRow = totAttr // dispCol\n",
    "else :\n",
    "    dispRow = (totAttr // dispCol) + 1\n",
    "    \n",
    "# Set figure width to display the data visualization plots\n",
    "fig_size = plt.rcParams[\"figure.figsize\"]\n",
    "fig_size[0] = dispCol*4\n",
    "fig_size[1] = dispRow*4\n",
    "plt.rcParams[\"figure.figsize\"] = fig_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x288 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Histograms for each attribute before pre-processing\n",
    "X_original.hist(layout=(dispRow,dispCol))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sepal_length', 'sepal_width', 'petal_length', 'petal_width']\n"
     ]
    }
   ],
   "source": [
    "tobe_transformed_cols = X_original.columns.tolist()\n",
    "# tobe_transformed_cols.remove('some_column_label')\n",
    "print(tobe_transformed_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.900681</td>\n",
       "      <td>1.032057</td>\n",
       "      <td>-1.341272</td>\n",
       "      <td>-1.312977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.143017</td>\n",
       "      <td>-0.124958</td>\n",
       "      <td>-1.341272</td>\n",
       "      <td>-1.312977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.385353</td>\n",
       "      <td>0.337848</td>\n",
       "      <td>-1.398138</td>\n",
       "      <td>-1.312977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.506521</td>\n",
       "      <td>0.106445</td>\n",
       "      <td>-1.284407</td>\n",
       "      <td>-1.312977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.021849</td>\n",
       "      <td>1.263460</td>\n",
       "      <td>-1.341272</td>\n",
       "      <td>-1.312977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>2.249683</td>\n",
       "      <td>-0.124958</td>\n",
       "      <td>1.331416</td>\n",
       "      <td>1.447956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>0.553333</td>\n",
       "      <td>0.800654</td>\n",
       "      <td>1.047087</td>\n",
       "      <td>1.579429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>0.674501</td>\n",
       "      <td>0.106445</td>\n",
       "      <td>0.990221</td>\n",
       "      <td>0.790591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>0.189830</td>\n",
       "      <td>-0.124958</td>\n",
       "      <td>0.592162</td>\n",
       "      <td>0.790591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>1.280340</td>\n",
       "      <td>0.106445</td>\n",
       "      <td>0.933356</td>\n",
       "      <td>1.185010</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>140 rows  4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal_length  sepal_width  petal_length  petal_width\n",
       "0       -0.900681     1.032057     -1.341272    -1.312977\n",
       "1       -1.143017    -0.124958     -1.341272    -1.312977\n",
       "2       -1.385353     0.337848     -1.398138    -1.312977\n",
       "3       -1.506521     0.106445     -1.284407    -1.312977\n",
       "4       -1.021849     1.263460     -1.341272    -1.312977\n",
       "..            ...          ...           ...          ...\n",
       "135      2.249683    -0.124958      1.331416     1.447956\n",
       "136      0.553333     0.800654      1.047087     1.579429\n",
       "137      0.674501     0.106445      0.990221     0.790591\n",
       "138      0.189830    -0.124958      0.592162     0.790591\n",
       "139      1.280340     0.106445      0.933356     1.185010\n",
       "\n",
       "[140 rows x 4 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply feature scaling and transformation\n",
    "# X_original = X_original.astype(float)\n",
    "scaler = preprocessing.StandardScaler()\n",
    "X_original[tobe_transformed_cols] = scaler.fit_transform(X_original[tobe_transformed_cols])\n",
    "\n",
    "X_original.head(-10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x288 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Histograms for each attribute after pre-processing\n",
    "X_original.hist(layout=(dispRow,dispCol))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform one-hot-encoding before splitting into trainig and test\n",
    "# X_original = pd.get_dummies(X_original)\n",
    "# print(X_original.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.d) Splitting Data into Training and Test Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "# Encode class values as integers and perform one-hot-encoding\n",
    "# y_encoded = y_original.to_numpy()\n",
    "encoder = preprocessing.LabelEncoder()\n",
    "encoder.fit(y_original)\n",
    "y_transformed = encoder.transform(y_original)\n",
    "y_encoded = tf.keras.utils.to_categorical(y_transformed)\n",
    "print(y_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train.shape: (112, 4) X_train.type: <class 'numpy.ndarray'>\n",
      "y_train.shape: (112, 3) y_train.type: <class 'numpy.ndarray'>\n",
      "X_test.shape: (38, 4) X_test.type: <class 'numpy.ndarray'>\n",
      "y_test.shape: (38, 3) y_test.type: <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "X_encoded = X_original.to_numpy()\n",
    "if (splitDataset):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_encoded, y_encoded, test_size=splitPercentage, \n",
    "                                                        stratify=y_encoded, random_state=seedNum)\n",
    "else:\n",
    "    X_train, y_train = X_encoded, y_encoded\n",
    "    X_test, y_test = X_encoded, y_encoded\n",
    "print(\"X_train.shape: {} X_train.type: {}\".format(X_train.shape, type(X_train)))\n",
    "print(\"y_train.shape: {} y_train.type: {}\".format(y_train.shape, type(y_train)))\n",
    "print(\"X_test.shape: {} X_test.type: {}\".format(X_test.shape, type(X_test)))\n",
    "print(\"y_test.shape: {} y_test.type: {}\".format(y_test.shape, type(y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (notifyStatus): email_notify(\"Phase 1 Load Data completed! \"+datetime.now().strftime('%a %B %d, %Y %I:%M:%S %p'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 2. Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (notifyStatus): email_notify(\"Phase 2 Define Model has begun! \"+datetime.now().strftime('%a %B %d, %Y %I:%M:%S %p'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Keras model required for KerasClassifier\n",
    "def create_default_model():\n",
    "    default_model = Sequential()\n",
    "    default_model.add(Dense(10, input_shape=(4,), activation='relu', kernel_initializer=default_kernel_init))\n",
    "    default_model.add(Dense(3, activation='softmax', kernel_initializer=default_kernel_init))\n",
    "    default_model.compile(loss=default_loss, optimizer=default_optimizer, metrics=default_metrics)\n",
    "    return default_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (notifyStatus): email_notify(\"Phase 2 Define Model completed! \"+datetime.now().strftime('%a %B %d, %Y %I:%M:%S %p'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 3. Fit and Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (notifyStatus): email_notify(\"Phase 3 Fit and Evaluate Model has begun! \"+datetime.now().strftime('%a %B %d, %Y %I:%M:%S %p'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating results using the metrics of ['accuracy']\n",
      "All cross-Validate results: [0.78260869 0.65217394 0.77272725 0.81818181 0.81818181]\n",
      "Baseline results [mean (std)]: 76.88% (6.11%)\n",
      "Total time for performing cross-validation of the default model: 0:00:09.829099\n"
     ]
    }
   ],
   "source": [
    "startTimeModule = datetime.now()\n",
    "\n",
    "# Initialize the default model\n",
    "reset_random(seedNum)\n",
    "cv_model = KerasClassifier(build_fn=create_default_model, epochs=default_epoch, batch_size=default_batch, verbose=0)\n",
    "# Fit and evaluate the Keras model using k-fold cross validation\n",
    "kfold = KFold(n_splits=n_folds, shuffle=True, random_state=seedNum)\n",
    "results = cross_val_score(cv_model, X_train, y_train, cv=kfold)\n",
    "print('Generating results using the metrics of', default_metrics)\n",
    "print('All cross-Validate results:', results)\n",
    "print('Baseline results [mean (std)]: %.2f%% (%.2f%%)' % (results.mean()*100, results.std()*100))\n",
    "print('Total time for performing cross-validation of the default model:', (datetime.now() - startTimeModule))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 112 samples, validate on 38 samples\n",
      "Epoch 1/50\n",
      "112/112 [==============================] - 1s 9ms/sample - loss: 1.0941 - accuracy: 0.5714 - val_loss: 1.0823 - val_accuracy: 0.9211\n",
      "Epoch 2/50\n",
      "112/112 [==============================] - 0s 357us/sample - loss: 1.0789 - accuracy: 0.7946 - val_loss: 1.0607 - val_accuracy: 0.8947\n",
      "Epoch 3/50\n",
      "112/112 [==============================] - 0s 366us/sample - loss: 1.0539 - accuracy: 0.8036 - val_loss: 1.0284 - val_accuracy: 0.8684\n",
      "Epoch 4/50\n",
      "112/112 [==============================] - 0s 422us/sample - loss: 1.0225 - accuracy: 0.7857 - val_loss: 0.9857 - val_accuracy: 0.8421\n",
      "Epoch 5/50\n",
      "112/112 [==============================] - 0s 345us/sample - loss: 0.9773 - accuracy: 0.7500 - val_loss: 0.9350 - val_accuracy: 0.7895\n",
      "Epoch 6/50\n",
      "112/112 [==============================] - 0s 347us/sample - loss: 0.9256 - accuracy: 0.7321 - val_loss: 0.8780 - val_accuracy: 0.7632\n",
      "Epoch 7/50\n",
      "112/112 [==============================] - 0s 348us/sample - loss: 0.8705 - accuracy: 0.7143 - val_loss: 0.8180 - val_accuracy: 0.7632\n",
      "Epoch 8/50\n",
      "112/112 [==============================] - 0s 357us/sample - loss: 0.8153 - accuracy: 0.6875 - val_loss: 0.7578 - val_accuracy: 0.7368\n",
      "Epoch 9/50\n",
      "112/112 [==============================] - 0s 348us/sample - loss: 0.7567 - accuracy: 0.6875 - val_loss: 0.7014 - val_accuracy: 0.7368\n",
      "Epoch 10/50\n",
      "112/112 [==============================] - 0s 345us/sample - loss: 0.7055 - accuracy: 0.6786 - val_loss: 0.6502 - val_accuracy: 0.7105\n",
      "Epoch 11/50\n",
      "112/112 [==============================] - 0s 332us/sample - loss: 0.6584 - accuracy: 0.6786 - val_loss: 0.6064 - val_accuracy: 0.7105\n",
      "Epoch 12/50\n",
      "112/112 [==============================] - 0s 351us/sample - loss: 0.6204 - accuracy: 0.6786 - val_loss: 0.5695 - val_accuracy: 0.7105\n",
      "Epoch 13/50\n",
      "112/112 [==============================] - 0s 344us/sample - loss: 0.5871 - accuracy: 0.6875 - val_loss: 0.5394 - val_accuracy: 0.7105\n",
      "Epoch 14/50\n",
      "112/112 [==============================] - 0s 347us/sample - loss: 0.5611 - accuracy: 0.6964 - val_loss: 0.5143 - val_accuracy: 0.7105\n",
      "Epoch 15/50\n",
      "112/112 [==============================] - 0s 347us/sample - loss: 0.5388 - accuracy: 0.6964 - val_loss: 0.4938 - val_accuracy: 0.7632\n",
      "Epoch 16/50\n",
      "112/112 [==============================] - 0s 349us/sample - loss: 0.5210 - accuracy: 0.7143 - val_loss: 0.4760 - val_accuracy: 0.7895\n",
      "Epoch 17/50\n",
      "112/112 [==============================] - 0s 350us/sample - loss: 0.5050 - accuracy: 0.7232 - val_loss: 0.4607 - val_accuracy: 0.7895\n",
      "Epoch 18/50\n",
      "112/112 [==============================] - 0s 338us/sample - loss: 0.4908 - accuracy: 0.7321 - val_loss: 0.4472 - val_accuracy: 0.7895\n",
      "Epoch 19/50\n",
      "112/112 [==============================] - 0s 326us/sample - loss: 0.4793 - accuracy: 0.7411 - val_loss: 0.4351 - val_accuracy: 0.8421\n",
      "Epoch 20/50\n",
      "112/112 [==============================] - 0s 375us/sample - loss: 0.4676 - accuracy: 0.7768 - val_loss: 0.4236 - val_accuracy: 0.8421\n",
      "Epoch 21/50\n",
      "112/112 [==============================] - 0s 343us/sample - loss: 0.4572 - accuracy: 0.7768 - val_loss: 0.4133 - val_accuracy: 0.8421\n",
      "Epoch 22/50\n",
      "112/112 [==============================] - 0s 351us/sample - loss: 0.4480 - accuracy: 0.7946 - val_loss: 0.4034 - val_accuracy: 0.8684\n",
      "Epoch 23/50\n",
      "112/112 [==============================] - 0s 346us/sample - loss: 0.4393 - accuracy: 0.7946 - val_loss: 0.3941 - val_accuracy: 0.8684\n",
      "Epoch 24/50\n",
      "112/112 [==============================] - 0s 344us/sample - loss: 0.4304 - accuracy: 0.8036 - val_loss: 0.3850 - val_accuracy: 0.8684\n",
      "Epoch 25/50\n",
      "112/112 [==============================] - 0s 338us/sample - loss: 0.4224 - accuracy: 0.8125 - val_loss: 0.3760 - val_accuracy: 0.8684\n",
      "Epoch 26/50\n",
      "112/112 [==============================] - 0s 395us/sample - loss: 0.4143 - accuracy: 0.8125 - val_loss: 0.3672 - val_accuracy: 0.8684\n",
      "Epoch 27/50\n",
      "112/112 [==============================] - 0s 360us/sample - loss: 0.4067 - accuracy: 0.8125 - val_loss: 0.3589 - val_accuracy: 0.8947\n",
      "Epoch 28/50\n",
      "112/112 [==============================] - 0s 419us/sample - loss: 0.3989 - accuracy: 0.8125 - val_loss: 0.3504 - val_accuracy: 0.8947\n",
      "Epoch 29/50\n",
      "112/112 [==============================] - 0s 356us/sample - loss: 0.3916 - accuracy: 0.8214 - val_loss: 0.3423 - val_accuracy: 0.8947\n",
      "Epoch 30/50\n",
      "112/112 [==============================] - 0s 350us/sample - loss: 0.3848 - accuracy: 0.8393 - val_loss: 0.3342 - val_accuracy: 0.9211\n",
      "Epoch 31/50\n",
      "112/112 [==============================] - 0s 389us/sample - loss: 0.3776 - accuracy: 0.8393 - val_loss: 0.3265 - val_accuracy: 0.9211\n",
      "Epoch 32/50\n",
      "112/112 [==============================] - 0s 351us/sample - loss: 0.3708 - accuracy: 0.8393 - val_loss: 0.3193 - val_accuracy: 0.9211\n",
      "Epoch 33/50\n",
      "112/112 [==============================] - 0s 360us/sample - loss: 0.3645 - accuracy: 0.8482 - val_loss: 0.3121 - val_accuracy: 0.9474\n",
      "Epoch 34/50\n",
      "112/112 [==============================] - 0s 336us/sample - loss: 0.3583 - accuracy: 0.8482 - val_loss: 0.3047 - val_accuracy: 0.9474\n",
      "Epoch 35/50\n",
      "112/112 [==============================] - 0s 332us/sample - loss: 0.3524 - accuracy: 0.8482 - val_loss: 0.2979 - val_accuracy: 0.9474\n",
      "Epoch 36/50\n",
      "112/112 [==============================] - 0s 353us/sample - loss: 0.3456 - accuracy: 0.8482 - val_loss: 0.2914 - val_accuracy: 0.9474\n",
      "Epoch 37/50\n",
      "112/112 [==============================] - 0s 358us/sample - loss: 0.3400 - accuracy: 0.8482 - val_loss: 0.2850 - val_accuracy: 0.9474\n",
      "Epoch 38/50\n",
      "112/112 [==============================] - 0s 350us/sample - loss: 0.3344 - accuracy: 0.8661 - val_loss: 0.2788 - val_accuracy: 0.9737\n",
      "Epoch 39/50\n",
      "112/112 [==============================] - 0s 347us/sample - loss: 0.3289 - accuracy: 0.8661 - val_loss: 0.2729 - val_accuracy: 0.9737\n",
      "Epoch 40/50\n",
      "112/112 [==============================] - 0s 336us/sample - loss: 0.3233 - accuracy: 0.8661 - val_loss: 0.2671 - val_accuracy: 0.9737\n",
      "Epoch 41/50\n",
      "112/112 [==============================] - 0s 337us/sample - loss: 0.3181 - accuracy: 0.8661 - val_loss: 0.2615 - val_accuracy: 0.9737\n",
      "Epoch 42/50\n",
      "112/112 [==============================] - 0s 344us/sample - loss: 0.3131 - accuracy: 0.8750 - val_loss: 0.2561 - val_accuracy: 0.9737\n",
      "Epoch 43/50\n",
      "112/112 [==============================] - 0s 356us/sample - loss: 0.3078 - accuracy: 0.8750 - val_loss: 0.2512 - val_accuracy: 0.9737\n",
      "Epoch 44/50\n",
      "112/112 [==============================] - 0s 429us/sample - loss: 0.3029 - accuracy: 0.8750 - val_loss: 0.2465 - val_accuracy: 0.9737\n",
      "Epoch 45/50\n",
      "112/112 [==============================] - 0s 339us/sample - loss: 0.2986 - accuracy: 0.8839 - val_loss: 0.2416 - val_accuracy: 0.9737\n",
      "Epoch 46/50\n",
      "112/112 [==============================] - 0s 344us/sample - loss: 0.2937 - accuracy: 0.8839 - val_loss: 0.2371 - val_accuracy: 0.9737\n",
      "Epoch 47/50\n",
      "112/112 [==============================] - 0s 349us/sample - loss: 0.2889 - accuracy: 0.8839 - val_loss: 0.2329 - val_accuracy: 0.9737\n",
      "Epoch 48/50\n",
      "112/112 [==============================] - 0s 333us/sample - loss: 0.2845 - accuracy: 0.8839 - val_loss: 0.2293 - val_accuracy: 0.9737\n",
      "Epoch 49/50\n",
      "112/112 [==============================] - 0s 415us/sample - loss: 0.2803 - accuracy: 0.8839 - val_loss: 0.2254 - val_accuracy: 0.9737\n",
      "Epoch 50/50\n",
      "112/112 [==============================] - 0s 349us/sample - loss: 0.2756 - accuracy: 0.8839 - val_loss: 0.2222 - val_accuracy: 0.9737\n",
      "Total time for performing cross-validation of the default model: 0:00:03.321971\n"
     ]
    }
   ],
   "source": [
    "startTimeModule = datetime.now()\n",
    "\n",
    "# Initialize the baseline model\n",
    "reset_random(seedNum)\n",
    "baseline_model = create_default_model()\n",
    "baseline_hist = baseline_model.fit(X_train, y_train, epochs=default_epoch, batch_size=default_batch,\n",
    "                                   validation_data=(X_test, y_test), verbose=1)\n",
    "print('Total time for performing cross-validation of the default model:', (datetime.now() - startTimeModule))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])\n"
     ]
    }
   ],
   "source": [
    "# List all data points in the baseline model training history\n",
    "print(baseline_hist.history.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x864 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Summarize model training hisotry for accuracy and loss\n",
    "fig, axs = plt.subplots(2, 1, figsize=(12,12))\n",
    "plt.subplot(211)\n",
    "plt.plot(baseline_hist.history['accuracy'], color='blue', label='train')\n",
    "plt.plot(baseline_hist.history['val_accuracy'], color='red', label='test')\n",
    "plt.title('Baseline Model Training Performance (Accuracy)')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper right')\n",
    "plt.subplot(212)\n",
    "plt.plot(baseline_hist.history['loss'], color='blue', label='train')\n",
    "plt.plot(baseline_hist.history['val_loss'], color='red', label='test')\n",
    "plt.title('Baseline Model Training Performance (Loss)')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (notifyStatus): email_notify(\"Phase 3 Fit and Evaluate Model completed! \"+datetime.now().strftime('%a %B %d, %Y %I:%M:%S %p'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 4. Optimize Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (notifyStatus): email_notify(\"Phase 4 Optimize Model has begun! \"+datetime.now().strftime('%a %B %d, %Y %I:%M:%S %p'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Keras model required for KerasClassifier\n",
    "def create_customized_model(optimizer, kernel_init):\n",
    "    customized_model = Sequential()\n",
    "    customized_model.add(Dense(10, input_shape=(4,), activation='relu', kernel_initializer=kernel_init))\n",
    "    customized_model.add(Dense(3, activation='softmax', kernel_initializer=kernel_init))\n",
    "    customized_model.compile(loss=default_loss, optimizer=optimizer, metrics=default_metrics)\n",
    "    return customized_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizer candidate #1 has the object ID of <tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7fe1d64eb110>\n",
      "Optimizer candidate #2 has the object ID of <tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7fe1d6493510>\n",
      "Optimizer candidate #3 has the object ID of <tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7fe1d6493d50>\n",
      "Initializer candidate #1 has the object ID of <tensorflow.python.ops.init_ops_v2.RandomNormal object at 0x7fe1d64f45d0>\n",
      "Initializer candidate #2 has the object ID of <tensorflow.python.ops.init_ops_v2.Orthogonal object at 0x7fe188299b50>\n",
      "Initializer candidate #2 has the object ID of <tensorflow.python.ops.init_ops_v2.GlorotNormal object at 0x7fe1882995d0>\n",
      "Fitting 5 folds for each of 27 candidates, totalling 135 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   8 tasks      | elapsed:   14.9s\n",
      "[Parallel(n_jobs=-1)]: Done 104 tasks      | elapsed:   43.7s\n",
      "[Parallel(n_jobs=-1)]: Done 135 out of 135 | elapsed:   51.4s finished\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/model_selection/_search.py:814: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.830357 using {'batch_size': 16, 'epochs': 50, 'kernel_init': <tensorflow.python.ops.init_ops_v2.GlorotNormal object at 0x7fe1882995d0>, 'optimizer': <tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7fe1d64eb110>}\n",
      "0.741071 (0.223720) with: {'batch_size': 16, 'epochs': 50, 'kernel_init': <tensorflow.python.ops.init_ops_v2.RandomNormal object at 0x7fe1d64f45d0>, 'optimizer': <tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7fe1d64eb110>}\n",
      "0.678571 (0.194815) with: {'batch_size': 16, 'epochs': 50, 'kernel_init': <tensorflow.python.ops.init_ops_v2.RandomNormal object at 0x7fe1d64f45d0>, 'optimizer': <tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7fe1d6493510>}\n",
      "0.705357 (0.195547) with: {'batch_size': 16, 'epochs': 50, 'kernel_init': <tensorflow.python.ops.init_ops_v2.RandomNormal object at 0x7fe1d64f45d0>, 'optimizer': <tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7fe1d6493d50>}\n",
      "0.794643 (0.101170) with: {'batch_size': 16, 'epochs': 50, 'kernel_init': <tensorflow.python.ops.init_ops_v2.Orthogonal object at 0x7fe188299b50>, 'optimizer': <tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7fe1d64eb110>}\n",
      "0.714286 (0.087683) with: {'batch_size': 16, 'epochs': 50, 'kernel_init': <tensorflow.python.ops.init_ops_v2.Orthogonal object at 0x7fe188299b50>, 'optimizer': <tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7fe1d6493510>}\n",
      "0.383929 (0.047242) with: {'batch_size': 16, 'epochs': 50, 'kernel_init': <tensorflow.python.ops.init_ops_v2.Orthogonal object at 0x7fe188299b50>, 'optimizer': <tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7fe1d6493d50>}\n",
      "0.830357 (0.122328) with: {'batch_size': 16, 'epochs': 50, 'kernel_init': <tensorflow.python.ops.init_ops_v2.GlorotNormal object at 0x7fe1882995d0>, 'optimizer': <tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7fe1d64eb110>}\n",
      "0.794643 (0.131906) with: {'batch_size': 16, 'epochs': 50, 'kernel_init': <tensorflow.python.ops.init_ops_v2.GlorotNormal object at 0x7fe1882995d0>, 'optimizer': <tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7fe1d6493510>}\n",
      "0.455357 (0.130629) with: {'batch_size': 16, 'epochs': 50, 'kernel_init': <tensorflow.python.ops.init_ops_v2.GlorotNormal object at 0x7fe1882995d0>, 'optimizer': <tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7fe1d6493d50>}\n",
      "0.678571 (0.194815) with: {'batch_size': 32, 'epochs': 50, 'kernel_init': <tensorflow.python.ops.init_ops_v2.RandomNormal object at 0x7fe1d64f45d0>, 'optimizer': <tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7fe1d64eb110>}\n",
      "0.723214 (0.216378) with: {'batch_size': 32, 'epochs': 50, 'kernel_init': <tensorflow.python.ops.init_ops_v2.RandomNormal object at 0x7fe1d64f45d0>, 'optimizer': <tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7fe1d6493510>}\n",
      "0.669643 (0.177029) with: {'batch_size': 32, 'epochs': 50, 'kernel_init': <tensorflow.python.ops.init_ops_v2.RandomNormal object at 0x7fe1d64f45d0>, 'optimizer': <tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7fe1d6493d50>}\n",
      "0.732143 (0.080902) with: {'batch_size': 32, 'epochs': 50, 'kernel_init': <tensorflow.python.ops.init_ops_v2.Orthogonal object at 0x7fe188299b50>, 'optimizer': <tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7fe1d64eb110>}\n",
      "0.616071 (0.102075) with: {'batch_size': 32, 'epochs': 50, 'kernel_init': <tensorflow.python.ops.init_ops_v2.Orthogonal object at 0x7fe188299b50>, 'optimizer': <tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7fe1d6493510>}\n",
      "0.357143 (0.067919) with: {'batch_size': 32, 'epochs': 50, 'kernel_init': <tensorflow.python.ops.init_ops_v2.Orthogonal object at 0x7fe188299b50>, 'optimizer': <tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7fe1d6493d50>}\n",
      "0.803571 (0.129087) with: {'batch_size': 32, 'epochs': 50, 'kernel_init': <tensorflow.python.ops.init_ops_v2.GlorotNormal object at 0x7fe1882995d0>, 'optimizer': <tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7fe1d64eb110>}\n",
      "0.642857 (0.127234) with: {'batch_size': 32, 'epochs': 50, 'kernel_init': <tensorflow.python.ops.init_ops_v2.GlorotNormal object at 0x7fe1882995d0>, 'optimizer': <tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7fe1d6493510>}\n",
      "0.428571 (0.125729) with: {'batch_size': 32, 'epochs': 50, 'kernel_init': <tensorflow.python.ops.init_ops_v2.GlorotNormal object at 0x7fe1882995d0>, 'optimizer': <tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7fe1d6493d50>}\n",
      "0.714286 (0.214632) with: {'batch_size': 64, 'epochs': 50, 'kernel_init': <tensorflow.python.ops.init_ops_v2.RandomNormal object at 0x7fe1d64f45d0>, 'optimizer': <tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7fe1d64eb110>}\n",
      "0.723214 (0.209120) with: {'batch_size': 64, 'epochs': 50, 'kernel_init': <tensorflow.python.ops.init_ops_v2.RandomNormal object at 0x7fe1d64f45d0>, 'optimizer': <tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7fe1d6493510>}\n",
      "0.607143 (0.149488) with: {'batch_size': 64, 'epochs': 50, 'kernel_init': <tensorflow.python.ops.init_ops_v2.RandomNormal object at 0x7fe1d64f45d0>, 'optimizer': <tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7fe1d6493d50>}\n",
      "0.696429 (0.119357) with: {'batch_size': 64, 'epochs': 50, 'kernel_init': <tensorflow.python.ops.init_ops_v2.Orthogonal object at 0x7fe188299b50>, 'optimizer': <tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7fe1d64eb110>}\n",
      "0.446429 (0.096739) with: {'batch_size': 64, 'epochs': 50, 'kernel_init': <tensorflow.python.ops.init_ops_v2.Orthogonal object at 0x7fe188299b50>, 'optimizer': <tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7fe1d6493510>}\n",
      "0.330357 (0.070922) with: {'batch_size': 64, 'epochs': 50, 'kernel_init': <tensorflow.python.ops.init_ops_v2.Orthogonal object at 0x7fe188299b50>, 'optimizer': <tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7fe1d6493d50>}\n",
      "0.767857 (0.127684) with: {'batch_size': 64, 'epochs': 50, 'kernel_init': <tensorflow.python.ops.init_ops_v2.GlorotNormal object at 0x7fe1882995d0>, 'optimizer': <tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7fe1d64eb110>}\n",
      "0.455357 (0.130629) with: {'batch_size': 64, 'epochs': 50, 'kernel_init': <tensorflow.python.ops.init_ops_v2.GlorotNormal object at 0x7fe1882995d0>, 'optimizer': <tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7fe1d6493510>}\n",
      "0.428571 (0.125729) with: {'batch_size': 64, 'epochs': 50, 'kernel_init': <tensorflow.python.ops.init_ops_v2.GlorotNormal object at 0x7fe1882995d0>, 'optimizer': <tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7fe1d6493d50>}\n",
      "Total time for performing grid-search of the best parameters: 0:00:53.298065\n"
     ]
    }
   ],
   "source": [
    "# Perform model hyperparameter tuning via SciKit Learn's GridSearchCV\n",
    "startTimeModule = datetime.now()\n",
    "\n",
    "# Perform grid search using different epochs, batch sizes, and optimizers\n",
    "optz_1 = tf.optimizers.Adam(learning_rate=0.0010)\n",
    "optz_2 = tf.optimizers.Adam(learning_rate=0.0005)\n",
    "optz_3 = tf.optimizers.Adam(learning_rate=0.0001)\n",
    "optimizer_grid = [optz_1, optz_2, optz_3]\n",
    "print('Optimizer candidate #1 has the object ID of', optz_1)\n",
    "print('Optimizer candidate #2 has the object ID of', optz_2)\n",
    "print('Optimizer candidate #3 has the object ID of', optz_3)\n",
    "\n",
    "init_1 = tf.initializers.RandomNormal(seed=seedNum)\n",
    "init_2 = tf.initializers.Orthogonal(seed=seedNum)\n",
    "init_3 = tf.initializers.GlorotNormal(seed=seedNum)\n",
    "init_grid = [init_1, init_2, init_3]\n",
    "print('Initializer candidate #1 has the object ID of', init_1)\n",
    "print('Initializer candidate #2 has the object ID of', init_2)\n",
    "print('Initializer candidate #2 has the object ID of', init_3)\n",
    "\n",
    "epoch_grid = [50]\n",
    "batch_grid = [16, 32, 64]\n",
    "\n",
    "# Create grid model\n",
    "param_grid = dict(optimizer=optimizer_grid, kernel_init=init_grid, epochs=epoch_grid, batch_size=batch_grid)\n",
    "reset_random(seedNum)\n",
    "grid_model = KerasClassifier(build_fn=create_customized_model, verbose=0)\n",
    "grid = GridSearchCV(estimator=grid_model, param_grid=param_grid, cv=n_folds, n_jobs=n_jobs, verbose=3)\n",
    "# n_iter = int(len(optimizer_grid) * len(init_grid) * len(epoch_grid) * len(batch_grid) * 0.5)\n",
    "# grid = RandomizedSearchCV(estimator=grid_model, param_distributions=param_grid, n_iter=n_iter, cv=n_folds, n_jobs=n_jobs, verbose=3)\n",
    "grid_result = grid.fit(X_train, y_train)\n",
    "\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "\tprint(\"%f (%f) with: %r\" % (mean, stdev, param))\n",
    "print('Total time for performing grid-search of the best parameters:', (datetime.now() - startTimeModule))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_optimizer = grid_result.best_params_[\"optimizer\"]\n",
    "best_kernel_init = grid_result.best_params_[\"kernel_init\"]\n",
    "best_epoch = grid_result.best_params_[\"epochs\"]\n",
    "best_batch = grid_result.best_params_[\"batch_size\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizer candidate #1 has the object ID of <tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7fe1d6395990>\n",
      "Optimizer candidate #2 has the object ID of <tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7fe1d6395290>\n",
      "Optimizer candidate #3 has the object ID of <tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7fe1d6395cd0>\n",
      "Initializer candidate #1 has the object ID of <tensorflow.python.ops.init_ops_v2.RandomNormal object at 0x7fe1b03bde50>\n",
      "Initializer candidate #2 has the object ID of <tensorflow.python.ops.init_ops_v2.Orthogonal object at 0x7fe1b03bd4d0>\n",
      "Initializer candidate #2 has the object ID of <tensorflow.python.ops.init_ops_v2.GlorotNormal object at 0x7fe1b03bd290>\n",
      "\n",
      "Forming the grid-search model #0 using: optimizer=<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7fe1d6395990>, kernel=<tensorflow.python.ops.init_ops_v2.RandomNormal object at 0x7fe1b03bde50>, epochs=50, batch_size=32\n",
      "Train on 112 samples, validate on 38 samples\n",
      "Epoch 1/50\n",
      "112/112 [==============================] - 1s 11ms/sample - loss: 1.0956 - accuracy: 0.5179 - val_loss: 1.0913 - val_accuracy: 0.8947\n",
      "Epoch 2/50\n",
      "112/112 [==============================] - 0s 335us/sample - loss: 1.0922 - accuracy: 0.6875 - val_loss: 1.0875 - val_accuracy: 0.9211\n",
      "Epoch 3/50\n",
      "112/112 [==============================] - 0s 350us/sample - loss: 1.0885 - accuracy: 0.7500 - val_loss: 1.0834 - val_accuracy: 0.8947\n",
      "Epoch 4/50\n",
      "112/112 [==============================] - 0s 338us/sample - loss: 1.0847 - accuracy: 0.7679 - val_loss: 1.0788 - val_accuracy: 0.8947\n",
      "Epoch 5/50\n",
      "112/112 [==============================] - 0s 362us/sample - loss: 1.0800 - accuracy: 0.7946 - val_loss: 1.0739 - val_accuracy: 0.9211\n",
      "Epoch 6/50\n",
      "112/112 [==============================] - 0s 355us/sample - loss: 1.0750 - accuracy: 0.8036 - val_loss: 1.0685 - val_accuracy: 0.9211\n",
      "Epoch 7/50\n",
      "112/112 [==============================] - 0s 316us/sample - loss: 1.0696 - accuracy: 0.7946 - val_loss: 1.0626 - val_accuracy: 0.8684\n",
      "Epoch 8/50\n",
      "112/112 [==============================] - 0s 342us/sample - loss: 1.0638 - accuracy: 0.7946 - val_loss: 1.0560 - val_accuracy: 0.8684\n",
      "Epoch 9/50\n",
      "112/112 [==============================] - 0s 325us/sample - loss: 1.0569 - accuracy: 0.7946 - val_loss: 1.0487 - val_accuracy: 0.8684\n",
      "Epoch 10/50\n",
      "112/112 [==============================] - 0s 331us/sample - loss: 1.0499 - accuracy: 0.7946 - val_loss: 1.0407 - val_accuracy: 0.8684\n",
      "Epoch 11/50\n",
      "112/112 [==============================] - 0s 337us/sample - loss: 1.0418 - accuracy: 0.7768 - val_loss: 1.0319 - val_accuracy: 0.8421\n",
      "Epoch 12/50\n",
      "112/112 [==============================] - 0s 329us/sample - loss: 1.0334 - accuracy: 0.7768 - val_loss: 1.0224 - val_accuracy: 0.8421\n",
      "Epoch 13/50\n",
      "112/112 [==============================] - 0s 337us/sample - loss: 1.0239 - accuracy: 0.7589 - val_loss: 1.0122 - val_accuracy: 0.8421\n",
      "Epoch 14/50\n",
      "112/112 [==============================] - 0s 353us/sample - loss: 1.0140 - accuracy: 0.7411 - val_loss: 1.0012 - val_accuracy: 0.8421\n",
      "Epoch 15/50\n",
      "112/112 [==============================] - 0s 363us/sample - loss: 1.0032 - accuracy: 0.7321 - val_loss: 0.9896 - val_accuracy: 0.8421\n",
      "Epoch 16/50\n",
      "112/112 [==============================] - 0s 337us/sample - loss: 0.9921 - accuracy: 0.7321 - val_loss: 0.9772 - val_accuracy: 0.8421\n",
      "Epoch 17/50\n",
      "112/112 [==============================] - 0s 351us/sample - loss: 0.9797 - accuracy: 0.7411 - val_loss: 0.9642 - val_accuracy: 0.8158\n",
      "Epoch 18/50\n",
      "112/112 [==============================] - 0s 349us/sample - loss: 0.9674 - accuracy: 0.7321 - val_loss: 0.9505 - val_accuracy: 0.7632\n",
      "Epoch 19/50\n",
      "112/112 [==============================] - 0s 351us/sample - loss: 0.9533 - accuracy: 0.7232 - val_loss: 0.9364 - val_accuracy: 0.7632\n",
      "Epoch 20/50\n",
      "112/112 [==============================] - 0s 495us/sample - loss: 0.9401 - accuracy: 0.7143 - val_loss: 0.9213 - val_accuracy: 0.7632\n",
      "Epoch 21/50\n",
      "112/112 [==============================] - 0s 334us/sample - loss: 0.9258 - accuracy: 0.7054 - val_loss: 0.9057 - val_accuracy: 0.7632\n",
      "Epoch 22/50\n",
      "112/112 [==============================] - 0s 345us/sample - loss: 0.9102 - accuracy: 0.7054 - val_loss: 0.8897 - val_accuracy: 0.7632\n",
      "Epoch 23/50\n",
      "112/112 [==============================] - 0s 335us/sample - loss: 0.8946 - accuracy: 0.7054 - val_loss: 0.8731 - val_accuracy: 0.7632\n",
      "Epoch 24/50\n",
      "112/112 [==============================] - 0s 341us/sample - loss: 0.8787 - accuracy: 0.6964 - val_loss: 0.8559 - val_accuracy: 0.7632\n",
      "Epoch 25/50\n",
      "112/112 [==============================] - 0s 349us/sample - loss: 0.8615 - accuracy: 0.6964 - val_loss: 0.8384 - val_accuracy: 0.7632\n",
      "Epoch 26/50\n",
      "112/112 [==============================] - 0s 367us/sample - loss: 0.8457 - accuracy: 0.6964 - val_loss: 0.8204 - val_accuracy: 0.7368\n",
      "Epoch 27/50\n",
      "112/112 [==============================] - 0s 343us/sample - loss: 0.8276 - accuracy: 0.6964 - val_loss: 0.8026 - val_accuracy: 0.7105\n",
      "Epoch 28/50\n",
      "112/112 [==============================] - 0s 341us/sample - loss: 0.8111 - accuracy: 0.6875 - val_loss: 0.7845 - val_accuracy: 0.7105\n",
      "Epoch 29/50\n",
      "112/112 [==============================] - 0s 345us/sample - loss: 0.7940 - accuracy: 0.6786 - val_loss: 0.7666 - val_accuracy: 0.7105\n",
      "Epoch 30/50\n",
      "112/112 [==============================] - 0s 334us/sample - loss: 0.7771 - accuracy: 0.6786 - val_loss: 0.7491 - val_accuracy: 0.7105\n",
      "Epoch 31/50\n",
      "112/112 [==============================] - 0s 336us/sample - loss: 0.7604 - accuracy: 0.6786 - val_loss: 0.7321 - val_accuracy: 0.7105\n",
      "Epoch 32/50\n",
      "112/112 [==============================] - 0s 341us/sample - loss: 0.7441 - accuracy: 0.6786 - val_loss: 0.7156 - val_accuracy: 0.7105\n",
      "Epoch 33/50\n",
      "112/112 [==============================] - 0s 331us/sample - loss: 0.7283 - accuracy: 0.6786 - val_loss: 0.6996 - val_accuracy: 0.7105\n",
      "Epoch 34/50\n",
      "112/112 [==============================] - 0s 342us/sample - loss: 0.7139 - accuracy: 0.6786 - val_loss: 0.6838 - val_accuracy: 0.7105\n",
      "Epoch 35/50\n",
      "112/112 [==============================] - 0s 344us/sample - loss: 0.6986 - accuracy: 0.6786 - val_loss: 0.6689 - val_accuracy: 0.7105\n",
      "Epoch 36/50\n",
      "112/112 [==============================] - 0s 337us/sample - loss: 0.6850 - accuracy: 0.6786 - val_loss: 0.6544 - val_accuracy: 0.7105\n",
      "Epoch 37/50\n",
      "112/112 [==============================] - 0s 345us/sample - loss: 0.6715 - accuracy: 0.6786 - val_loss: 0.6406 - val_accuracy: 0.7105\n",
      "Epoch 38/50\n",
      "112/112 [==============================] - 0s 334us/sample - loss: 0.6587 - accuracy: 0.6786 - val_loss: 0.6274 - val_accuracy: 0.7105\n",
      "Epoch 39/50\n",
      "112/112 [==============================] - 0s 352us/sample - loss: 0.6464 - accuracy: 0.6786 - val_loss: 0.6150 - val_accuracy: 0.7105\n",
      "Epoch 40/50\n",
      "112/112 [==============================] - 0s 352us/sample - loss: 0.6352 - accuracy: 0.6786 - val_loss: 0.6031 - val_accuracy: 0.7105\n",
      "Epoch 41/50\n",
      "112/112 [==============================] - 0s 343us/sample - loss: 0.6241 - accuracy: 0.6786 - val_loss: 0.5920 - val_accuracy: 0.7105\n",
      "Epoch 42/50\n",
      "112/112 [==============================] - 0s 377us/sample - loss: 0.6139 - accuracy: 0.6786 - val_loss: 0.5814 - val_accuracy: 0.7105\n",
      "Epoch 43/50\n",
      "112/112 [==============================] - 0s 352us/sample - loss: 0.6043 - accuracy: 0.6875 - val_loss: 0.5713 - val_accuracy: 0.7105\n",
      "Epoch 44/50\n",
      "112/112 [==============================] - 0s 409us/sample - loss: 0.5951 - accuracy: 0.6875 - val_loss: 0.5618 - val_accuracy: 0.7105\n",
      "Epoch 45/50\n",
      "112/112 [==============================] - 0s 338us/sample - loss: 0.5863 - accuracy: 0.6875 - val_loss: 0.5528 - val_accuracy: 0.7105\n",
      "Epoch 46/50\n",
      "112/112 [==============================] - 0s 336us/sample - loss: 0.5780 - accuracy: 0.6875 - val_loss: 0.5442 - val_accuracy: 0.7105\n",
      "Epoch 47/50\n",
      "112/112 [==============================] - 0s 344us/sample - loss: 0.5705 - accuracy: 0.6964 - val_loss: 0.5359 - val_accuracy: 0.7368\n",
      "Epoch 48/50\n",
      "112/112 [==============================] - 0s 350us/sample - loss: 0.5632 - accuracy: 0.6964 - val_loss: 0.5282 - val_accuracy: 0.7368\n",
      "Epoch 49/50\n",
      "112/112 [==============================] - 0s 335us/sample - loss: 0.5563 - accuracy: 0.6964 - val_loss: 0.5210 - val_accuracy: 0.7368\n",
      "Epoch 50/50\n",
      "112/112 [==============================] - 0s 463us/sample - loss: 0.5496 - accuracy: 0.6964 - val_loss: 0.5142 - val_accuracy: 0.7368\n",
      "\n",
      "Forming the grid-search model #1 using: optimizer=<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7fe1d6395990>, kernel=<tensorflow.python.ops.init_ops_v2.RandomNormal object at 0x7fe1b03bde50>, epochs=50, batch_size=64\n",
      "Train on 112 samples, validate on 38 samples\n",
      "Epoch 1/50\n",
      "112/112 [==============================] - 1s 9ms/sample - loss: 1.0961 - accuracy: 0.5000 - val_loss: 1.0919 - val_accuracy: 0.8684\n",
      "Epoch 2/50\n",
      "112/112 [==============================] - 0s 276us/sample - loss: 1.0931 - accuracy: 0.6607 - val_loss: 1.0875 - val_accuracy: 0.9211\n",
      "Epoch 3/50\n",
      "112/112 [==============================] - 0s 278us/sample - loss: 1.0888 - accuracy: 0.7321 - val_loss: 1.0822 - val_accuracy: 0.9211\n",
      "Epoch 4/50\n",
      "112/112 [==============================] - 0s 267us/sample - loss: 1.0838 - accuracy: 0.7768 - val_loss: 1.0759 - val_accuracy: 0.8947\n",
      "Epoch 5/50\n",
      "112/112 [==============================] - 0s 254us/sample - loss: 1.0773 - accuracy: 0.8036 - val_loss: 1.0689 - val_accuracy: 0.9211\n",
      "Epoch 6/50\n",
      "112/112 [==============================] - 0s 266us/sample - loss: 1.0701 - accuracy: 0.8036 - val_loss: 1.0608 - val_accuracy: 0.8947\n",
      "Epoch 7/50\n",
      "112/112 [==============================] - 0s 284us/sample - loss: 1.0619 - accuracy: 0.8036 - val_loss: 1.0517 - val_accuracy: 0.8684\n",
      "Epoch 8/50\n",
      "112/112 [==============================] - 0s 288us/sample - loss: 1.0534 - accuracy: 0.7946 - val_loss: 1.0416 - val_accuracy: 0.8684\n",
      "Epoch 9/50\n",
      "112/112 [==============================] - 0s 286us/sample - loss: 1.0430 - accuracy: 0.7946 - val_loss: 1.0305 - val_accuracy: 0.8684\n",
      "Epoch 10/50\n",
      "112/112 [==============================] - 0s 290us/sample - loss: 1.0324 - accuracy: 0.7946 - val_loss: 1.0184 - val_accuracy: 0.8684\n",
      "Epoch 11/50\n",
      "112/112 [==============================] - 0s 292us/sample - loss: 1.0204 - accuracy: 0.7857 - val_loss: 1.0054 - val_accuracy: 0.8684\n",
      "Epoch 12/50\n",
      "112/112 [==============================] - 0s 281us/sample - loss: 1.0081 - accuracy: 0.7679 - val_loss: 0.9916 - val_accuracy: 0.8421\n",
      "Epoch 13/50\n",
      "112/112 [==============================] - 0s 266us/sample - loss: 0.9945 - accuracy: 0.7411 - val_loss: 0.9770 - val_accuracy: 0.8421\n",
      "Epoch 14/50\n",
      "112/112 [==============================] - 0s 307us/sample - loss: 0.9806 - accuracy: 0.7411 - val_loss: 0.9617 - val_accuracy: 0.8158\n",
      "Epoch 15/50\n",
      "112/112 [==============================] - 0s 273us/sample - loss: 0.9657 - accuracy: 0.7500 - val_loss: 0.9458 - val_accuracy: 0.7895\n",
      "Epoch 16/50\n",
      "112/112 [==============================] - 0s 286us/sample - loss: 0.9508 - accuracy: 0.7321 - val_loss: 0.9293 - val_accuracy: 0.7895\n",
      "Epoch 17/50\n",
      "112/112 [==============================] - 0s 320us/sample - loss: 0.9342 - accuracy: 0.7321 - val_loss: 0.9124 - val_accuracy: 0.7895\n",
      "Epoch 18/50\n",
      "112/112 [==============================] - 0s 279us/sample - loss: 0.9184 - accuracy: 0.7143 - val_loss: 0.8951 - val_accuracy: 0.7632\n",
      "Epoch 19/50\n",
      "112/112 [==============================] - 0s 365us/sample - loss: 0.9007 - accuracy: 0.7143 - val_loss: 0.8775 - val_accuracy: 0.7632\n",
      "Epoch 20/50\n",
      "112/112 [==============================] - 0s 285us/sample - loss: 0.8847 - accuracy: 0.7143 - val_loss: 0.8595 - val_accuracy: 0.7632\n",
      "Epoch 21/50\n",
      "112/112 [==============================] - 0s 278us/sample - loss: 0.8673 - accuracy: 0.7054 - val_loss: 0.8414 - val_accuracy: 0.7632\n",
      "Epoch 22/50\n",
      "112/112 [==============================] - 0s 277us/sample - loss: 0.8495 - accuracy: 0.6964 - val_loss: 0.8233 - val_accuracy: 0.7632\n",
      "Epoch 23/50\n",
      "112/112 [==============================] - 0s 278us/sample - loss: 0.8322 - accuracy: 0.6964 - val_loss: 0.8051 - val_accuracy: 0.7632\n",
      "Epoch 24/50\n",
      "112/112 [==============================] - 0s 281us/sample - loss: 0.8149 - accuracy: 0.6964 - val_loss: 0.7871 - val_accuracy: 0.7368\n",
      "Epoch 25/50\n",
      "112/112 [==============================] - 0s 265us/sample - loss: 0.7974 - accuracy: 0.6964 - val_loss: 0.7692 - val_accuracy: 0.7368\n",
      "Epoch 26/50\n",
      "112/112 [==============================] - 0s 284us/sample - loss: 0.7811 - accuracy: 0.6964 - val_loss: 0.7516 - val_accuracy: 0.7368\n",
      "Epoch 27/50\n",
      "112/112 [==============================] - 0s 283us/sample - loss: 0.7637 - accuracy: 0.6964 - val_loss: 0.7344 - val_accuracy: 0.7368\n",
      "Epoch 28/50\n",
      "112/112 [==============================] - 0s 293us/sample - loss: 0.7481 - accuracy: 0.6964 - val_loss: 0.7176 - val_accuracy: 0.7368\n",
      "Epoch 29/50\n",
      "112/112 [==============================] - 0s 269us/sample - loss: 0.7321 - accuracy: 0.6964 - val_loss: 0.7014 - val_accuracy: 0.7368\n",
      "Epoch 30/50\n",
      "112/112 [==============================] - 0s 274us/sample - loss: 0.7168 - accuracy: 0.6964 - val_loss: 0.6857 - val_accuracy: 0.7368\n",
      "Epoch 31/50\n",
      "112/112 [==============================] - 0s 276us/sample - loss: 0.7019 - accuracy: 0.6964 - val_loss: 0.6707 - val_accuracy: 0.7368\n",
      "Epoch 32/50\n",
      "112/112 [==============================] - 0s 272us/sample - loss: 0.6876 - accuracy: 0.6964 - val_loss: 0.6563 - val_accuracy: 0.7368\n",
      "Epoch 33/50\n",
      "112/112 [==============================] - 0s 288us/sample - loss: 0.6741 - accuracy: 0.6964 - val_loss: 0.6424 - val_accuracy: 0.7368\n",
      "Epoch 34/50\n",
      "112/112 [==============================] - 0s 296us/sample - loss: 0.6616 - accuracy: 0.6964 - val_loss: 0.6291 - val_accuracy: 0.7368\n",
      "Epoch 35/50\n",
      "112/112 [==============================] - 0s 271us/sample - loss: 0.6488 - accuracy: 0.6964 - val_loss: 0.6166 - val_accuracy: 0.7368\n",
      "Epoch 36/50\n",
      "112/112 [==============================] - 0s 278us/sample - loss: 0.6374 - accuracy: 0.6964 - val_loss: 0.6046 - val_accuracy: 0.7368\n",
      "Epoch 37/50\n",
      "112/112 [==============================] - 0s 271us/sample - loss: 0.6264 - accuracy: 0.6964 - val_loss: 0.5933 - val_accuracy: 0.7368\n",
      "Epoch 38/50\n",
      "112/112 [==============================] - 0s 275us/sample - loss: 0.6158 - accuracy: 0.6964 - val_loss: 0.5825 - val_accuracy: 0.7368\n",
      "Epoch 39/50\n",
      "112/112 [==============================] - 0s 275us/sample - loss: 0.6058 - accuracy: 0.6964 - val_loss: 0.5723 - val_accuracy: 0.7632\n",
      "Epoch 40/50\n",
      "112/112 [==============================] - 0s 279us/sample - loss: 0.5967 - accuracy: 0.6964 - val_loss: 0.5626 - val_accuracy: 0.7632\n",
      "Epoch 41/50\n",
      "112/112 [==============================] - 0s 265us/sample - loss: 0.5875 - accuracy: 0.6964 - val_loss: 0.5535 - val_accuracy: 0.7632\n",
      "Epoch 42/50\n",
      "112/112 [==============================] - ETA: 0s - loss: 0.6121 - accuracy: 0.67 - 0s 257us/sample - loss: 0.5792 - accuracy: 0.6964 - val_loss: 0.5448 - val_accuracy: 0.7632\n",
      "Epoch 43/50\n",
      "112/112 [==============================] - 0s 297us/sample - loss: 0.5713 - accuracy: 0.6964 - val_loss: 0.5366 - val_accuracy: 0.7632\n",
      "Epoch 44/50\n",
      "112/112 [==============================] - 0s 296us/sample - loss: 0.5637 - accuracy: 0.7054 - val_loss: 0.5287 - val_accuracy: 0.7632\n",
      "Epoch 45/50\n",
      "112/112 [==============================] - 0s 265us/sample - loss: 0.5565 - accuracy: 0.7143 - val_loss: 0.5213 - val_accuracy: 0.7895\n",
      "Epoch 46/50\n",
      "112/112 [==============================] - 0s 290us/sample - loss: 0.5498 - accuracy: 0.7232 - val_loss: 0.5142 - val_accuracy: 0.7895\n",
      "Epoch 47/50\n",
      "112/112 [==============================] - 0s 284us/sample - loss: 0.5434 - accuracy: 0.7232 - val_loss: 0.5075 - val_accuracy: 0.7895\n",
      "Epoch 48/50\n",
      "112/112 [==============================] - 0s 280us/sample - loss: 0.5373 - accuracy: 0.7232 - val_loss: 0.5011 - val_accuracy: 0.7895\n",
      "Epoch 49/50\n",
      "112/112 [==============================] - 0s 275us/sample - loss: 0.5316 - accuracy: 0.7232 - val_loss: 0.4950 - val_accuracy: 0.7895\n",
      "Epoch 50/50\n",
      "112/112 [==============================] - 0s 267us/sample - loss: 0.5260 - accuracy: 0.7232 - val_loss: 0.4892 - val_accuracy: 0.7895\n",
      "\n",
      "Forming the grid-search model #2 using: optimizer=<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7fe1d6395990>, kernel=<tensorflow.python.ops.init_ops_v2.RandomNormal object at 0x7fe1b03bde50>, epochs=50, batch_size=128\n",
      "Train on 112 samples, validate on 38 samples\n",
      "Epoch 1/50\n",
      "112/112 [==============================] - 1s 9ms/sample - loss: 1.0965 - accuracy: 0.4196 - val_loss: 1.0935 - val_accuracy: 0.5789\n",
      "Epoch 2/50\n",
      "112/112 [==============================] - 0s 218us/sample - loss: 1.0951 - accuracy: 0.5000 - val_loss: 1.0915 - val_accuracy: 0.6053\n",
      "Epoch 3/50\n",
      "112/112 [==============================] - 0s 244us/sample - loss: 1.0933 - accuracy: 0.5714 - val_loss: 1.0891 - val_accuracy: 0.5789\n",
      "Epoch 4/50\n",
      "112/112 [==============================] - 0s 235us/sample - loss: 1.0910 - accuracy: 0.5357 - val_loss: 1.0863 - val_accuracy: 0.5263\n",
      "Epoch 5/50\n",
      "112/112 [==============================] - 0s 217us/sample - loss: 1.0883 - accuracy: 0.5446 - val_loss: 1.0832 - val_accuracy: 0.5526\n",
      "Epoch 6/50\n",
      "112/112 [==============================] - 0s 229us/sample - loss: 1.0852 - accuracy: 0.5357 - val_loss: 1.0798 - val_accuracy: 0.5526\n",
      "Epoch 7/50\n",
      "112/112 [==============================] - 0s 228us/sample - loss: 1.0818 - accuracy: 0.5446 - val_loss: 1.0761 - val_accuracy: 0.6842\n",
      "Epoch 8/50\n",
      "112/112 [==============================] - 0s 234us/sample - loss: 1.0781 - accuracy: 0.5893 - val_loss: 1.0721 - val_accuracy: 0.6842\n",
      "Epoch 9/50\n",
      "112/112 [==============================] - 0s 233us/sample - loss: 1.0740 - accuracy: 0.6518 - val_loss: 1.0676 - val_accuracy: 0.6842\n",
      "Epoch 10/50\n",
      "112/112 [==============================] - 0s 243us/sample - loss: 1.0696 - accuracy: 0.7143 - val_loss: 1.0628 - val_accuracy: 0.7105\n",
      "Epoch 11/50\n",
      "112/112 [==============================] - 0s 233us/sample - loss: 1.0649 - accuracy: 0.7679 - val_loss: 1.0575 - val_accuracy: 0.8421\n",
      "Epoch 12/50\n",
      "112/112 [==============================] - 0s 234us/sample - loss: 1.0598 - accuracy: 0.8125 - val_loss: 1.0519 - val_accuracy: 0.8421\n",
      "Epoch 13/50\n",
      "112/112 [==============================] - 0s 225us/sample - loss: 1.0544 - accuracy: 0.8571 - val_loss: 1.0458 - val_accuracy: 0.9474\n",
      "Epoch 14/50\n",
      "112/112 [==============================] - 0s 234us/sample - loss: 1.0486 - accuracy: 0.8929 - val_loss: 1.0393 - val_accuracy: 0.9737\n",
      "Epoch 15/50\n",
      "112/112 [==============================] - 0s 226us/sample - loss: 1.0424 - accuracy: 0.8750 - val_loss: 1.0325 - val_accuracy: 0.9737\n",
      "Epoch 16/50\n",
      "112/112 [==============================] - 0s 228us/sample - loss: 1.0360 - accuracy: 0.8750 - val_loss: 1.0253 - val_accuracy: 0.9474\n",
      "Epoch 17/50\n",
      "112/112 [==============================] - 0s 247us/sample - loss: 1.0292 - accuracy: 0.9018 - val_loss: 1.0178 - val_accuracy: 0.9474\n",
      "Epoch 18/50\n",
      "112/112 [==============================] - 0s 251us/sample - loss: 1.0220 - accuracy: 0.8661 - val_loss: 1.0101 - val_accuracy: 0.9211\n",
      "Epoch 19/50\n",
      "112/112 [==============================] - 0s 240us/sample - loss: 1.0146 - accuracy: 0.8661 - val_loss: 1.0020 - val_accuracy: 0.9211\n",
      "Epoch 20/50\n",
      "112/112 [==============================] - 0s 233us/sample - loss: 1.0068 - accuracy: 0.8482 - val_loss: 0.9936 - val_accuracy: 0.9211\n",
      "Epoch 21/50\n",
      "112/112 [==============================] - 0s 308us/sample - loss: 0.9987 - accuracy: 0.8393 - val_loss: 0.9850 - val_accuracy: 0.9211\n",
      "Epoch 22/50\n",
      "112/112 [==============================] - 0s 228us/sample - loss: 0.9904 - accuracy: 0.8304 - val_loss: 0.9761 - val_accuracy: 0.9211\n",
      "Epoch 23/50\n",
      "112/112 [==============================] - 0s 263us/sample - loss: 0.9817 - accuracy: 0.8214 - val_loss: 0.9669 - val_accuracy: 0.9211\n",
      "Epoch 24/50\n",
      "112/112 [==============================] - 0s 229us/sample - loss: 0.9728 - accuracy: 0.8214 - val_loss: 0.9575 - val_accuracy: 0.9211\n",
      "Epoch 25/50\n",
      "112/112 [==============================] - 0s 236us/sample - loss: 0.9637 - accuracy: 0.8214 - val_loss: 0.9478 - val_accuracy: 0.9211\n",
      "Epoch 26/50\n",
      "112/112 [==============================] - 0s 237us/sample - loss: 0.9543 - accuracy: 0.8214 - val_loss: 0.9379 - val_accuracy: 0.9211\n",
      "Epoch 27/50\n",
      "112/112 [==============================] - 0s 231us/sample - loss: 0.9447 - accuracy: 0.8214 - val_loss: 0.9278 - val_accuracy: 0.9211\n",
      "Epoch 28/50\n",
      "112/112 [==============================] - 0s 235us/sample - loss: 0.9349 - accuracy: 0.8214 - val_loss: 0.9175 - val_accuracy: 0.9211\n",
      "Epoch 29/50\n",
      "112/112 [==============================] - 0s 230us/sample - loss: 0.9249 - accuracy: 0.8214 - val_loss: 0.9070 - val_accuracy: 0.9211\n",
      "Epoch 30/50\n",
      "112/112 [==============================] - 0s 239us/sample - loss: 0.9148 - accuracy: 0.8214 - val_loss: 0.8964 - val_accuracy: 0.9211\n",
      "Epoch 31/50\n",
      "112/112 [==============================] - 0s 2ms/sample - loss: 0.9045 - accuracy: 0.8214 - val_loss: 0.8856 - val_accuracy: 0.9211\n",
      "Epoch 32/50\n",
      "112/112 [==============================] - 0s 231us/sample - loss: 0.8940 - accuracy: 0.8214 - val_loss: 0.8746 - val_accuracy: 0.9211\n",
      "Epoch 33/50\n",
      "112/112 [==============================] - 0s 231us/sample - loss: 0.8834 - accuracy: 0.8214 - val_loss: 0.8636 - val_accuracy: 0.9211\n",
      "Epoch 34/50\n",
      "112/112 [==============================] - 0s 234us/sample - loss: 0.8727 - accuracy: 0.8214 - val_loss: 0.8524 - val_accuracy: 0.9211\n",
      "Epoch 35/50\n",
      "112/112 [==============================] - 0s 241us/sample - loss: 0.8619 - accuracy: 0.8214 - val_loss: 0.8412 - val_accuracy: 0.8947\n",
      "Epoch 36/50\n",
      "112/112 [==============================] - 0s 241us/sample - loss: 0.8511 - accuracy: 0.8125 - val_loss: 0.8298 - val_accuracy: 0.8947\n",
      "Epoch 37/50\n",
      "112/112 [==============================] - 0s 226us/sample - loss: 0.8401 - accuracy: 0.8125 - val_loss: 0.8185 - val_accuracy: 0.8947\n",
      "Epoch 38/50\n",
      "112/112 [==============================] - 0s 233us/sample - loss: 0.8292 - accuracy: 0.8125 - val_loss: 0.8071 - val_accuracy: 0.8947\n",
      "Epoch 39/50\n",
      "112/112 [==============================] - 0s 231us/sample - loss: 0.8183 - accuracy: 0.8036 - val_loss: 0.7957 - val_accuracy: 0.8947\n",
      "Epoch 40/50\n",
      "112/112 [==============================] - 0s 235us/sample - loss: 0.8073 - accuracy: 0.8036 - val_loss: 0.7843 - val_accuracy: 0.8947\n",
      "Epoch 41/50\n",
      "112/112 [==============================] - 0s 218us/sample - loss: 0.7964 - accuracy: 0.8036 - val_loss: 0.7729 - val_accuracy: 0.8947\n",
      "Epoch 42/50\n",
      "112/112 [==============================] - 0s 234us/sample - loss: 0.7855 - accuracy: 0.8036 - val_loss: 0.7616 - val_accuracy: 0.8947\n",
      "Epoch 43/50\n",
      "112/112 [==============================] - 0s 246us/sample - loss: 0.7748 - accuracy: 0.8036 - val_loss: 0.7504 - val_accuracy: 0.8947\n",
      "Epoch 44/50\n",
      "112/112 [==============================] - 0s 226us/sample - loss: 0.7641 - accuracy: 0.7946 - val_loss: 0.7392 - val_accuracy: 0.8947\n",
      "Epoch 45/50\n",
      "112/112 [==============================] - 0s 228us/sample - loss: 0.7534 - accuracy: 0.7946 - val_loss: 0.7281 - val_accuracy: 0.8947\n",
      "Epoch 46/50\n",
      "112/112 [==============================] - 0s 230us/sample - loss: 0.7430 - accuracy: 0.7946 - val_loss: 0.7172 - val_accuracy: 0.8947\n",
      "Epoch 47/50\n",
      "112/112 [==============================] - 0s 247us/sample - loss: 0.7326 - accuracy: 0.7946 - val_loss: 0.7064 - val_accuracy: 0.8947\n",
      "Epoch 48/50\n",
      "112/112 [==============================] - 0s 245us/sample - loss: 0.7224 - accuracy: 0.7946 - val_loss: 0.6957 - val_accuracy: 0.8947\n",
      "Epoch 49/50\n",
      "112/112 [==============================] - 0s 229us/sample - loss: 0.7124 - accuracy: 0.7946 - val_loss: 0.6853 - val_accuracy: 0.8947\n",
      "Epoch 50/50\n",
      "112/112 [==============================] - 0s 250us/sample - loss: 0.7025 - accuracy: 0.7946 - val_loss: 0.6749 - val_accuracy: 0.8947\n",
      "\n",
      "Forming the grid-search model #3 using: optimizer=<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7fe1d6395990>, kernel=<tensorflow.python.ops.init_ops_v2.Orthogonal object at 0x7fe1b03bd4d0>, epochs=50, batch_size=32\n",
      "Train on 112 samples, validate on 38 samples\n",
      "Epoch 1/50\n",
      "112/112 [==============================] - 1s 9ms/sample - loss: 1.2258 - accuracy: 0.2946 - val_loss: 1.1620 - val_accuracy: 0.3947\n",
      "Epoch 2/50\n",
      "112/112 [==============================] - 0s 341us/sample - loss: 1.1668 - accuracy: 0.3661 - val_loss: 1.0914 - val_accuracy: 0.4211\n",
      "Epoch 3/50\n",
      "112/112 [==============================] - 0s 355us/sample - loss: 1.1016 - accuracy: 0.4018 - val_loss: 1.0218 - val_accuracy: 0.4474\n",
      "Epoch 4/50\n",
      "112/112 [==============================] - 0s 348us/sample - loss: 1.0429 - accuracy: 0.4196 - val_loss: 0.9571 - val_accuracy: 0.5789\n",
      "Epoch 5/50\n",
      "112/112 [==============================] - 0s 353us/sample - loss: 0.9826 - accuracy: 0.5446 - val_loss: 0.8999 - val_accuracy: 0.7895\n",
      "Epoch 6/50\n",
      "112/112 [==============================] - 0s 348us/sample - loss: 0.9337 - accuracy: 0.6429 - val_loss: 0.8478 - val_accuracy: 0.8158\n",
      "Epoch 7/50\n",
      "112/112 [==============================] - 0s 345us/sample - loss: 0.8891 - accuracy: 0.7232 - val_loss: 0.8006 - val_accuracy: 0.9211\n",
      "Epoch 8/50\n",
      "112/112 [==============================] - 0s 338us/sample - loss: 0.8505 - accuracy: 0.7321 - val_loss: 0.7578 - val_accuracy: 0.8947\n",
      "Epoch 9/50\n",
      "112/112 [==============================] - 0s 353us/sample - loss: 0.8119 - accuracy: 0.7232 - val_loss: 0.7198 - val_accuracy: 0.8947\n",
      "Epoch 10/50\n",
      "112/112 [==============================] - 0s 352us/sample - loss: 0.7790 - accuracy: 0.7679 - val_loss: 0.6852 - val_accuracy: 0.9211\n",
      "Epoch 11/50\n",
      "112/112 [==============================] - 0s 363us/sample - loss: 0.7488 - accuracy: 0.7768 - val_loss: 0.6539 - val_accuracy: 0.9211\n",
      "Epoch 12/50\n",
      "112/112 [==============================] - 0s 352us/sample - loss: 0.7212 - accuracy: 0.7768 - val_loss: 0.6254 - val_accuracy: 0.9211\n",
      "Epoch 13/50\n",
      "112/112 [==============================] - 0s 340us/sample - loss: 0.6953 - accuracy: 0.7768 - val_loss: 0.5998 - val_accuracy: 0.9211\n",
      "Epoch 14/50\n",
      "112/112 [==============================] - 0s 355us/sample - loss: 0.6722 - accuracy: 0.7768 - val_loss: 0.5761 - val_accuracy: 0.9211\n",
      "Epoch 15/50\n",
      "112/112 [==============================] - 0s 339us/sample - loss: 0.6497 - accuracy: 0.7857 - val_loss: 0.5551 - val_accuracy: 0.9211\n",
      "Epoch 16/50\n",
      "112/112 [==============================] - 0s 356us/sample - loss: 0.6304 - accuracy: 0.7857 - val_loss: 0.5349 - val_accuracy: 0.9211\n",
      "Epoch 17/50\n",
      "112/112 [==============================] - 0s 342us/sample - loss: 0.6111 - accuracy: 0.7946 - val_loss: 0.5168 - val_accuracy: 0.9211\n",
      "Epoch 18/50\n",
      "112/112 [==============================] - 0s 337us/sample - loss: 0.5935 - accuracy: 0.7946 - val_loss: 0.5002 - val_accuracy: 0.9211\n",
      "Epoch 19/50\n",
      "112/112 [==============================] - 0s 345us/sample - loss: 0.5773 - accuracy: 0.8036 - val_loss: 0.4850 - val_accuracy: 0.9211\n",
      "Epoch 20/50\n",
      "112/112 [==============================] - 0s 310us/sample - loss: 0.5622 - accuracy: 0.8036 - val_loss: 0.4705 - val_accuracy: 0.9211\n",
      "Epoch 21/50\n",
      "112/112 [==============================] - 0s 399us/sample - loss: 0.5481 - accuracy: 0.8036 - val_loss: 0.4573 - val_accuracy: 0.9211\n",
      "Epoch 22/50\n",
      "112/112 [==============================] - 0s 352us/sample - loss: 0.5351 - accuracy: 0.8036 - val_loss: 0.4447 - val_accuracy: 0.9211\n",
      "Epoch 23/50\n",
      "112/112 [==============================] - 0s 351us/sample - loss: 0.5228 - accuracy: 0.8214 - val_loss: 0.4329 - val_accuracy: 0.9211\n",
      "Epoch 24/50\n",
      "112/112 [==============================] - 0s 363us/sample - loss: 0.5112 - accuracy: 0.8214 - val_loss: 0.4219 - val_accuracy: 0.9211\n",
      "Epoch 25/50\n",
      "112/112 [==============================] - 0s 344us/sample - loss: 0.5003 - accuracy: 0.8214 - val_loss: 0.4117 - val_accuracy: 0.9211\n",
      "Epoch 26/50\n",
      "112/112 [==============================] - 0s 357us/sample - loss: 0.4902 - accuracy: 0.8214 - val_loss: 0.4019 - val_accuracy: 0.9211\n",
      "Epoch 27/50\n",
      "112/112 [==============================] - 0s 360us/sample - loss: 0.4804 - accuracy: 0.8214 - val_loss: 0.3930 - val_accuracy: 0.9211\n",
      "Epoch 28/50\n",
      "112/112 [==============================] - 0s 363us/sample - loss: 0.4712 - accuracy: 0.8214 - val_loss: 0.3846 - val_accuracy: 0.9211\n",
      "Epoch 29/50\n",
      "112/112 [==============================] - 0s 355us/sample - loss: 0.4627 - accuracy: 0.8214 - val_loss: 0.3766 - val_accuracy: 0.9211\n",
      "Epoch 30/50\n",
      "112/112 [==============================] - 0s 345us/sample - loss: 0.4547 - accuracy: 0.8214 - val_loss: 0.3691 - val_accuracy: 0.9211\n",
      "Epoch 31/50\n",
      "112/112 [==============================] - 0s 367us/sample - loss: 0.4469 - accuracy: 0.8214 - val_loss: 0.3622 - val_accuracy: 0.9211\n",
      "Epoch 32/50\n",
      "112/112 [==============================] - 0s 344us/sample - loss: 0.4395 - accuracy: 0.8304 - val_loss: 0.3558 - val_accuracy: 0.9211\n",
      "Epoch 33/50\n",
      "112/112 [==============================] - 0s 347us/sample - loss: 0.4324 - accuracy: 0.8304 - val_loss: 0.3496 - val_accuracy: 0.9211\n",
      "Epoch 34/50\n",
      "112/112 [==============================] - 0s 348us/sample - loss: 0.4256 - accuracy: 0.8304 - val_loss: 0.3433 - val_accuracy: 0.9211\n",
      "Epoch 35/50\n",
      "112/112 [==============================] - 0s 358us/sample - loss: 0.4193 - accuracy: 0.8214 - val_loss: 0.3375 - val_accuracy: 0.9211\n",
      "Epoch 36/50\n",
      "112/112 [==============================] - 0s 348us/sample - loss: 0.4127 - accuracy: 0.8214 - val_loss: 0.3322 - val_accuracy: 0.9211\n",
      "Epoch 37/50\n",
      "112/112 [==============================] - 0s 350us/sample - loss: 0.4067 - accuracy: 0.8393 - val_loss: 0.3270 - val_accuracy: 0.9211\n",
      "Epoch 38/50\n",
      "112/112 [==============================] - 0s 360us/sample - loss: 0.4010 - accuracy: 0.8393 - val_loss: 0.3220 - val_accuracy: 0.9211\n",
      "Epoch 39/50\n",
      "112/112 [==============================] - 0s 509us/sample - loss: 0.3955 - accuracy: 0.8393 - val_loss: 0.3173 - val_accuracy: 0.9211\n",
      "Epoch 40/50\n",
      "112/112 [==============================] - 0s 346us/sample - loss: 0.3900 - accuracy: 0.8393 - val_loss: 0.3126 - val_accuracy: 0.9211\n",
      "Epoch 41/50\n",
      "112/112 [==============================] - 0s 346us/sample - loss: 0.3850 - accuracy: 0.8393 - val_loss: 0.3083 - val_accuracy: 0.9474\n",
      "Epoch 42/50\n",
      "112/112 [==============================] - 0s 352us/sample - loss: 0.3800 - accuracy: 0.8393 - val_loss: 0.3041 - val_accuracy: 0.9474\n",
      "Epoch 43/50\n",
      "112/112 [==============================] - 0s 340us/sample - loss: 0.3748 - accuracy: 0.8482 - val_loss: 0.3000 - val_accuracy: 0.9474\n",
      "Epoch 44/50\n",
      "112/112 [==============================] - 0s 351us/sample - loss: 0.3701 - accuracy: 0.8482 - val_loss: 0.2961 - val_accuracy: 0.9474\n",
      "Epoch 45/50\n",
      "112/112 [==============================] - 0s 343us/sample - loss: 0.3657 - accuracy: 0.8482 - val_loss: 0.2923 - val_accuracy: 0.9474\n",
      "Epoch 46/50\n",
      "112/112 [==============================] - 0s 353us/sample - loss: 0.3610 - accuracy: 0.8482 - val_loss: 0.2885 - val_accuracy: 0.9474\n",
      "Epoch 47/50\n",
      "112/112 [==============================] - 0s 354us/sample - loss: 0.3565 - accuracy: 0.8571 - val_loss: 0.2847 - val_accuracy: 0.9474\n",
      "Epoch 48/50\n",
      "112/112 [==============================] - 0s 333us/sample - loss: 0.3522 - accuracy: 0.8571 - val_loss: 0.2814 - val_accuracy: 0.9474\n",
      "Epoch 49/50\n",
      "112/112 [==============================] - 0s 338us/sample - loss: 0.3483 - accuracy: 0.8571 - val_loss: 0.2781 - val_accuracy: 0.9474\n",
      "Epoch 50/50\n",
      "112/112 [==============================] - 0s 348us/sample - loss: 0.3441 - accuracy: 0.8571 - val_loss: 0.2753 - val_accuracy: 0.9474\n",
      "\n",
      "Forming the grid-search model #4 using: optimizer=<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7fe1d6395990>, kernel=<tensorflow.python.ops.init_ops_v2.Orthogonal object at 0x7fe1b03bd4d0>, epochs=50, batch_size=64\n",
      "Train on 112 samples, validate on 38 samples\n",
      "Epoch 1/50\n",
      "112/112 [==============================] - 1s 9ms/sample - loss: 1.2332 - accuracy: 0.2857 - val_loss: 1.1876 - val_accuracy: 0.3421\n",
      "Epoch 2/50\n",
      "112/112 [==============================] - 0s 268us/sample - loss: 1.2028 - accuracy: 0.3304 - val_loss: 1.1465 - val_accuracy: 0.4211\n",
      "Epoch 3/50\n",
      "112/112 [==============================] - 0s 269us/sample - loss: 1.1648 - accuracy: 0.3482 - val_loss: 1.1026 - val_accuracy: 0.4211\n",
      "Epoch 4/50\n",
      "112/112 [==============================] - 0s 262us/sample - loss: 1.1275 - accuracy: 0.3929 - val_loss: 1.0587 - val_accuracy: 0.4474\n",
      "Epoch 5/50\n",
      "112/112 [==============================] - 0s 266us/sample - loss: 1.0857 - accuracy: 0.4107 - val_loss: 1.0161 - val_accuracy: 0.4737\n",
      "Epoch 6/50\n",
      "112/112 [==============================] - 0s 279us/sample - loss: 1.0493 - accuracy: 0.4107 - val_loss: 0.9759 - val_accuracy: 0.5263\n",
      "Epoch 7/50\n",
      "112/112 [==============================] - 0s 271us/sample - loss: 1.0114 - accuracy: 0.5179 - val_loss: 0.9378 - val_accuracy: 0.6842\n",
      "Epoch 8/50\n",
      "112/112 [==============================] - 0s 288us/sample - loss: 0.9802 - accuracy: 0.5804 - val_loss: 0.9019 - val_accuracy: 0.7895\n",
      "Epoch 9/50\n",
      "112/112 [==============================] - 0s 294us/sample - loss: 0.9464 - accuracy: 0.6429 - val_loss: 0.8685 - val_accuracy: 0.8421\n",
      "Epoch 10/50\n",
      "112/112 [==============================] - 0s 280us/sample - loss: 0.9163 - accuracy: 0.7054 - val_loss: 0.8370 - val_accuracy: 0.8684\n",
      "Epoch 11/50\n",
      "112/112 [==============================] - 0s 268us/sample - loss: 0.8881 - accuracy: 0.7321 - val_loss: 0.8068 - val_accuracy: 0.9211\n",
      "Epoch 12/50\n",
      "112/112 [==============================] - 0s 287us/sample - loss: 0.8622 - accuracy: 0.7411 - val_loss: 0.7781 - val_accuracy: 0.9211\n",
      "Epoch 13/50\n",
      "112/112 [==============================] - 0s 286us/sample - loss: 0.8369 - accuracy: 0.7321 - val_loss: 0.7510 - val_accuracy: 0.8947\n",
      "Epoch 14/50\n",
      "112/112 [==============================] - 0s 282us/sample - loss: 0.8140 - accuracy: 0.7232 - val_loss: 0.7253 - val_accuracy: 0.8947\n",
      "Epoch 15/50\n",
      "112/112 [==============================] - 0s 289us/sample - loss: 0.7902 - accuracy: 0.7411 - val_loss: 0.7014 - val_accuracy: 0.9211\n",
      "Epoch 16/50\n",
      "112/112 [==============================] - 0s 285us/sample - loss: 0.7701 - accuracy: 0.7589 - val_loss: 0.6786 - val_accuracy: 0.9211\n",
      "Epoch 17/50\n",
      "112/112 [==============================] - 0s 269us/sample - loss: 0.7494 - accuracy: 0.7768 - val_loss: 0.6574 - val_accuracy: 0.9211\n",
      "Epoch 18/50\n",
      "112/112 [==============================] - 0s 272us/sample - loss: 0.7301 - accuracy: 0.7768 - val_loss: 0.6375 - val_accuracy: 0.9211\n",
      "Epoch 19/50\n",
      "112/112 [==============================] - 0s 282us/sample - loss: 0.7114 - accuracy: 0.7768 - val_loss: 0.6187 - val_accuracy: 0.9211\n",
      "Epoch 20/50\n",
      "112/112 [==============================] - 0s 292us/sample - loss: 0.6943 - accuracy: 0.7768 - val_loss: 0.6009 - val_accuracy: 0.9211\n",
      "Epoch 21/50\n",
      "112/112 [==============================] - 0s 267us/sample - loss: 0.6776 - accuracy: 0.7857 - val_loss: 0.5841 - val_accuracy: 0.9211\n",
      "Epoch 22/50\n",
      "112/112 [==============================] - 0s 286us/sample - loss: 0.6619 - accuracy: 0.7857 - val_loss: 0.5683 - val_accuracy: 0.9211\n",
      "Epoch 23/50\n",
      "112/112 [==============================] - 0s 282us/sample - loss: 0.6471 - accuracy: 0.7946 - val_loss: 0.5533 - val_accuracy: 0.9211\n",
      "Epoch 24/50\n",
      "112/112 [==============================] - 0s 276us/sample - loss: 0.6329 - accuracy: 0.7946 - val_loss: 0.5391 - val_accuracy: 0.9211\n",
      "Epoch 25/50\n",
      "112/112 [==============================] - 0s 275us/sample - loss: 0.6192 - accuracy: 0.7946 - val_loss: 0.5258 - val_accuracy: 0.9211\n",
      "Epoch 26/50\n",
      "112/112 [==============================] - 0s 295us/sample - loss: 0.6065 - accuracy: 0.7946 - val_loss: 0.5131 - val_accuracy: 0.9211\n",
      "Epoch 27/50\n",
      "112/112 [==============================] - 0s 275us/sample - loss: 0.5937 - accuracy: 0.7946 - val_loss: 0.5013 - val_accuracy: 0.9211\n",
      "Epoch 28/50\n",
      "112/112 [==============================] - 0s 303us/sample - loss: 0.5820 - accuracy: 0.8036 - val_loss: 0.4900 - val_accuracy: 0.9211\n",
      "Epoch 29/50\n",
      "112/112 [==============================] - 0s 270us/sample - loss: 0.5708 - accuracy: 0.8036 - val_loss: 0.4793 - val_accuracy: 0.9211\n",
      "Epoch 30/50\n",
      "112/112 [==============================] - 0s 269us/sample - loss: 0.5600 - accuracy: 0.8036 - val_loss: 0.4692 - val_accuracy: 0.9211\n",
      "Epoch 31/50\n",
      "112/112 [==============================] - 0s 292us/sample - loss: 0.5499 - accuracy: 0.8036 - val_loss: 0.4595 - val_accuracy: 0.9211\n",
      "Epoch 32/50\n",
      "112/112 [==============================] - 0s 269us/sample - loss: 0.5400 - accuracy: 0.8125 - val_loss: 0.4503 - val_accuracy: 0.9211\n",
      "Epoch 33/50\n",
      "112/112 [==============================] - 0s 280us/sample - loss: 0.5306 - accuracy: 0.8125 - val_loss: 0.4414 - val_accuracy: 0.9211\n",
      "Epoch 34/50\n",
      "112/112 [==============================] - ETA: 0s - loss: 0.5140 - accuracy: 0.84 - 0s 279us/sample - loss: 0.5217 - accuracy: 0.8214 - val_loss: 0.4329 - val_accuracy: 0.9211\n",
      "Epoch 35/50\n",
      "112/112 [==============================] - 0s 283us/sample - loss: 0.5133 - accuracy: 0.8214 - val_loss: 0.4248 - val_accuracy: 0.9211\n",
      "Epoch 36/50\n",
      "112/112 [==============================] - 0s 276us/sample - loss: 0.5049 - accuracy: 0.8214 - val_loss: 0.4171 - val_accuracy: 0.9211\n",
      "Epoch 37/50\n",
      "112/112 [==============================] - 0s 283us/sample - loss: 0.4970 - accuracy: 0.8214 - val_loss: 0.4098 - val_accuracy: 0.9211\n",
      "Epoch 38/50\n",
      "112/112 [==============================] - 0s 293us/sample - loss: 0.4896 - accuracy: 0.8214 - val_loss: 0.4027 - val_accuracy: 0.9211\n",
      "Epoch 39/50\n",
      "112/112 [==============================] - 0s 277us/sample - loss: 0.4823 - accuracy: 0.8214 - val_loss: 0.3959 - val_accuracy: 0.9211\n",
      "Epoch 40/50\n",
      "112/112 [==============================] - 0s 274us/sample - loss: 0.4753 - accuracy: 0.8214 - val_loss: 0.3894 - val_accuracy: 0.9211\n",
      "Epoch 41/50\n",
      "112/112 [==============================] - 0s 371us/sample - loss: 0.4688 - accuracy: 0.8125 - val_loss: 0.3832 - val_accuracy: 0.9211\n",
      "Epoch 42/50\n",
      "112/112 [==============================] - 0s 271us/sample - loss: 0.4624 - accuracy: 0.8125 - val_loss: 0.3772 - val_accuracy: 0.9211\n",
      "Epoch 43/50\n",
      "112/112 [==============================] - 0s 274us/sample - loss: 0.4560 - accuracy: 0.8214 - val_loss: 0.3715 - val_accuracy: 0.9211\n",
      "Epoch 44/50\n",
      "112/112 [==============================] - 0s 289us/sample - loss: 0.4502 - accuracy: 0.8214 - val_loss: 0.3659 - val_accuracy: 0.9211\n",
      "Epoch 45/50\n",
      "112/112 [==============================] - 0s 275us/sample - loss: 0.4447 - accuracy: 0.8214 - val_loss: 0.3605 - val_accuracy: 0.9211\n",
      "Epoch 46/50\n",
      "112/112 [==============================] - 0s 288us/sample - loss: 0.4390 - accuracy: 0.8214 - val_loss: 0.3553 - val_accuracy: 0.9211\n",
      "Epoch 47/50\n",
      "112/112 [==============================] - 0s 272us/sample - loss: 0.4337 - accuracy: 0.8214 - val_loss: 0.3504 - val_accuracy: 0.9211\n",
      "Epoch 48/50\n",
      "112/112 [==============================] - 0s 288us/sample - loss: 0.4285 - accuracy: 0.8214 - val_loss: 0.3458 - val_accuracy: 0.9211\n",
      "Epoch 49/50\n",
      "112/112 [==============================] - 0s 276us/sample - loss: 0.4237 - accuracy: 0.8214 - val_loss: 0.3412 - val_accuracy: 0.9211\n",
      "Epoch 50/50\n",
      "112/112 [==============================] - 0s 276us/sample - loss: 0.4188 - accuracy: 0.8393 - val_loss: 0.3369 - val_accuracy: 0.9211\n",
      "\n",
      "Forming the grid-search model #5 using: optimizer=<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7fe1d6395990>, kernel=<tensorflow.python.ops.init_ops_v2.Orthogonal object at 0x7fe1b03bd4d0>, epochs=50, batch_size=128\n",
      "Train on 112 samples, validate on 38 samples\n",
      "Epoch 1/50\n",
      "112/112 [==============================] - 1s 11ms/sample - loss: 1.2377 - accuracy: 0.2679 - val_loss: 1.2036 - val_accuracy: 0.3421\n",
      "Epoch 2/50\n",
      "112/112 [==============================] - 0s 224us/sample - loss: 1.2251 - accuracy: 0.2946 - val_loss: 1.1849 - val_accuracy: 0.3421\n",
      "Epoch 3/50\n",
      "112/112 [==============================] - 0s 233us/sample - loss: 1.2083 - accuracy: 0.3125 - val_loss: 1.1635 - val_accuracy: 0.3684\n",
      "Epoch 4/50\n",
      "112/112 [==============================] - 0s 226us/sample - loss: 1.1891 - accuracy: 0.3304 - val_loss: 1.1406 - val_accuracy: 0.4211\n",
      "Epoch 5/50\n",
      "112/112 [==============================] - 0s 223us/sample - loss: 1.1685 - accuracy: 0.3393 - val_loss: 1.1170 - val_accuracy: 0.4211\n",
      "Epoch 6/50\n",
      "112/112 [==============================] - 0s 289us/sample - loss: 1.1472 - accuracy: 0.3750 - val_loss: 1.0930 - val_accuracy: 0.4211\n",
      "Epoch 7/50\n",
      "112/112 [==============================] - 0s 235us/sample - loss: 1.1256 - accuracy: 0.4018 - val_loss: 1.0690 - val_accuracy: 0.4211\n",
      "Epoch 8/50\n",
      "112/112 [==============================] - 0s 237us/sample - loss: 1.1040 - accuracy: 0.4107 - val_loss: 1.0451 - val_accuracy: 0.4474\n",
      "Epoch 9/50\n",
      "112/112 [==============================] - 0s 234us/sample - loss: 1.0825 - accuracy: 0.4107 - val_loss: 1.0216 - val_accuracy: 0.4737\n",
      "Epoch 10/50\n",
      "112/112 [==============================] - 0s 229us/sample - loss: 1.0614 - accuracy: 0.4464 - val_loss: 0.9987 - val_accuracy: 0.5526\n",
      "Epoch 11/50\n",
      "112/112 [==============================] - 0s 231us/sample - loss: 1.0406 - accuracy: 0.4464 - val_loss: 0.9763 - val_accuracy: 0.6053\n",
      "Epoch 12/50\n",
      "112/112 [==============================] - 0s 230us/sample - loss: 1.0203 - accuracy: 0.4911 - val_loss: 0.9546 - val_accuracy: 0.6842\n",
      "Epoch 13/50\n",
      "112/112 [==============================] - 0s 251us/sample - loss: 1.0006 - accuracy: 0.5714 - val_loss: 0.9334 - val_accuracy: 0.7632\n",
      "Epoch 14/50\n",
      "112/112 [==============================] - 0s 239us/sample - loss: 0.9816 - accuracy: 0.6071 - val_loss: 0.9130 - val_accuracy: 0.8158\n",
      "Epoch 15/50\n",
      "112/112 [==============================] - 0s 231us/sample - loss: 0.9631 - accuracy: 0.6429 - val_loss: 0.8932 - val_accuracy: 0.8684\n",
      "Epoch 16/50\n",
      "112/112 [==============================] - 0s 236us/sample - loss: 0.9453 - accuracy: 0.6964 - val_loss: 0.8740 - val_accuracy: 0.8947\n",
      "Epoch 17/50\n",
      "112/112 [==============================] - 0s 233us/sample - loss: 0.9280 - accuracy: 0.7232 - val_loss: 0.8553 - val_accuracy: 0.9211\n",
      "Epoch 18/50\n",
      "112/112 [==============================] - 0s 223us/sample - loss: 0.9113 - accuracy: 0.7500 - val_loss: 0.8371 - val_accuracy: 0.9211\n",
      "Epoch 19/50\n",
      "112/112 [==============================] - 0s 229us/sample - loss: 0.8953 - accuracy: 0.7500 - val_loss: 0.8195 - val_accuracy: 0.9211\n",
      "Epoch 20/50\n",
      "112/112 [==============================] - 0s 233us/sample - loss: 0.8798 - accuracy: 0.7500 - val_loss: 0.8023 - val_accuracy: 0.9211\n",
      "Epoch 21/50\n",
      "112/112 [==============================] - 0s 234us/sample - loss: 0.8647 - accuracy: 0.7500 - val_loss: 0.7856 - val_accuracy: 0.9211\n",
      "Epoch 22/50\n",
      "112/112 [==============================] - 0s 229us/sample - loss: 0.8500 - accuracy: 0.7500 - val_loss: 0.7695 - val_accuracy: 0.9211\n",
      "Epoch 23/50\n",
      "112/112 [==============================] - 0s 230us/sample - loss: 0.8357 - accuracy: 0.7500 - val_loss: 0.7538 - val_accuracy: 0.8947\n",
      "Epoch 24/50\n",
      "112/112 [==============================] - 0s 227us/sample - loss: 0.8219 - accuracy: 0.7500 - val_loss: 0.7386 - val_accuracy: 0.8947\n",
      "Epoch 25/50\n",
      "112/112 [==============================] - 0s 246us/sample - loss: 0.8083 - accuracy: 0.7500 - val_loss: 0.7239 - val_accuracy: 0.9211\n",
      "Epoch 26/50\n",
      "112/112 [==============================] - 0s 245us/sample - loss: 0.7952 - accuracy: 0.7768 - val_loss: 0.7096 - val_accuracy: 0.9211\n",
      "Epoch 27/50\n",
      "112/112 [==============================] - 0s 226us/sample - loss: 0.7824 - accuracy: 0.7768 - val_loss: 0.6958 - val_accuracy: 0.9211\n",
      "Epoch 28/50\n",
      "112/112 [==============================] - 0s 238us/sample - loss: 0.7700 - accuracy: 0.7857 - val_loss: 0.6825 - val_accuracy: 0.9211\n",
      "Epoch 29/50\n",
      "112/112 [==============================] - 0s 244us/sample - loss: 0.7580 - accuracy: 0.7857 - val_loss: 0.6697 - val_accuracy: 0.9211\n",
      "Epoch 30/50\n",
      "112/112 [==============================] - 0s 259us/sample - loss: 0.7463 - accuracy: 0.7857 - val_loss: 0.6572 - val_accuracy: 0.9211\n",
      "Epoch 31/50\n",
      "112/112 [==============================] - 0s 232us/sample - loss: 0.7349 - accuracy: 0.7946 - val_loss: 0.6450 - val_accuracy: 0.9211\n",
      "Epoch 32/50\n",
      "112/112 [==============================] - 0s 224us/sample - loss: 0.7238 - accuracy: 0.7946 - val_loss: 0.6333 - val_accuracy: 0.9211\n",
      "Epoch 33/50\n",
      "112/112 [==============================] - 0s 233us/sample - loss: 0.7129 - accuracy: 0.7946 - val_loss: 0.6218 - val_accuracy: 0.9211\n",
      "Epoch 34/50\n",
      "112/112 [==============================] - 0s 269us/sample - loss: 0.7023 - accuracy: 0.7946 - val_loss: 0.6107 - val_accuracy: 0.9211\n",
      "Epoch 35/50\n",
      "112/112 [==============================] - 0s 237us/sample - loss: 0.6920 - accuracy: 0.7946 - val_loss: 0.6000 - val_accuracy: 0.9211\n",
      "Epoch 36/50\n",
      "112/112 [==============================] - 0s 228us/sample - loss: 0.6819 - accuracy: 0.7946 - val_loss: 0.5896 - val_accuracy: 0.9211\n",
      "Epoch 37/50\n",
      "112/112 [==============================] - 0s 244us/sample - loss: 0.6721 - accuracy: 0.8036 - val_loss: 0.5795 - val_accuracy: 0.9211\n",
      "Epoch 38/50\n",
      "112/112 [==============================] - 0s 224us/sample - loss: 0.6625 - accuracy: 0.8125 - val_loss: 0.5698 - val_accuracy: 0.9211\n",
      "Epoch 39/50\n",
      "112/112 [==============================] - 0s 230us/sample - loss: 0.6532 - accuracy: 0.8125 - val_loss: 0.5604 - val_accuracy: 0.9211\n",
      "Epoch 40/50\n",
      "112/112 [==============================] - 0s 240us/sample - loss: 0.6441 - accuracy: 0.8125 - val_loss: 0.5513 - val_accuracy: 0.9211\n",
      "Epoch 41/50\n",
      "112/112 [==============================] - 0s 215us/sample - loss: 0.6352 - accuracy: 0.8125 - val_loss: 0.5424 - val_accuracy: 0.9211\n",
      "Epoch 42/50\n",
      "112/112 [==============================] - 0s 223us/sample - loss: 0.6266 - accuracy: 0.8125 - val_loss: 0.5339 - val_accuracy: 0.9211\n",
      "Epoch 43/50\n",
      "112/112 [==============================] - 0s 232us/sample - loss: 0.6181 - accuracy: 0.8125 - val_loss: 0.5256 - val_accuracy: 0.9211\n",
      "Epoch 44/50\n",
      "112/112 [==============================] - 0s 228us/sample - loss: 0.6098 - accuracy: 0.8125 - val_loss: 0.5175 - val_accuracy: 0.9211\n",
      "Epoch 45/50\n",
      "112/112 [==============================] - 0s 232us/sample - loss: 0.6018 - accuracy: 0.8214 - val_loss: 0.5097 - val_accuracy: 0.9211\n",
      "Epoch 46/50\n",
      "112/112 [==============================] - 0s 228us/sample - loss: 0.5940 - accuracy: 0.8214 - val_loss: 0.5022 - val_accuracy: 0.9211\n",
      "Epoch 47/50\n",
      "112/112 [==============================] - 0s 224us/sample - loss: 0.5863 - accuracy: 0.8214 - val_loss: 0.4949 - val_accuracy: 0.9211\n",
      "Epoch 48/50\n",
      "112/112 [==============================] - 0s 225us/sample - loss: 0.5789 - accuracy: 0.8214 - val_loss: 0.4878 - val_accuracy: 0.9211\n",
      "Epoch 49/50\n",
      "112/112 [==============================] - 0s 241us/sample - loss: 0.5716 - accuracy: 0.8214 - val_loss: 0.4809 - val_accuracy: 0.9211\n",
      "Epoch 50/50\n",
      "112/112 [==============================] - 0s 230us/sample - loss: 0.5645 - accuracy: 0.8214 - val_loss: 0.4742 - val_accuracy: 0.9211\n",
      "\n",
      "Forming the grid-search model #6 using: optimizer=<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7fe1d6395990>, kernel=<tensorflow.python.ops.init_ops_v2.GlorotNormal object at 0x7fe1b03bd290>, epochs=50, batch_size=32\n",
      "Train on 112 samples, validate on 38 samples\n",
      "Epoch 1/50\n",
      "112/112 [==============================] - 1s 9ms/sample - loss: 1.3366 - accuracy: 0.4196 - val_loss: 1.1799 - val_accuracy: 0.5000\n",
      "Epoch 2/50\n",
      "112/112 [==============================] - 0s 343us/sample - loss: 1.2077 - accuracy: 0.4464 - val_loss: 1.0347 - val_accuracy: 0.5263\n",
      "Epoch 3/50\n",
      "112/112 [==============================] - 0s 353us/sample - loss: 1.0563 - accuracy: 0.4643 - val_loss: 0.8959 - val_accuracy: 0.5526\n",
      "Epoch 4/50\n",
      "112/112 [==============================] - 0s 335us/sample - loss: 0.9328 - accuracy: 0.5179 - val_loss: 0.7739 - val_accuracy: 0.6842\n",
      "Epoch 5/50\n",
      "112/112 [==============================] - 0s 352us/sample - loss: 0.8120 - accuracy: 0.6607 - val_loss: 0.6785 - val_accuracy: 0.8684\n",
      "Epoch 6/50\n",
      "112/112 [==============================] - 0s 356us/sample - loss: 0.7189 - accuracy: 0.7679 - val_loss: 0.6060 - val_accuracy: 0.8684\n",
      "Epoch 7/50\n",
      "112/112 [==============================] - 0s 341us/sample - loss: 0.6529 - accuracy: 0.8125 - val_loss: 0.5504 - val_accuracy: 0.8684\n",
      "Epoch 8/50\n",
      "112/112 [==============================] - 0s 356us/sample - loss: 0.6011 - accuracy: 0.8125 - val_loss: 0.5082 - val_accuracy: 0.8684\n",
      "Epoch 9/50\n",
      "112/112 [==============================] - 0s 343us/sample - loss: 0.5606 - accuracy: 0.8125 - val_loss: 0.4755 - val_accuracy: 0.8684\n",
      "Epoch 10/50\n",
      "112/112 [==============================] - 0s 329us/sample - loss: 0.5287 - accuracy: 0.8214 - val_loss: 0.4494 - val_accuracy: 0.8684\n",
      "Epoch 11/50\n",
      "112/112 [==============================] - 0s 432us/sample - loss: 0.5028 - accuracy: 0.8214 - val_loss: 0.4282 - val_accuracy: 0.8684\n",
      "Epoch 12/50\n",
      "112/112 [==============================] - 0s 346us/sample - loss: 0.4817 - accuracy: 0.8304 - val_loss: 0.4107 - val_accuracy: 0.8684\n",
      "Epoch 13/50\n",
      "112/112 [==============================] - 0s 360us/sample - loss: 0.4633 - accuracy: 0.8214 - val_loss: 0.3961 - val_accuracy: 0.8684\n",
      "Epoch 14/50\n",
      "112/112 [==============================] - 0s 351us/sample - loss: 0.4481 - accuracy: 0.8214 - val_loss: 0.3833 - val_accuracy: 0.8684\n",
      "Epoch 15/50\n",
      "112/112 [==============================] - 0s 351us/sample - loss: 0.4350 - accuracy: 0.8214 - val_loss: 0.3725 - val_accuracy: 0.8947\n",
      "Epoch 16/50\n",
      "112/112 [==============================] - 0s 353us/sample - loss: 0.4232 - accuracy: 0.8214 - val_loss: 0.3624 - val_accuracy: 0.8947\n",
      "Epoch 17/50\n",
      "112/112 [==============================] - 0s 357us/sample - loss: 0.4125 - accuracy: 0.8214 - val_loss: 0.3538 - val_accuracy: 0.8947\n",
      "Epoch 18/50\n",
      "112/112 [==============================] - 0s 357us/sample - loss: 0.4027 - accuracy: 0.8304 - val_loss: 0.3462 - val_accuracy: 0.8947\n",
      "Epoch 19/50\n",
      "112/112 [==============================] - 0s 362us/sample - loss: 0.3945 - accuracy: 0.8304 - val_loss: 0.3396 - val_accuracy: 0.8947\n",
      "Epoch 20/50\n",
      "112/112 [==============================] - 0s 382us/sample - loss: 0.3862 - accuracy: 0.8304 - val_loss: 0.3331 - val_accuracy: 0.8947\n",
      "Epoch 21/50\n",
      "112/112 [==============================] - 0s 333us/sample - loss: 0.3788 - accuracy: 0.8393 - val_loss: 0.3276 - val_accuracy: 0.8947\n",
      "Epoch 22/50\n",
      "112/112 [==============================] - 0s 347us/sample - loss: 0.3719 - accuracy: 0.8482 - val_loss: 0.3221 - val_accuracy: 0.9211\n",
      "Epoch 23/50\n",
      "112/112 [==============================] - 0s 336us/sample - loss: 0.3654 - accuracy: 0.8482 - val_loss: 0.3170 - val_accuracy: 0.9211\n",
      "Epoch 24/50\n",
      "112/112 [==============================] - 0s 350us/sample - loss: 0.3592 - accuracy: 0.8482 - val_loss: 0.3122 - val_accuracy: 0.9211\n",
      "Epoch 25/50\n",
      "112/112 [==============================] - 0s 339us/sample - loss: 0.3535 - accuracy: 0.8482 - val_loss: 0.3078 - val_accuracy: 0.9211\n",
      "Epoch 26/50\n",
      "112/112 [==============================] - 0s 337us/sample - loss: 0.3479 - accuracy: 0.8482 - val_loss: 0.3033 - val_accuracy: 0.9211\n",
      "Epoch 27/50\n",
      "112/112 [==============================] - 0s 337us/sample - loss: 0.3428 - accuracy: 0.8482 - val_loss: 0.2995 - val_accuracy: 0.9211\n",
      "Epoch 28/50\n",
      "112/112 [==============================] - 0s 346us/sample - loss: 0.3377 - accuracy: 0.8482 - val_loss: 0.2956 - val_accuracy: 0.9211\n",
      "Epoch 29/50\n",
      "112/112 [==============================] - 0s 344us/sample - loss: 0.3327 - accuracy: 0.8482 - val_loss: 0.2921 - val_accuracy: 0.9211\n",
      "Epoch 30/50\n",
      "112/112 [==============================] - 0s 329us/sample - loss: 0.3283 - accuracy: 0.8482 - val_loss: 0.2887 - val_accuracy: 0.9211\n",
      "Epoch 31/50\n",
      "112/112 [==============================] - 0s 343us/sample - loss: 0.3236 - accuracy: 0.8571 - val_loss: 0.2854 - val_accuracy: 0.9474\n",
      "Epoch 32/50\n",
      "112/112 [==============================] - 0s 353us/sample - loss: 0.3191 - accuracy: 0.8571 - val_loss: 0.2825 - val_accuracy: 0.9474\n",
      "Epoch 33/50\n",
      "112/112 [==============================] - 0s 357us/sample - loss: 0.3147 - accuracy: 0.8571 - val_loss: 0.2794 - val_accuracy: 0.9474\n",
      "Epoch 34/50\n",
      "112/112 [==============================] - 0s 347us/sample - loss: 0.3106 - accuracy: 0.8571 - val_loss: 0.2761 - val_accuracy: 0.9474\n",
      "Epoch 35/50\n",
      "112/112 [==============================] - 0s 351us/sample - loss: 0.3067 - accuracy: 0.8661 - val_loss: 0.2729 - val_accuracy: 0.9474\n",
      "Epoch 36/50\n",
      "112/112 [==============================] - 0s 343us/sample - loss: 0.3023 - accuracy: 0.8661 - val_loss: 0.2699 - val_accuracy: 0.9474\n",
      "Epoch 37/50\n",
      "112/112 [==============================] - 0s 458us/sample - loss: 0.2986 - accuracy: 0.8661 - val_loss: 0.2668 - val_accuracy: 0.9474\n",
      "Epoch 38/50\n",
      "112/112 [==============================] - 0s 335us/sample - loss: 0.2948 - accuracy: 0.8839 - val_loss: 0.2638 - val_accuracy: 0.9474\n",
      "Epoch 39/50\n",
      "112/112 [==============================] - 0s 350us/sample - loss: 0.2913 - accuracy: 0.8839 - val_loss: 0.2613 - val_accuracy: 0.9474\n",
      "Epoch 40/50\n",
      "112/112 [==============================] - 0s 336us/sample - loss: 0.2877 - accuracy: 0.8839 - val_loss: 0.2585 - val_accuracy: 0.9474\n",
      "Epoch 41/50\n",
      "112/112 [==============================] - 0s 348us/sample - loss: 0.2844 - accuracy: 0.8839 - val_loss: 0.2560 - val_accuracy: 0.9474\n",
      "Epoch 42/50\n",
      "112/112 [==============================] - 0s 317us/sample - loss: 0.2811 - accuracy: 0.8839 - val_loss: 0.2534 - val_accuracy: 0.9474\n",
      "Epoch 43/50\n",
      "112/112 [==============================] - 0s 332us/sample - loss: 0.2775 - accuracy: 0.8929 - val_loss: 0.2510 - val_accuracy: 0.9474\n",
      "Epoch 44/50\n",
      "112/112 [==============================] - 0s 338us/sample - loss: 0.2743 - accuracy: 0.8929 - val_loss: 0.2489 - val_accuracy: 0.9474\n",
      "Epoch 45/50\n",
      "112/112 [==============================] - 0s 491us/sample - loss: 0.2714 - accuracy: 0.8929 - val_loss: 0.2465 - val_accuracy: 0.9474\n",
      "Epoch 46/50\n",
      "112/112 [==============================] - 0s 354us/sample - loss: 0.2682 - accuracy: 0.8929 - val_loss: 0.2442 - val_accuracy: 0.9474\n",
      "Epoch 47/50\n",
      "112/112 [==============================] - 0s 349us/sample - loss: 0.2650 - accuracy: 0.8929 - val_loss: 0.2420 - val_accuracy: 0.9474\n",
      "Epoch 48/50\n",
      "112/112 [==============================] - 0s 336us/sample - loss: 0.2623 - accuracy: 0.8929 - val_loss: 0.2403 - val_accuracy: 0.9474\n",
      "Epoch 49/50\n",
      "112/112 [==============================] - 0s 342us/sample - loss: 0.2595 - accuracy: 0.8929 - val_loss: 0.2381 - val_accuracy: 0.9474\n",
      "Epoch 50/50\n",
      "112/112 [==============================] - 0s 353us/sample - loss: 0.2567 - accuracy: 0.9018 - val_loss: 0.2365 - val_accuracy: 0.9474\n",
      "\n",
      "Forming the grid-search model #7 using: optimizer=<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7fe1d6395990>, kernel=<tensorflow.python.ops.init_ops_v2.GlorotNormal object at 0x7fe1b03bd290>, epochs=50, batch_size=64\n",
      "Train on 112 samples, validate on 38 samples\n",
      "Epoch 1/50\n",
      "112/112 [==============================] - 1s 9ms/sample - loss: 1.3532 - accuracy: 0.4196 - val_loss: 1.2375 - val_accuracy: 0.5000\n",
      "Epoch 2/50\n",
      "112/112 [==============================] - 0s 267us/sample - loss: 1.2944 - accuracy: 0.4375 - val_loss: 1.1632 - val_accuracy: 0.5000\n",
      "Epoch 3/50\n",
      "112/112 [==============================] - 0s 268us/sample - loss: 1.2161 - accuracy: 0.4464 - val_loss: 1.0829 - val_accuracy: 0.5263\n",
      "Epoch 4/50\n",
      "112/112 [==============================] - 0s 272us/sample - loss: 1.1432 - accuracy: 0.4554 - val_loss: 1.0016 - val_accuracy: 0.5263\n",
      "Epoch 5/50\n",
      "112/112 [==============================] - 0s 269us/sample - loss: 1.0604 - accuracy: 0.4643 - val_loss: 0.9240 - val_accuracy: 0.5263\n",
      "Epoch 6/50\n",
      "112/112 [==============================] - 0s 282us/sample - loss: 0.9769 - accuracy: 0.4732 - val_loss: 0.8516 - val_accuracy: 0.5789\n",
      "Epoch 7/50\n",
      "112/112 [==============================] - ETA: 0s - loss: 0.9227 - accuracy: 0.54 - 0s 315us/sample - loss: 0.9074 - accuracy: 0.5089 - val_loss: 0.7849 - val_accuracy: 0.6579\n",
      "Epoch 8/50\n",
      "112/112 [==============================] - 0s 263us/sample - loss: 0.8418 - accuracy: 0.5982 - val_loss: 0.7257 - val_accuracy: 0.8158\n",
      "Epoch 9/50\n",
      "112/112 [==============================] - 0s 279us/sample - loss: 0.7819 - accuracy: 0.7232 - val_loss: 0.6745 - val_accuracy: 0.8684\n",
      "Epoch 10/50\n",
      "112/112 [==============================] - 0s 279us/sample - loss: 0.7336 - accuracy: 0.7679 - val_loss: 0.6301 - val_accuracy: 0.8684\n",
      "Epoch 11/50\n",
      "112/112 [==============================] - 0s 274us/sample - loss: 0.6891 - accuracy: 0.8125 - val_loss: 0.5921 - val_accuracy: 0.8684\n",
      "Epoch 12/50\n",
      "112/112 [==============================] - 0s 265us/sample - loss: 0.6512 - accuracy: 0.8125 - val_loss: 0.5595 - val_accuracy: 0.8684\n",
      "Epoch 13/50\n",
      "112/112 [==============================] - 0s 257us/sample - loss: 0.6181 - accuracy: 0.8125 - val_loss: 0.5315 - val_accuracy: 0.8684\n",
      "Epoch 14/50\n",
      "112/112 [==============================] - 0s 250us/sample - loss: 0.5904 - accuracy: 0.8125 - val_loss: 0.5073 - val_accuracy: 0.8684\n",
      "Epoch 15/50\n",
      "112/112 [==============================] - 0s 278us/sample - loss: 0.5663 - accuracy: 0.8125 - val_loss: 0.4865 - val_accuracy: 0.8684\n",
      "Epoch 16/50\n",
      "112/112 [==============================] - 0s 278us/sample - loss: 0.5454 - accuracy: 0.8125 - val_loss: 0.4681 - val_accuracy: 0.8684\n",
      "Epoch 17/50\n",
      "112/112 [==============================] - 0s 265us/sample - loss: 0.5260 - accuracy: 0.8214 - val_loss: 0.4523 - val_accuracy: 0.8684\n",
      "Epoch 18/50\n",
      "112/112 [==============================] - 0s 263us/sample - loss: 0.5095 - accuracy: 0.8214 - val_loss: 0.4384 - val_accuracy: 0.8684\n",
      "Epoch 19/50\n",
      "112/112 [==============================] - 0s 279us/sample - loss: 0.4949 - accuracy: 0.8214 - val_loss: 0.4260 - val_accuracy: 0.8684\n",
      "Epoch 20/50\n",
      "112/112 [==============================] - 0s 279us/sample - loss: 0.4819 - accuracy: 0.8304 - val_loss: 0.4149 - val_accuracy: 0.8684\n",
      "Epoch 21/50\n",
      "112/112 [==============================] - 0s 265us/sample - loss: 0.4697 - accuracy: 0.8214 - val_loss: 0.4050 - val_accuracy: 0.8684\n",
      "Epoch 22/50\n",
      "112/112 [==============================] - 0s 277us/sample - loss: 0.4587 - accuracy: 0.8304 - val_loss: 0.3959 - val_accuracy: 0.8684\n",
      "Epoch 23/50\n",
      "112/112 [==============================] - 0s 257us/sample - loss: 0.4487 - accuracy: 0.8304 - val_loss: 0.3875 - val_accuracy: 0.8684\n",
      "Epoch 24/50\n",
      "112/112 [==============================] - 0s 264us/sample - loss: 0.4396 - accuracy: 0.8214 - val_loss: 0.3799 - val_accuracy: 0.8684\n",
      "Epoch 25/50\n",
      "112/112 [==============================] - 0s 275us/sample - loss: 0.4311 - accuracy: 0.8214 - val_loss: 0.3730 - val_accuracy: 0.8684\n",
      "Epoch 26/50\n",
      "112/112 [==============================] - 0s 340us/sample - loss: 0.4231 - accuracy: 0.8214 - val_loss: 0.3664 - val_accuracy: 0.8684\n",
      "Epoch 27/50\n",
      "112/112 [==============================] - 0s 278us/sample - loss: 0.4160 - accuracy: 0.8214 - val_loss: 0.3606 - val_accuracy: 0.8947\n",
      "Epoch 28/50\n",
      "112/112 [==============================] - 0s 282us/sample - loss: 0.4088 - accuracy: 0.8214 - val_loss: 0.3550 - val_accuracy: 0.9211\n",
      "Epoch 29/50\n",
      "112/112 [==============================] - 0s 281us/sample - loss: 0.4024 - accuracy: 0.8304 - val_loss: 0.3499 - val_accuracy: 0.9211\n",
      "Epoch 30/50\n",
      "112/112 [==============================] - 0s 293us/sample - loss: 0.3963 - accuracy: 0.8304 - val_loss: 0.3450 - val_accuracy: 0.9211\n",
      "Epoch 31/50\n",
      "112/112 [==============================] - 0s 341us/sample - loss: 0.3905 - accuracy: 0.8304 - val_loss: 0.3405 - val_accuracy: 0.9211\n",
      "Epoch 32/50\n",
      "112/112 [==============================] - 0s 280us/sample - loss: 0.3849 - accuracy: 0.8393 - val_loss: 0.3364 - val_accuracy: 0.9211\n",
      "Epoch 33/50\n",
      "112/112 [==============================] - 0s 274us/sample - loss: 0.3795 - accuracy: 0.8482 - val_loss: 0.3324 - val_accuracy: 0.9211\n",
      "Epoch 34/50\n",
      "112/112 [==============================] - 0s 3ms/sample - loss: 0.3746 - accuracy: 0.8482 - val_loss: 0.3286 - val_accuracy: 0.9211\n",
      "Epoch 35/50\n",
      "112/112 [==============================] - 0s 257us/sample - loss: 0.3699 - accuracy: 0.8482 - val_loss: 0.3250 - val_accuracy: 0.9211\n",
      "Epoch 36/50\n",
      "112/112 [==============================] - 0s 278us/sample - loss: 0.3651 - accuracy: 0.8482 - val_loss: 0.3216 - val_accuracy: 0.9211\n",
      "Epoch 37/50\n",
      "112/112 [==============================] - 0s 288us/sample - loss: 0.3607 - accuracy: 0.8482 - val_loss: 0.3183 - val_accuracy: 0.9211\n",
      "Epoch 38/50\n",
      "112/112 [==============================] - 0s 283us/sample - loss: 0.3564 - accuracy: 0.8571 - val_loss: 0.3152 - val_accuracy: 0.9211\n",
      "Epoch 39/50\n",
      "112/112 [==============================] - 0s 287us/sample - loss: 0.3523 - accuracy: 0.8571 - val_loss: 0.3121 - val_accuracy: 0.9211\n",
      "Epoch 40/50\n",
      "112/112 [==============================] - 0s 352us/sample - loss: 0.3482 - accuracy: 0.8571 - val_loss: 0.3091 - val_accuracy: 0.9211\n",
      "Epoch 41/50\n",
      "112/112 [==============================] - 0s 279us/sample - loss: 0.3445 - accuracy: 0.8571 - val_loss: 0.3062 - val_accuracy: 0.9211\n",
      "Epoch 42/50\n",
      "112/112 [==============================] - 0s 271us/sample - loss: 0.3408 - accuracy: 0.8571 - val_loss: 0.3034 - val_accuracy: 0.9211\n",
      "Epoch 43/50\n",
      "112/112 [==============================] - 0s 269us/sample - loss: 0.3370 - accuracy: 0.8571 - val_loss: 0.3008 - val_accuracy: 0.9474\n",
      "Epoch 44/50\n",
      "112/112 [==============================] - 0s 281us/sample - loss: 0.3335 - accuracy: 0.8571 - val_loss: 0.2981 - val_accuracy: 0.9474\n",
      "Epoch 45/50\n",
      "112/112 [==============================] - 0s 275us/sample - loss: 0.3304 - accuracy: 0.8571 - val_loss: 0.2955 - val_accuracy: 0.9474\n",
      "Epoch 46/50\n",
      "112/112 [==============================] - 0s 278us/sample - loss: 0.3268 - accuracy: 0.8571 - val_loss: 0.2929 - val_accuracy: 0.9474\n",
      "Epoch 47/50\n",
      "112/112 [==============================] - 0s 282us/sample - loss: 0.3235 - accuracy: 0.8571 - val_loss: 0.2905 - val_accuracy: 0.9474\n",
      "Epoch 48/50\n",
      "112/112 [==============================] - 0s 286us/sample - loss: 0.3202 - accuracy: 0.8571 - val_loss: 0.2882 - val_accuracy: 0.9474\n",
      "Epoch 49/50\n",
      "112/112 [==============================] - 0s 272us/sample - loss: 0.3172 - accuracy: 0.8571 - val_loss: 0.2859 - val_accuracy: 0.9474\n",
      "Epoch 50/50\n",
      "112/112 [==============================] - 0s 278us/sample - loss: 0.3141 - accuracy: 0.8571 - val_loss: 0.2838 - val_accuracy: 0.9474\n",
      "\n",
      "Forming the grid-search model #8 using: optimizer=<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7fe1d6395990>, kernel=<tensorflow.python.ops.init_ops_v2.GlorotNormal object at 0x7fe1b03bd290>, epochs=50, batch_size=128\n",
      "Train on 112 samples, validate on 38 samples\n",
      "Epoch 1/50\n",
      "112/112 [==============================] - 1s 8ms/sample - loss: 1.3623 - accuracy: 0.4196 - val_loss: 1.2679 - val_accuracy: 0.5000\n",
      "Epoch 2/50\n",
      "112/112 [==============================] - 0s 219us/sample - loss: 1.3385 - accuracy: 0.4196 - val_loss: 1.2353 - val_accuracy: 0.5000\n",
      "Epoch 3/50\n",
      "112/112 [==============================] - 0s 230us/sample - loss: 1.3068 - accuracy: 0.4375 - val_loss: 1.1980 - val_accuracy: 0.5000\n",
      "Epoch 4/50\n",
      "112/112 [==============================] - 0s 222us/sample - loss: 1.2703 - accuracy: 0.4375 - val_loss: 1.1579 - val_accuracy: 0.5000\n",
      "Epoch 5/50\n",
      "112/112 [==============================] - 0s 228us/sample - loss: 1.2308 - accuracy: 0.4375 - val_loss: 1.1163 - val_accuracy: 0.5263\n",
      "Epoch 6/50\n",
      "112/112 [==============================] - 0s 236us/sample - loss: 1.1895 - accuracy: 0.4554 - val_loss: 1.0738 - val_accuracy: 0.5263\n",
      "Epoch 7/50\n",
      "112/112 [==============================] - 0s 224us/sample - loss: 1.1470 - accuracy: 0.4554 - val_loss: 1.0311 - val_accuracy: 0.5263\n",
      "Epoch 8/50\n",
      "112/112 [==============================] - 0s 232us/sample - loss: 1.1043 - accuracy: 0.4643 - val_loss: 0.9891 - val_accuracy: 0.5526\n",
      "Epoch 9/50\n",
      "112/112 [==============================] - 0s 230us/sample - loss: 1.0619 - accuracy: 0.4732 - val_loss: 0.9477 - val_accuracy: 0.5526\n",
      "Epoch 10/50\n",
      "112/112 [==============================] - 0s 293us/sample - loss: 1.0201 - accuracy: 0.4732 - val_loss: 0.9076 - val_accuracy: 0.5526\n",
      "Epoch 11/50\n",
      "112/112 [==============================] - 0s 232us/sample - loss: 0.9793 - accuracy: 0.4821 - val_loss: 0.8688 - val_accuracy: 0.5526\n",
      "Epoch 12/50\n",
      "112/112 [==============================] - 0s 236us/sample - loss: 0.9399 - accuracy: 0.4821 - val_loss: 0.8315 - val_accuracy: 0.5789\n",
      "Epoch 13/50\n",
      "112/112 [==============================] - 0s 233us/sample - loss: 0.9022 - accuracy: 0.5179 - val_loss: 0.7960 - val_accuracy: 0.6316\n",
      "Epoch 14/50\n",
      "112/112 [==============================] - 0s 235us/sample - loss: 0.8660 - accuracy: 0.5446 - val_loss: 0.7624 - val_accuracy: 0.6842\n",
      "Epoch 15/50\n",
      "112/112 [==============================] - 0s 230us/sample - loss: 0.8318 - accuracy: 0.6161 - val_loss: 0.7309 - val_accuracy: 0.7632\n",
      "Epoch 16/50\n",
      "112/112 [==============================] - 0s 249us/sample - loss: 0.8000 - accuracy: 0.6875 - val_loss: 0.7016 - val_accuracy: 0.8421\n",
      "Epoch 17/50\n",
      "112/112 [==============================] - 0s 232us/sample - loss: 0.7705 - accuracy: 0.7232 - val_loss: 0.6743 - val_accuracy: 0.8684\n",
      "Epoch 18/50\n",
      "112/112 [==============================] - 0s 226us/sample - loss: 0.7430 - accuracy: 0.7589 - val_loss: 0.6490 - val_accuracy: 0.8684\n",
      "Epoch 19/50\n",
      "112/112 [==============================] - 0s 233us/sample - loss: 0.7175 - accuracy: 0.7857 - val_loss: 0.6257 - val_accuracy: 0.8684\n",
      "Epoch 20/50\n",
      "112/112 [==============================] - 0s 228us/sample - loss: 0.6939 - accuracy: 0.7946 - val_loss: 0.6042 - val_accuracy: 0.8684\n",
      "Epoch 21/50\n",
      "112/112 [==============================] - 0s 241us/sample - loss: 0.6720 - accuracy: 0.8125 - val_loss: 0.5844 - val_accuracy: 0.8684\n",
      "Epoch 22/50\n",
      "112/112 [==============================] - 0s 228us/sample - loss: 0.6516 - accuracy: 0.8125 - val_loss: 0.5663 - val_accuracy: 0.8684\n",
      "Epoch 23/50\n",
      "112/112 [==============================] - 0s 238us/sample - loss: 0.6327 - accuracy: 0.8125 - val_loss: 0.5496 - val_accuracy: 0.8684\n",
      "Epoch 24/50\n",
      "112/112 [==============================] - 0s 228us/sample - loss: 0.6152 - accuracy: 0.8125 - val_loss: 0.5341 - val_accuracy: 0.8684\n",
      "Epoch 25/50\n",
      "112/112 [==============================] - 0s 226us/sample - loss: 0.5989 - accuracy: 0.8125 - val_loss: 0.5200 - val_accuracy: 0.8684\n",
      "Epoch 26/50\n",
      "112/112 [==============================] - 0s 218us/sample - loss: 0.5838 - accuracy: 0.8125 - val_loss: 0.5070 - val_accuracy: 0.8684\n",
      "Epoch 27/50\n",
      "112/112 [==============================] - 0s 234us/sample - loss: 0.5698 - accuracy: 0.8125 - val_loss: 0.4950 - val_accuracy: 0.8684\n",
      "Epoch 28/50\n",
      "112/112 [==============================] - 0s 283us/sample - loss: 0.5567 - accuracy: 0.8214 - val_loss: 0.4839 - val_accuracy: 0.8684\n",
      "Epoch 29/50\n",
      "112/112 [==============================] - 0s 233us/sample - loss: 0.5445 - accuracy: 0.8214 - val_loss: 0.4736 - val_accuracy: 0.8684\n",
      "Epoch 30/50\n",
      "112/112 [==============================] - 0s 236us/sample - loss: 0.5331 - accuracy: 0.8214 - val_loss: 0.4640 - val_accuracy: 0.8684\n",
      "Epoch 31/50\n",
      "112/112 [==============================] - 0s 225us/sample - loss: 0.5225 - accuracy: 0.8214 - val_loss: 0.4552 - val_accuracy: 0.8947\n",
      "Epoch 32/50\n",
      "112/112 [==============================] - 0s 224us/sample - loss: 0.5125 - accuracy: 0.8214 - val_loss: 0.4471 - val_accuracy: 0.8947\n",
      "Epoch 33/50\n",
      "112/112 [==============================] - 0s 219us/sample - loss: 0.5031 - accuracy: 0.8214 - val_loss: 0.4394 - val_accuracy: 0.8947\n",
      "Epoch 34/50\n",
      "112/112 [==============================] - 0s 233us/sample - loss: 0.4943 - accuracy: 0.8214 - val_loss: 0.4323 - val_accuracy: 0.8947\n",
      "Epoch 35/50\n",
      "112/112 [==============================] - 0s 325us/sample - loss: 0.4860 - accuracy: 0.8214 - val_loss: 0.4256 - val_accuracy: 0.8947\n",
      "Epoch 36/50\n",
      "112/112 [==============================] - 0s 234us/sample - loss: 0.4781 - accuracy: 0.8304 - val_loss: 0.4193 - val_accuracy: 0.8947\n",
      "Epoch 37/50\n",
      "112/112 [==============================] - 0s 235us/sample - loss: 0.4706 - accuracy: 0.8304 - val_loss: 0.4134 - val_accuracy: 0.8947\n",
      "Epoch 38/50\n",
      "112/112 [==============================] - 0s 234us/sample - loss: 0.4635 - accuracy: 0.8304 - val_loss: 0.4078 - val_accuracy: 0.8947\n",
      "Epoch 39/50\n",
      "112/112 [==============================] - 0s 234us/sample - loss: 0.4567 - accuracy: 0.8304 - val_loss: 0.4025 - val_accuracy: 0.8947\n",
      "Epoch 40/50\n",
      "112/112 [==============================] - 0s 567us/sample - loss: 0.4502 - accuracy: 0.8304 - val_loss: 0.3975 - val_accuracy: 0.8947\n",
      "Epoch 41/50\n",
      "112/112 [==============================] - 0s 237us/sample - loss: 0.4441 - accuracy: 0.8304 - val_loss: 0.3927 - val_accuracy: 0.8947\n",
      "Epoch 42/50\n",
      "112/112 [==============================] - 0s 241us/sample - loss: 0.4382 - accuracy: 0.8393 - val_loss: 0.3880 - val_accuracy: 0.8947\n",
      "Epoch 43/50\n",
      "112/112 [==============================] - 0s 229us/sample - loss: 0.4326 - accuracy: 0.8571 - val_loss: 0.3836 - val_accuracy: 0.8947\n",
      "Epoch 44/50\n",
      "112/112 [==============================] - 0s 238us/sample - loss: 0.4272 - accuracy: 0.8571 - val_loss: 0.3793 - val_accuracy: 0.8947\n",
      "Epoch 45/50\n",
      "112/112 [==============================] - 0s 238us/sample - loss: 0.4220 - accuracy: 0.8571 - val_loss: 0.3753 - val_accuracy: 0.8947\n",
      "Epoch 46/50\n",
      "112/112 [==============================] - 0s 230us/sample - loss: 0.4170 - accuracy: 0.8571 - val_loss: 0.3714 - val_accuracy: 0.8947\n",
      "Epoch 47/50\n",
      "112/112 [==============================] - 0s 284us/sample - loss: 0.4123 - accuracy: 0.8571 - val_loss: 0.3676 - val_accuracy: 0.8947\n",
      "Epoch 48/50\n",
      "112/112 [==============================] - 0s 236us/sample - loss: 0.4077 - accuracy: 0.8482 - val_loss: 0.3641 - val_accuracy: 0.8947\n",
      "Epoch 49/50\n",
      "112/112 [==============================] - 0s 228us/sample - loss: 0.4032 - accuracy: 0.8482 - val_loss: 0.3606 - val_accuracy: 0.8947\n",
      "Epoch 50/50\n",
      "112/112 [==============================] - 0s 231us/sample - loss: 0.3989 - accuracy: 0.8482 - val_loss: 0.3573 - val_accuracy: 0.8947\n",
      "\n",
      "Forming the grid-search model #9 using: optimizer=<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7fe1d6395290>, kernel=<tensorflow.python.ops.init_ops_v2.RandomNormal object at 0x7fe1b03bde50>, epochs=50, batch_size=32\n",
      "Train on 112 samples, validate on 38 samples\n",
      "Epoch 1/50\n",
      "112/112 [==============================] - 1s 9ms/sample - loss: 1.0961 - accuracy: 0.4554 - val_loss: 1.0931 - val_accuracy: 0.7632\n",
      "Epoch 2/50\n",
      "112/112 [==============================] - 0s 342us/sample - loss: 1.0944 - accuracy: 0.5536 - val_loss: 1.0914 - val_accuracy: 0.8947\n",
      "Epoch 3/50\n",
      "112/112 [==============================] - 0s 343us/sample - loss: 1.0928 - accuracy: 0.6161 - val_loss: 1.0895 - val_accuracy: 0.9211\n",
      "Epoch 4/50\n",
      "112/112 [==============================] - 0s 351us/sample - loss: 1.0911 - accuracy: 0.7321 - val_loss: 1.0875 - val_accuracy: 0.9211\n",
      "Epoch 5/50\n",
      "112/112 [==============================] - 0s 340us/sample - loss: 1.0891 - accuracy: 0.7589 - val_loss: 1.0854 - val_accuracy: 0.9211\n",
      "Epoch 6/50\n",
      "112/112 [==============================] - 0s 341us/sample - loss: 1.0871 - accuracy: 0.7679 - val_loss: 1.0832 - val_accuracy: 0.8947\n",
      "Epoch 7/50\n",
      "112/112 [==============================] - 0s 349us/sample - loss: 1.0850 - accuracy: 0.7679 - val_loss: 1.0809 - val_accuracy: 0.8947\n",
      "Epoch 8/50\n",
      "112/112 [==============================] - 0s 334us/sample - loss: 1.0828 - accuracy: 0.7857 - val_loss: 1.0784 - val_accuracy: 0.8947\n",
      "Epoch 9/50\n",
      "112/112 [==============================] - 0s 335us/sample - loss: 1.0803 - accuracy: 0.8036 - val_loss: 1.0759 - val_accuracy: 0.9211\n",
      "Epoch 10/50\n",
      "112/112 [==============================] - 0s 339us/sample - loss: 1.0778 - accuracy: 0.8036 - val_loss: 1.0732 - val_accuracy: 0.9211\n",
      "Epoch 11/50\n",
      "112/112 [==============================] - 0s 339us/sample - loss: 1.0751 - accuracy: 0.8036 - val_loss: 1.0703 - val_accuracy: 0.9211\n",
      "Epoch 12/50\n",
      "112/112 [==============================] - 0s 396us/sample - loss: 1.0723 - accuracy: 0.8036 - val_loss: 1.0673 - val_accuracy: 0.9211\n",
      "Epoch 13/50\n",
      "112/112 [==============================] - 0s 336us/sample - loss: 1.0693 - accuracy: 0.8036 - val_loss: 1.0641 - val_accuracy: 0.8684\n",
      "Epoch 14/50\n",
      "112/112 [==============================] - 0s 340us/sample - loss: 1.0662 - accuracy: 0.8036 - val_loss: 1.0607 - val_accuracy: 0.8684\n",
      "Epoch 15/50\n",
      "112/112 [==============================] - 0s 336us/sample - loss: 1.0628 - accuracy: 0.8036 - val_loss: 1.0572 - val_accuracy: 0.8684\n",
      "Epoch 16/50\n",
      "112/112 [==============================] - 0s 345us/sample - loss: 1.0594 - accuracy: 0.8036 - val_loss: 1.0534 - val_accuracy: 0.8684\n",
      "Epoch 17/50\n",
      "112/112 [==============================] - 0s 429us/sample - loss: 1.0556 - accuracy: 0.7946 - val_loss: 1.0495 - val_accuracy: 0.8684\n",
      "Epoch 18/50\n",
      "112/112 [==============================] - 0s 332us/sample - loss: 1.0518 - accuracy: 0.7946 - val_loss: 1.0453 - val_accuracy: 0.8684\n",
      "Epoch 19/50\n",
      "112/112 [==============================] - 0s 336us/sample - loss: 1.0475 - accuracy: 0.7946 - val_loss: 1.0410 - val_accuracy: 0.8684\n",
      "Epoch 20/50\n",
      "112/112 [==============================] - 0s 345us/sample - loss: 1.0435 - accuracy: 0.7946 - val_loss: 1.0364 - val_accuracy: 0.8684\n",
      "Epoch 21/50\n",
      "112/112 [==============================] - 0s 335us/sample - loss: 1.0390 - accuracy: 0.7857 - val_loss: 1.0316 - val_accuracy: 0.8684\n",
      "Epoch 22/50\n",
      "112/112 [==============================] - 0s 337us/sample - loss: 1.0343 - accuracy: 0.7857 - val_loss: 1.0266 - val_accuracy: 0.8684\n",
      "Epoch 23/50\n",
      "112/112 [==============================] - 0s 336us/sample - loss: 1.0294 - accuracy: 0.7768 - val_loss: 1.0214 - val_accuracy: 0.8421\n",
      "Epoch 24/50\n",
      "112/112 [==============================] - 0s 341us/sample - loss: 1.0243 - accuracy: 0.7679 - val_loss: 1.0159 - val_accuracy: 0.8421\n",
      "Epoch 25/50\n",
      "112/112 [==============================] - 0s 344us/sample - loss: 1.0189 - accuracy: 0.7679 - val_loss: 1.0103 - val_accuracy: 0.8421\n",
      "Epoch 26/50\n",
      "112/112 [==============================] - 0s 452us/sample - loss: 1.0136 - accuracy: 0.7321 - val_loss: 1.0043 - val_accuracy: 0.8421\n",
      "Epoch 27/50\n",
      "112/112 [==============================] - 0s 351us/sample - loss: 1.0075 - accuracy: 0.7321 - val_loss: 0.9982 - val_accuracy: 0.8421\n",
      "Epoch 28/50\n",
      "112/112 [==============================] - 0s 326us/sample - loss: 1.0018 - accuracy: 0.7321 - val_loss: 0.9918 - val_accuracy: 0.8421\n",
      "Epoch 29/50\n",
      "112/112 [==============================] - 0s 334us/sample - loss: 0.9956 - accuracy: 0.7411 - val_loss: 0.9852 - val_accuracy: 0.7632\n",
      "Epoch 30/50\n",
      "112/112 [==============================] - 0s 332us/sample - loss: 0.9892 - accuracy: 0.7232 - val_loss: 0.9784 - val_accuracy: 0.7632\n",
      "Epoch 31/50\n",
      "112/112 [==============================] - 0s 391us/sample - loss: 0.9826 - accuracy: 0.7232 - val_loss: 0.9715 - val_accuracy: 0.7632\n",
      "Epoch 32/50\n",
      "112/112 [==============================] - 0s 331us/sample - loss: 0.9758 - accuracy: 0.7232 - val_loss: 0.9645 - val_accuracy: 0.7632\n",
      "Epoch 33/50\n",
      "112/112 [==============================] - 0s 332us/sample - loss: 0.9689 - accuracy: 0.7232 - val_loss: 0.9573 - val_accuracy: 0.7632\n",
      "Epoch 34/50\n",
      "112/112 [==============================] - 0s 342us/sample - loss: 0.9622 - accuracy: 0.7143 - val_loss: 0.9497 - val_accuracy: 0.7632\n",
      "Epoch 35/50\n",
      "112/112 [==============================] - 0s 331us/sample - loss: 0.9546 - accuracy: 0.7054 - val_loss: 0.9421 - val_accuracy: 0.7632\n",
      "Epoch 36/50\n",
      "112/112 [==============================] - 0s 465us/sample - loss: 0.9475 - accuracy: 0.7054 - val_loss: 0.9342 - val_accuracy: 0.7632\n",
      "Epoch 37/50\n",
      "112/112 [==============================] - 0s 350us/sample - loss: 0.9398 - accuracy: 0.7054 - val_loss: 0.9262 - val_accuracy: 0.7632\n",
      "Epoch 38/50\n",
      "112/112 [==============================] - 0s 392us/sample - loss: 0.9322 - accuracy: 0.7054 - val_loss: 0.9180 - val_accuracy: 0.7632\n",
      "Epoch 39/50\n",
      "112/112 [==============================] - 0s 375us/sample - loss: 0.9241 - accuracy: 0.6964 - val_loss: 0.9097 - val_accuracy: 0.7632\n",
      "Epoch 40/50\n",
      "112/112 [==============================] - 0s 331us/sample - loss: 0.9165 - accuracy: 0.6964 - val_loss: 0.9012 - val_accuracy: 0.7632\n",
      "Epoch 41/50\n",
      "112/112 [==============================] - 0s 338us/sample - loss: 0.9081 - accuracy: 0.6964 - val_loss: 0.8928 - val_accuracy: 0.7632\n",
      "Epoch 42/50\n",
      "112/112 [==============================] - 0s 349us/sample - loss: 0.8999 - accuracy: 0.6964 - val_loss: 0.8842 - val_accuracy: 0.7632\n",
      "Epoch 43/50\n",
      "112/112 [==============================] - 0s 339us/sample - loss: 0.8918 - accuracy: 0.6875 - val_loss: 0.8754 - val_accuracy: 0.7632\n",
      "Epoch 44/50\n",
      "112/112 [==============================] - 0s 390us/sample - loss: 0.8833 - accuracy: 0.6875 - val_loss: 0.8665 - val_accuracy: 0.7368\n",
      "Epoch 45/50\n",
      "112/112 [==============================] - 0s 330us/sample - loss: 0.8745 - accuracy: 0.6875 - val_loss: 0.8575 - val_accuracy: 0.7105\n",
      "Epoch 46/50\n",
      "112/112 [==============================] - 0s 346us/sample - loss: 0.8658 - accuracy: 0.6875 - val_loss: 0.8484 - val_accuracy: 0.7105\n",
      "Epoch 47/50\n",
      "112/112 [==============================] - 0s 344us/sample - loss: 0.8574 - accuracy: 0.6875 - val_loss: 0.8391 - val_accuracy: 0.7105\n",
      "Epoch 48/50\n",
      "112/112 [==============================] - 0s 329us/sample - loss: 0.8487 - accuracy: 0.6875 - val_loss: 0.8299 - val_accuracy: 0.7105\n",
      "Epoch 49/50\n",
      "112/112 [==============================] - 0s 423us/sample - loss: 0.8397 - accuracy: 0.6875 - val_loss: 0.8207 - val_accuracy: 0.7105\n",
      "Epoch 50/50\n",
      "112/112 [==============================] - 0s 330us/sample - loss: 0.8311 - accuracy: 0.6786 - val_loss: 0.8115 - val_accuracy: 0.7105\n",
      "\n",
      "Forming the grid-search model #10 using: optimizer=<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7fe1d6395290>, kernel=<tensorflow.python.ops.init_ops_v2.RandomNormal object at 0x7fe1b03bde50>, epochs=50, batch_size=64\n",
      "Train on 112 samples, validate on 38 samples\n",
      "Epoch 1/50\n",
      "112/112 [==============================] - 1s 11ms/sample - loss: 1.0963 - accuracy: 0.4643 - val_loss: 1.0934 - val_accuracy: 0.7632\n",
      "Epoch 2/50\n",
      "112/112 [==============================] - 0s 272us/sample - loss: 1.0948 - accuracy: 0.5536 - val_loss: 1.0913 - val_accuracy: 0.8684\n",
      "Epoch 3/50\n",
      "112/112 [==============================] - 0s 288us/sample - loss: 1.0929 - accuracy: 0.6250 - val_loss: 1.0889 - val_accuracy: 0.9211\n",
      "Epoch 4/50\n",
      "112/112 [==============================] - 0s 270us/sample - loss: 1.0907 - accuracy: 0.7232 - val_loss: 1.0861 - val_accuracy: 0.9211\n",
      "Epoch 5/50\n",
      "112/112 [==============================] - 0s 274us/sample - loss: 1.0878 - accuracy: 0.7411 - val_loss: 1.0830 - val_accuracy: 0.8947\n",
      "Epoch 6/50\n",
      "112/112 [==============================] - 0s 294us/sample - loss: 1.0849 - accuracy: 0.7768 - val_loss: 1.0798 - val_accuracy: 0.8947\n",
      "Epoch 7/50\n",
      "112/112 [==============================] - 0s 284us/sample - loss: 1.0817 - accuracy: 0.7857 - val_loss: 1.0764 - val_accuracy: 0.8947\n",
      "Epoch 8/50\n",
      "112/112 [==============================] - 0s 283us/sample - loss: 1.0785 - accuracy: 0.8036 - val_loss: 1.0727 - val_accuracy: 0.9211\n",
      "Epoch 9/50\n",
      "112/112 [==============================] - 0s 283us/sample - loss: 1.0747 - accuracy: 0.8036 - val_loss: 1.0690 - val_accuracy: 0.9211\n",
      "Epoch 10/50\n",
      "112/112 [==============================] - 0s 275us/sample - loss: 1.0710 - accuracy: 0.8036 - val_loss: 1.0649 - val_accuracy: 0.8947\n",
      "Epoch 11/50\n",
      "112/112 [==============================] - 0s 267us/sample - loss: 1.0670 - accuracy: 0.7946 - val_loss: 1.0607 - val_accuracy: 0.8947\n",
      "Epoch 12/50\n",
      "112/112 [==============================] - 0s 270us/sample - loss: 1.0628 - accuracy: 0.8036 - val_loss: 1.0562 - val_accuracy: 0.8947\n",
      "Epoch 13/50\n",
      "112/112 [==============================] - 0s 280us/sample - loss: 1.0584 - accuracy: 0.8036 - val_loss: 1.0516 - val_accuracy: 0.8684\n",
      "Epoch 14/50\n",
      "112/112 [==============================] - 0s 269us/sample - loss: 1.0539 - accuracy: 0.8036 - val_loss: 1.0466 - val_accuracy: 0.8684\n",
      "Epoch 15/50\n",
      "112/112 [==============================] - 0s 276us/sample - loss: 1.0491 - accuracy: 0.7946 - val_loss: 1.0416 - val_accuracy: 0.8684\n",
      "Epoch 16/50\n",
      "112/112 [==============================] - 0s 284us/sample - loss: 1.0444 - accuracy: 0.7946 - val_loss: 1.0363 - val_accuracy: 0.8684\n",
      "Epoch 17/50\n",
      "112/112 [==============================] - 0s 268us/sample - loss: 1.0391 - accuracy: 0.7946 - val_loss: 1.0308 - val_accuracy: 0.8684\n",
      "Epoch 18/50\n",
      "112/112 [==============================] - 0s 310us/sample - loss: 1.0340 - accuracy: 0.7946 - val_loss: 1.0252 - val_accuracy: 0.8684\n",
      "Epoch 19/50\n",
      "112/112 [==============================] - 0s 285us/sample - loss: 1.0283 - accuracy: 0.7946 - val_loss: 1.0195 - val_accuracy: 0.8684\n",
      "Epoch 20/50\n",
      "112/112 [==============================] - 0s 303us/sample - loss: 1.0231 - accuracy: 0.7946 - val_loss: 1.0136 - val_accuracy: 0.8684\n",
      "Epoch 21/50\n",
      "112/112 [==============================] - 0s 276us/sample - loss: 1.0173 - accuracy: 0.7946 - val_loss: 1.0075 - val_accuracy: 0.8684\n",
      "Epoch 22/50\n",
      "112/112 [==============================] - 0s 273us/sample - loss: 1.0114 - accuracy: 0.7857 - val_loss: 1.0014 - val_accuracy: 0.8421\n",
      "Epoch 23/50\n",
      "112/112 [==============================] - 0s 271us/sample - loss: 1.0055 - accuracy: 0.7679 - val_loss: 0.9951 - val_accuracy: 0.8421\n",
      "Epoch 24/50\n",
      "112/112 [==============================] - 0s 283us/sample - loss: 0.9994 - accuracy: 0.7589 - val_loss: 0.9887 - val_accuracy: 0.8421\n",
      "Epoch 25/50\n",
      "112/112 [==============================] - 0s 285us/sample - loss: 0.9931 - accuracy: 0.7500 - val_loss: 0.9821 - val_accuracy: 0.8421\n",
      "Epoch 26/50\n",
      "112/112 [==============================] - 0s 264us/sample - loss: 0.9870 - accuracy: 0.7411 - val_loss: 0.9754 - val_accuracy: 0.8421\n",
      "Epoch 27/50\n",
      "112/112 [==============================] - 0s 284us/sample - loss: 0.9802 - accuracy: 0.7411 - val_loss: 0.9686 - val_accuracy: 0.8421\n",
      "Epoch 28/50\n",
      "112/112 [==============================] - 0s 266us/sample - loss: 0.9739 - accuracy: 0.7500 - val_loss: 0.9617 - val_accuracy: 0.8158\n",
      "Epoch 29/50\n",
      "112/112 [==============================] - 0s 275us/sample - loss: 0.9672 - accuracy: 0.7500 - val_loss: 0.9547 - val_accuracy: 0.8158\n",
      "Epoch 30/50\n",
      "112/112 [==============================] - 0s 268us/sample - loss: 0.9605 - accuracy: 0.7500 - val_loss: 0.9477 - val_accuracy: 0.7895\n",
      "Epoch 31/50\n",
      "112/112 [==============================] - 0s 292us/sample - loss: 0.9536 - accuracy: 0.7321 - val_loss: 0.9405 - val_accuracy: 0.7895\n",
      "Epoch 32/50\n",
      "112/112 [==============================] - 0s 275us/sample - loss: 0.9467 - accuracy: 0.7321 - val_loss: 0.9333 - val_accuracy: 0.7895\n",
      "Epoch 33/50\n",
      "112/112 [==============================] - 0s 287us/sample - loss: 0.9397 - accuracy: 0.7321 - val_loss: 0.9260 - val_accuracy: 0.7895\n",
      "Epoch 34/50\n",
      "112/112 [==============================] - 0s 281us/sample - loss: 0.9329 - accuracy: 0.7321 - val_loss: 0.9186 - val_accuracy: 0.7895\n",
      "Epoch 35/50\n",
      "112/112 [==============================] - 0s 265us/sample - loss: 0.9255 - accuracy: 0.7232 - val_loss: 0.9112 - val_accuracy: 0.7895\n",
      "Epoch 36/50\n",
      "112/112 [==============================] - 0s 274us/sample - loss: 0.9185 - accuracy: 0.7232 - val_loss: 0.9037 - val_accuracy: 0.7632\n",
      "Epoch 37/50\n",
      "112/112 [==============================] - 0s 275us/sample - loss: 0.9113 - accuracy: 0.7143 - val_loss: 0.8961 - val_accuracy: 0.7632\n",
      "Epoch 38/50\n",
      "112/112 [==============================] - 0s 307us/sample - loss: 0.9040 - accuracy: 0.7054 - val_loss: 0.8885 - val_accuracy: 0.7632\n",
      "Epoch 39/50\n",
      "112/112 [==============================] - 0s 278us/sample - loss: 0.8965 - accuracy: 0.7054 - val_loss: 0.8808 - val_accuracy: 0.7632\n",
      "Epoch 40/50\n",
      "112/112 [==============================] - 0s 290us/sample - loss: 0.8896 - accuracy: 0.7054 - val_loss: 0.8732 - val_accuracy: 0.7632\n",
      "Epoch 41/50\n",
      "112/112 [==============================] - 0s 298us/sample - loss: 0.8820 - accuracy: 0.7054 - val_loss: 0.8655 - val_accuracy: 0.7632\n",
      "Epoch 42/50\n",
      "112/112 [==============================] - 0s 274us/sample - loss: 0.8745 - accuracy: 0.7054 - val_loss: 0.8579 - val_accuracy: 0.7632\n",
      "Epoch 43/50\n",
      "112/112 [==============================] - 0s 276us/sample - loss: 0.8675 - accuracy: 0.7054 - val_loss: 0.8502 - val_accuracy: 0.7632\n",
      "Epoch 44/50\n",
      "112/112 [==============================] - 0s 276us/sample - loss: 0.8601 - accuracy: 0.6964 - val_loss: 0.8426 - val_accuracy: 0.7632\n",
      "Epoch 45/50\n",
      "112/112 [==============================] - 0s 280us/sample - loss: 0.8525 - accuracy: 0.6964 - val_loss: 0.8350 - val_accuracy: 0.7632\n",
      "Epoch 46/50\n",
      "112/112 [==============================] - 0s 284us/sample - loss: 0.8452 - accuracy: 0.6964 - val_loss: 0.8274 - val_accuracy: 0.7632\n",
      "Epoch 47/50\n",
      "112/112 [==============================] - 0s 248us/sample - loss: 0.8381 - accuracy: 0.6964 - val_loss: 0.8198 - val_accuracy: 0.7632\n",
      "Epoch 48/50\n",
      "112/112 [==============================] - 0s 283us/sample - loss: 0.8311 - accuracy: 0.6964 - val_loss: 0.8123 - val_accuracy: 0.7632\n",
      "Epoch 49/50\n",
      "112/112 [==============================] - 0s 404us/sample - loss: 0.8238 - accuracy: 0.6964 - val_loss: 0.8048 - val_accuracy: 0.7368\n",
      "Epoch 50/50\n",
      "112/112 [==============================] - 0s 271us/sample - loss: 0.8169 - accuracy: 0.6964 - val_loss: 0.7974 - val_accuracy: 0.7368\n",
      "\n",
      "Forming the grid-search model #11 using: optimizer=<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7fe1d6395290>, kernel=<tensorflow.python.ops.init_ops_v2.RandomNormal object at 0x7fe1b03bde50>, epochs=50, batch_size=128\n",
      "Train on 112 samples, validate on 38 samples\n",
      "Epoch 1/50\n",
      "112/112 [==============================] - 1s 8ms/sample - loss: 1.0965 - accuracy: 0.4196 - val_loss: 1.0942 - val_accuracy: 0.5263\n",
      "Epoch 2/50\n",
      "112/112 [==============================] - 0s 224us/sample - loss: 1.0958 - accuracy: 0.4732 - val_loss: 1.0932 - val_accuracy: 0.5789\n",
      "Epoch 3/50\n",
      "112/112 [==============================] - 0s 221us/sample - loss: 1.0949 - accuracy: 0.5268 - val_loss: 1.0921 - val_accuracy: 0.5789\n",
      "Epoch 4/50\n",
      "112/112 [==============================] - 0s 224us/sample - loss: 1.0938 - accuracy: 0.5446 - val_loss: 1.0908 - val_accuracy: 0.5789\n",
      "Epoch 5/50\n",
      "112/112 [==============================] - 0s 296us/sample - loss: 1.0926 - accuracy: 0.5446 - val_loss: 1.0893 - val_accuracy: 0.5789\n",
      "Epoch 6/50\n",
      "112/112 [==============================] - 0s 219us/sample - loss: 1.0912 - accuracy: 0.5446 - val_loss: 1.0878 - val_accuracy: 0.5526\n",
      "Epoch 7/50\n",
      "112/112 [==============================] - 0s 216us/sample - loss: 1.0897 - accuracy: 0.5357 - val_loss: 1.0862 - val_accuracy: 0.5263\n",
      "Epoch 8/50\n",
      "112/112 [==============================] - 0s 304us/sample - loss: 1.0881 - accuracy: 0.5446 - val_loss: 1.0844 - val_accuracy: 0.5526\n",
      "Epoch 9/50\n",
      "112/112 [==============================] - 0s 221us/sample - loss: 1.0864 - accuracy: 0.5357 - val_loss: 1.0826 - val_accuracy: 0.5526\n",
      "Epoch 10/50\n",
      "112/112 [==============================] - 0s 232us/sample - loss: 1.0846 - accuracy: 0.5446 - val_loss: 1.0807 - val_accuracy: 0.5789\n",
      "Epoch 11/50\n",
      "112/112 [==============================] - 0s 236us/sample - loss: 1.0828 - accuracy: 0.5446 - val_loss: 1.0788 - val_accuracy: 0.6053\n",
      "Epoch 12/50\n",
      "112/112 [==============================] - 0s 240us/sample - loss: 1.0808 - accuracy: 0.5804 - val_loss: 1.0767 - val_accuracy: 0.6842\n",
      "Epoch 13/50\n",
      "112/112 [==============================] - 0s 230us/sample - loss: 1.0787 - accuracy: 0.5893 - val_loss: 1.0745 - val_accuracy: 0.6842\n",
      "Epoch 14/50\n",
      "112/112 [==============================] - 0s 231us/sample - loss: 1.0766 - accuracy: 0.6607 - val_loss: 1.0723 - val_accuracy: 0.6842\n",
      "Epoch 15/50\n",
      "112/112 [==============================] - 0s 221us/sample - loss: 1.0744 - accuracy: 0.6875 - val_loss: 1.0700 - val_accuracy: 0.6842\n",
      "Epoch 16/50\n",
      "112/112 [==============================] - 0s 231us/sample - loss: 1.0721 - accuracy: 0.7054 - val_loss: 1.0676 - val_accuracy: 0.6842\n",
      "Epoch 17/50\n",
      "112/112 [==============================] - 0s 238us/sample - loss: 1.0697 - accuracy: 0.7321 - val_loss: 1.0651 - val_accuracy: 0.7105\n",
      "Epoch 18/50\n",
      "112/112 [==============================] - 0s 234us/sample - loss: 1.0672 - accuracy: 0.7679 - val_loss: 1.0625 - val_accuracy: 0.7895\n",
      "Epoch 19/50\n",
      "112/112 [==============================] - 0s 241us/sample - loss: 1.0647 - accuracy: 0.7857 - val_loss: 1.0598 - val_accuracy: 0.8421\n",
      "Epoch 20/50\n",
      "112/112 [==============================] - 0s 229us/sample - loss: 1.0621 - accuracy: 0.8125 - val_loss: 1.0571 - val_accuracy: 0.8421\n",
      "Epoch 21/50\n",
      "112/112 [==============================] - 0s 240us/sample - loss: 1.0595 - accuracy: 0.8482 - val_loss: 1.0542 - val_accuracy: 0.8684\n",
      "Epoch 22/50\n",
      "112/112 [==============================] - 0s 239us/sample - loss: 1.0567 - accuracy: 0.8571 - val_loss: 1.0513 - val_accuracy: 0.9211\n",
      "Epoch 23/50\n",
      "112/112 [==============================] - 0s 229us/sample - loss: 1.0539 - accuracy: 0.8839 - val_loss: 1.0483 - val_accuracy: 0.9474\n",
      "Epoch 24/50\n",
      "112/112 [==============================] - 0s 224us/sample - loss: 1.0510 - accuracy: 0.8839 - val_loss: 1.0452 - val_accuracy: 0.9474\n",
      "Epoch 25/50\n",
      "112/112 [==============================] - 0s 241us/sample - loss: 1.0481 - accuracy: 0.8750 - val_loss: 1.0420 - val_accuracy: 0.9737\n",
      "Epoch 26/50\n",
      "112/112 [==============================] - 0s 233us/sample - loss: 1.0450 - accuracy: 0.8750 - val_loss: 1.0388 - val_accuracy: 0.9737\n",
      "Epoch 27/50\n",
      "112/112 [==============================] - 0s 292us/sample - loss: 1.0420 - accuracy: 0.8839 - val_loss: 1.0355 - val_accuracy: 1.0000\n",
      "Epoch 28/50\n",
      "112/112 [==============================] - 0s 234us/sample - loss: 1.0388 - accuracy: 0.8750 - val_loss: 1.0321 - val_accuracy: 0.9737\n",
      "Epoch 29/50\n",
      "112/112 [==============================] - 0s 240us/sample - loss: 1.0356 - accuracy: 0.8839 - val_loss: 1.0287 - val_accuracy: 0.9474\n",
      "Epoch 30/50\n",
      "112/112 [==============================] - 0s 240us/sample - loss: 1.0323 - accuracy: 0.8929 - val_loss: 1.0252 - val_accuracy: 0.9474\n",
      "Epoch 31/50\n",
      "112/112 [==============================] - 0s 230us/sample - loss: 1.0289 - accuracy: 0.8839 - val_loss: 1.0217 - val_accuracy: 0.9474\n",
      "Epoch 32/50\n",
      "112/112 [==============================] - 0s 214us/sample - loss: 1.0255 - accuracy: 0.8750 - val_loss: 1.0181 - val_accuracy: 0.9474\n",
      "Epoch 33/50\n",
      "112/112 [==============================] - 0s 241us/sample - loss: 1.0221 - accuracy: 0.8750 - val_loss: 1.0144 - val_accuracy: 0.9474\n",
      "Epoch 34/50\n",
      "112/112 [==============================] - 0s 248us/sample - loss: 1.0185 - accuracy: 0.8661 - val_loss: 1.0107 - val_accuracy: 0.9474\n",
      "Epoch 35/50\n",
      "112/112 [==============================] - 0s 221us/sample - loss: 1.0149 - accuracy: 0.8661 - val_loss: 1.0070 - val_accuracy: 0.9474\n",
      "Epoch 36/50\n",
      "112/112 [==============================] - 0s 224us/sample - loss: 1.0113 - accuracy: 0.8661 - val_loss: 1.0032 - val_accuracy: 0.9474\n",
      "Epoch 37/50\n",
      "112/112 [==============================] - 0s 273us/sample - loss: 1.0076 - accuracy: 0.8571 - val_loss: 0.9993 - val_accuracy: 0.9474\n",
      "Epoch 38/50\n",
      "112/112 [==============================] - 0s 245us/sample - loss: 1.0039 - accuracy: 0.8571 - val_loss: 0.9954 - val_accuracy: 0.9474\n",
      "Epoch 39/50\n",
      "112/112 [==============================] - 0s 229us/sample - loss: 1.0001 - accuracy: 0.8661 - val_loss: 0.9915 - val_accuracy: 0.9211\n",
      "Epoch 40/50\n",
      "112/112 [==============================] - 0s 235us/sample - loss: 0.9962 - accuracy: 0.8571 - val_loss: 0.9875 - val_accuracy: 0.9211\n",
      "Epoch 41/50\n",
      "112/112 [==============================] - 0s 255us/sample - loss: 0.9923 - accuracy: 0.8482 - val_loss: 0.9835 - val_accuracy: 0.9211\n",
      "Epoch 42/50\n",
      "112/112 [==============================] - 0s 228us/sample - loss: 0.9884 - accuracy: 0.8482 - val_loss: 0.9794 - val_accuracy: 0.9211\n",
      "Epoch 43/50\n",
      "112/112 [==============================] - 0s 231us/sample - loss: 0.9844 - accuracy: 0.8482 - val_loss: 0.9752 - val_accuracy: 0.9211\n",
      "Epoch 44/50\n",
      "112/112 [==============================] - 0s 245us/sample - loss: 0.9804 - accuracy: 0.8482 - val_loss: 0.9711 - val_accuracy: 0.9211\n",
      "Epoch 45/50\n",
      "112/112 [==============================] - 0s 234us/sample - loss: 0.9764 - accuracy: 0.8393 - val_loss: 0.9669 - val_accuracy: 0.9211\n",
      "Epoch 46/50\n",
      "112/112 [==============================] - 0s 254us/sample - loss: 0.9723 - accuracy: 0.8393 - val_loss: 0.9626 - val_accuracy: 0.9211\n",
      "Epoch 47/50\n",
      "112/112 [==============================] - 0s 230us/sample - loss: 0.9681 - accuracy: 0.8304 - val_loss: 0.9583 - val_accuracy: 0.9211\n",
      "Epoch 48/50\n",
      "112/112 [==============================] - 0s 223us/sample - loss: 0.9640 - accuracy: 0.8304 - val_loss: 0.9540 - val_accuracy: 0.9211\n",
      "Epoch 49/50\n",
      "112/112 [==============================] - 0s 228us/sample - loss: 0.9598 - accuracy: 0.8304 - val_loss: 0.9496 - val_accuracy: 0.9211\n",
      "Epoch 50/50\n",
      "112/112 [==============================] - 0s 234us/sample - loss: 0.9556 - accuracy: 0.8304 - val_loss: 0.9452 - val_accuracy: 0.9211\n",
      "\n",
      "Forming the grid-search model #12 using: optimizer=<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7fe1d6395290>, kernel=<tensorflow.python.ops.init_ops_v2.Orthogonal object at 0x7fe1b03bd4d0>, epochs=50, batch_size=32\n",
      "Train on 112 samples, validate on 38 samples\n",
      "Epoch 1/50\n",
      "112/112 [==============================] - 1s 9ms/sample - loss: 1.2317 - accuracy: 0.2857 - val_loss: 1.1895 - val_accuracy: 0.3421\n",
      "Epoch 2/50\n",
      "112/112 [==============================] - 0s 328us/sample - loss: 1.2015 - accuracy: 0.3304 - val_loss: 1.1520 - val_accuracy: 0.4211\n",
      "Epoch 3/50\n",
      "112/112 [==============================] - 0s 337us/sample - loss: 1.1666 - accuracy: 0.3571 - val_loss: 1.1136 - val_accuracy: 0.4211\n",
      "Epoch 4/50\n",
      "112/112 [==============================] - 0s 328us/sample - loss: 1.1338 - accuracy: 0.3929 - val_loss: 1.0763 - val_accuracy: 0.4474\n",
      "Epoch 5/50\n",
      "112/112 [==============================] - 0s 327us/sample - loss: 1.0988 - accuracy: 0.4018 - val_loss: 1.0422 - val_accuracy: 0.4474\n",
      "Epoch 6/50\n",
      "112/112 [==============================] - 0s 355us/sample - loss: 1.0696 - accuracy: 0.4018 - val_loss: 1.0104 - val_accuracy: 0.4737\n",
      "Epoch 7/50\n",
      "112/112 [==============================] - 0s 343us/sample - loss: 1.0413 - accuracy: 0.4018 - val_loss: 0.9814 - val_accuracy: 0.5263\n",
      "Epoch 8/50\n",
      "112/112 [==============================] - 0s 344us/sample - loss: 1.0168 - accuracy: 0.4732 - val_loss: 0.9545 - val_accuracy: 0.5789\n",
      "Epoch 9/50\n",
      "112/112 [==============================] - 0s 346us/sample - loss: 0.9919 - accuracy: 0.5446 - val_loss: 0.9303 - val_accuracy: 0.6316\n",
      "Epoch 10/50\n",
      "112/112 [==============================] - 0s 395us/sample - loss: 0.9705 - accuracy: 0.5714 - val_loss: 0.9073 - val_accuracy: 0.7632\n",
      "Epoch 11/50\n",
      "112/112 [==============================] - 0s 376us/sample - loss: 0.9502 - accuracy: 0.5893 - val_loss: 0.8859 - val_accuracy: 0.8158\n",
      "Epoch 12/50\n",
      "112/112 [==============================] - 0s 334us/sample - loss: 0.9318 - accuracy: 0.6339 - val_loss: 0.8657 - val_accuracy: 0.8158\n",
      "Epoch 13/50\n",
      "112/112 [==============================] - 0s 347us/sample - loss: 0.9140 - accuracy: 0.6696 - val_loss: 0.8469 - val_accuracy: 0.8158\n",
      "Epoch 14/50\n",
      "112/112 [==============================] - 0s 353us/sample - loss: 0.8978 - accuracy: 0.6964 - val_loss: 0.8289 - val_accuracy: 0.8421\n",
      "Epoch 15/50\n",
      "112/112 [==============================] - 0s 410us/sample - loss: 0.8813 - accuracy: 0.7321 - val_loss: 0.8122 - val_accuracy: 0.8684\n",
      "Epoch 16/50\n",
      "112/112 [==============================] - 0s 338us/sample - loss: 0.8671 - accuracy: 0.7411 - val_loss: 0.7957 - val_accuracy: 0.9211\n",
      "Epoch 17/50\n",
      "112/112 [==============================] - 0s 337us/sample - loss: 0.8522 - accuracy: 0.7411 - val_loss: 0.7801 - val_accuracy: 0.9211\n",
      "Epoch 18/50\n",
      "112/112 [==============================] - 0s 431us/sample - loss: 0.8386 - accuracy: 0.7411 - val_loss: 0.7652 - val_accuracy: 0.9211\n",
      "Epoch 19/50\n",
      "112/112 [==============================] - 0s 371us/sample - loss: 0.8248 - accuracy: 0.7411 - val_loss: 0.7512 - val_accuracy: 0.9211\n",
      "Epoch 20/50\n",
      "112/112 [==============================] - 0s 334us/sample - loss: 0.8125 - accuracy: 0.7411 - val_loss: 0.7373 - val_accuracy: 0.9211\n",
      "Epoch 21/50\n",
      "112/112 [==============================] - 0s 430us/sample - loss: 0.8001 - accuracy: 0.7411 - val_loss: 0.7243 - val_accuracy: 0.9211\n",
      "Epoch 22/50\n",
      "112/112 [==============================] - 0s 341us/sample - loss: 0.7882 - accuracy: 0.7411 - val_loss: 0.7116 - val_accuracy: 0.9211\n",
      "Epoch 23/50\n",
      "112/112 [==============================] - 0s 332us/sample - loss: 0.7766 - accuracy: 0.7411 - val_loss: 0.6995 - val_accuracy: 0.9211\n",
      "Epoch 24/50\n",
      "112/112 [==============================] - 0s 408us/sample - loss: 0.7657 - accuracy: 0.7500 - val_loss: 0.6875 - val_accuracy: 0.9211\n",
      "Epoch 25/50\n",
      "112/112 [==============================] - 0s 365us/sample - loss: 0.7548 - accuracy: 0.7589 - val_loss: 0.6761 - val_accuracy: 0.9211\n",
      "Epoch 26/50\n",
      "112/112 [==============================] - 0s 356us/sample - loss: 0.7447 - accuracy: 0.7679 - val_loss: 0.6648 - val_accuracy: 0.9211\n",
      "Epoch 27/50\n",
      "112/112 [==============================] - 0s 336us/sample - loss: 0.7341 - accuracy: 0.7679 - val_loss: 0.6542 - val_accuracy: 0.9211\n",
      "Epoch 28/50\n",
      "112/112 [==============================] - 0s 359us/sample - loss: 0.7246 - accuracy: 0.7768 - val_loss: 0.6437 - val_accuracy: 0.9211\n",
      "Epoch 29/50\n",
      "112/112 [==============================] - 0s 340us/sample - loss: 0.7150 - accuracy: 0.7768 - val_loss: 0.6336 - val_accuracy: 0.9211\n",
      "Epoch 30/50\n",
      "112/112 [==============================] - 0s 345us/sample - loss: 0.7058 - accuracy: 0.7768 - val_loss: 0.6239 - val_accuracy: 0.9211\n",
      "Epoch 31/50\n",
      "112/112 [==============================] - 0s 346us/sample - loss: 0.6968 - accuracy: 0.7768 - val_loss: 0.6147 - val_accuracy: 0.9211\n",
      "Epoch 32/50\n",
      "112/112 [==============================] - 0s 311us/sample - loss: 0.6880 - accuracy: 0.7768 - val_loss: 0.6059 - val_accuracy: 0.9211\n",
      "Epoch 33/50\n",
      "112/112 [==============================] - 0s 331us/sample - loss: 0.6796 - accuracy: 0.7768 - val_loss: 0.5974 - val_accuracy: 0.9211\n",
      "Epoch 34/50\n",
      "112/112 [==============================] - 0s 323us/sample - loss: 0.6717 - accuracy: 0.7768 - val_loss: 0.5888 - val_accuracy: 0.9211\n",
      "Epoch 35/50\n",
      "112/112 [==============================] - 0s 346us/sample - loss: 0.6635 - accuracy: 0.7768 - val_loss: 0.5807 - val_accuracy: 0.9211\n",
      "Epoch 36/50\n",
      "112/112 [==============================] - 0s 324us/sample - loss: 0.6557 - accuracy: 0.7768 - val_loss: 0.5729 - val_accuracy: 0.9211\n",
      "Epoch 37/50\n",
      "112/112 [==============================] - 0s 389us/sample - loss: 0.6482 - accuracy: 0.7768 - val_loss: 0.5653 - val_accuracy: 0.9211\n",
      "Epoch 38/50\n",
      "112/112 [==============================] - 0s 348us/sample - loss: 0.6410 - accuracy: 0.7768 - val_loss: 0.5578 - val_accuracy: 0.9211\n",
      "Epoch 39/50\n",
      "112/112 [==============================] - 0s 345us/sample - loss: 0.6337 - accuracy: 0.7857 - val_loss: 0.5506 - val_accuracy: 0.9211\n",
      "Epoch 40/50\n",
      "112/112 [==============================] - 0s 343us/sample - loss: 0.6268 - accuracy: 0.7857 - val_loss: 0.5436 - val_accuracy: 0.9211\n",
      "Epoch 41/50\n",
      "112/112 [==============================] - 0s 331us/sample - loss: 0.6200 - accuracy: 0.8036 - val_loss: 0.5367 - val_accuracy: 0.9211\n",
      "Epoch 42/50\n",
      "112/112 [==============================] - 0s 345us/sample - loss: 0.6133 - accuracy: 0.8036 - val_loss: 0.5300 - val_accuracy: 0.9211\n",
      "Epoch 43/50\n",
      "112/112 [==============================] - 0s 334us/sample - loss: 0.6069 - accuracy: 0.8036 - val_loss: 0.5234 - val_accuracy: 0.9211\n",
      "Epoch 44/50\n",
      "112/112 [==============================] - 0s 335us/sample - loss: 0.6006 - accuracy: 0.8036 - val_loss: 0.5171 - val_accuracy: 0.9211\n",
      "Epoch 45/50\n",
      "112/112 [==============================] - 0s 353us/sample - loss: 0.5945 - accuracy: 0.8036 - val_loss: 0.5108 - val_accuracy: 0.9211\n",
      "Epoch 46/50\n",
      "112/112 [==============================] - 0s 361us/sample - loss: 0.5884 - accuracy: 0.8036 - val_loss: 0.5047 - val_accuracy: 0.9211\n",
      "Epoch 47/50\n",
      "112/112 [==============================] - 0s 339us/sample - loss: 0.5826 - accuracy: 0.8036 - val_loss: 0.4985 - val_accuracy: 0.9211\n",
      "Epoch 48/50\n",
      "112/112 [==============================] - 0s 346us/sample - loss: 0.5768 - accuracy: 0.8036 - val_loss: 0.4927 - val_accuracy: 0.9211\n",
      "Epoch 49/50\n",
      "112/112 [==============================] - 0s 338us/sample - loss: 0.5713 - accuracy: 0.8036 - val_loss: 0.4870 - val_accuracy: 0.9211\n",
      "Epoch 50/50\n",
      "112/112 [==============================] - 0s 333us/sample - loss: 0.5658 - accuracy: 0.8036 - val_loss: 0.4816 - val_accuracy: 0.9211\n",
      "\n",
      "Forming the grid-search model #13 using: optimizer=<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7fe1d6395290>, kernel=<tensorflow.python.ops.init_ops_v2.Orthogonal object at 0x7fe1b03bd4d0>, epochs=50, batch_size=64\n",
      "Train on 112 samples, validate on 38 samples\n",
      "Epoch 1/50\n",
      "112/112 [==============================] - 1s 11ms/sample - loss: 1.2354 - accuracy: 0.2679 - val_loss: 1.2026 - val_accuracy: 0.3421\n",
      "Epoch 2/50\n",
      "112/112 [==============================] - 0s 264us/sample - loss: 1.2201 - accuracy: 0.2946 - val_loss: 1.1815 - val_accuracy: 0.3421\n",
      "Epoch 3/50\n",
      "112/112 [==============================] - 0s 299us/sample - loss: 1.2004 - accuracy: 0.3125 - val_loss: 1.1582 - val_accuracy: 0.3947\n",
      "Epoch 4/50\n",
      "112/112 [==============================] - 0s 273us/sample - loss: 1.1805 - accuracy: 0.3393 - val_loss: 1.1342 - val_accuracy: 0.4211\n",
      "Epoch 5/50\n",
      "112/112 [==============================] - 0s 284us/sample - loss: 1.1577 - accuracy: 0.3571 - val_loss: 1.1106 - val_accuracy: 0.4211\n",
      "Epoch 6/50\n",
      "112/112 [==============================] - 0s 281us/sample - loss: 1.1374 - accuracy: 0.3839 - val_loss: 1.0875 - val_accuracy: 0.4211\n",
      "Epoch 7/50\n",
      "112/112 [==============================] - 0s 278us/sample - loss: 1.1157 - accuracy: 0.3929 - val_loss: 1.0651 - val_accuracy: 0.4474\n",
      "Epoch 8/50\n",
      "112/112 [==============================] - 0s 279us/sample - loss: 1.0973 - accuracy: 0.4018 - val_loss: 1.0435 - val_accuracy: 0.4474\n",
      "Epoch 9/50\n",
      "112/112 [==============================] - 0s 262us/sample - loss: 1.0769 - accuracy: 0.4018 - val_loss: 1.0230 - val_accuracy: 0.4737\n",
      "Epoch 10/50\n",
      "112/112 [==============================] - 0s 297us/sample - loss: 1.0583 - accuracy: 0.4196 - val_loss: 1.0034 - val_accuracy: 0.5000\n",
      "Epoch 11/50\n",
      "112/112 [==============================] - 0s 282us/sample - loss: 1.0405 - accuracy: 0.4286 - val_loss: 0.9848 - val_accuracy: 0.5263\n",
      "Epoch 12/50\n",
      "112/112 [==============================] - 0s 273us/sample - loss: 1.0241 - accuracy: 0.4643 - val_loss: 0.9668 - val_accuracy: 0.5526\n",
      "Epoch 13/50\n",
      "112/112 [==============================] - 0s 258us/sample - loss: 1.0077 - accuracy: 0.5089 - val_loss: 0.9495 - val_accuracy: 0.6316\n",
      "Epoch 14/50\n",
      "112/112 [==============================] - 0s 256us/sample - loss: 0.9930 - accuracy: 0.5804 - val_loss: 0.9330 - val_accuracy: 0.6842\n",
      "Epoch 15/50\n",
      "112/112 [==============================] - 0s 267us/sample - loss: 0.9773 - accuracy: 0.5893 - val_loss: 0.9174 - val_accuracy: 0.7368\n",
      "Epoch 16/50\n",
      "112/112 [==============================] - 0s 260us/sample - loss: 0.9643 - accuracy: 0.5804 - val_loss: 0.9023 - val_accuracy: 0.7895\n",
      "Epoch 17/50\n",
      "112/112 [==============================] - 0s 345us/sample - loss: 0.9505 - accuracy: 0.6071 - val_loss: 0.8878 - val_accuracy: 0.8158\n",
      "Epoch 18/50\n",
      "112/112 [==============================] - 0s 273us/sample - loss: 0.9376 - accuracy: 0.6429 - val_loss: 0.8738 - val_accuracy: 0.8158\n",
      "Epoch 19/50\n",
      "112/112 [==============================] - 0s 286us/sample - loss: 0.9248 - accuracy: 0.6607 - val_loss: 0.8605 - val_accuracy: 0.8421\n",
      "Epoch 20/50\n",
      "112/112 [==============================] - 0s 304us/sample - loss: 0.9133 - accuracy: 0.6786 - val_loss: 0.8476 - val_accuracy: 0.8421\n",
      "Epoch 21/50\n",
      "112/112 [==============================] - 0s 250us/sample - loss: 0.9016 - accuracy: 0.7054 - val_loss: 0.8352 - val_accuracy: 0.8684\n",
      "Epoch 22/50\n",
      "112/112 [==============================] - 0s 244us/sample - loss: 0.8907 - accuracy: 0.7232 - val_loss: 0.8230 - val_accuracy: 0.8684\n",
      "Epoch 23/50\n",
      "112/112 [==============================] - 0s 276us/sample - loss: 0.8799 - accuracy: 0.7411 - val_loss: 0.8112 - val_accuracy: 0.9211\n",
      "Epoch 24/50\n",
      "112/112 [==============================] - 0s 276us/sample - loss: 0.8694 - accuracy: 0.7411 - val_loss: 0.7998 - val_accuracy: 0.9211\n",
      "Epoch 25/50\n",
      "112/112 [==============================] - 0s 282us/sample - loss: 0.8592 - accuracy: 0.7411 - val_loss: 0.7886 - val_accuracy: 0.9211\n",
      "Epoch 26/50\n",
      "112/112 [==============================] - 0s 258us/sample - loss: 0.8496 - accuracy: 0.7411 - val_loss: 0.7778 - val_accuracy: 0.9211\n",
      "Epoch 27/50\n",
      "112/112 [==============================] - 0s 279us/sample - loss: 0.8397 - accuracy: 0.7411 - val_loss: 0.7674 - val_accuracy: 0.9211\n",
      "Epoch 28/50\n",
      "112/112 [==============================] - 0s 295us/sample - loss: 0.8308 - accuracy: 0.7411 - val_loss: 0.7572 - val_accuracy: 0.9211\n",
      "Epoch 29/50\n",
      "112/112 [==============================] - 0s 256us/sample - loss: 0.8215 - accuracy: 0.7411 - val_loss: 0.7474 - val_accuracy: 0.8947\n",
      "Epoch 30/50\n",
      "112/112 [==============================] - 0s 320us/sample - loss: 0.8128 - accuracy: 0.7321 - val_loss: 0.7378 - val_accuracy: 0.8947\n",
      "Epoch 31/50\n",
      "112/112 [==============================] - 0s 285us/sample - loss: 0.8042 - accuracy: 0.7321 - val_loss: 0.7285 - val_accuracy: 0.8947\n",
      "Epoch 32/50\n",
      "112/112 [==============================] - 0s 261us/sample - loss: 0.7957 - accuracy: 0.7321 - val_loss: 0.7195 - val_accuracy: 0.8947\n",
      "Epoch 33/50\n",
      "112/112 [==============================] - 0s 269us/sample - loss: 0.7875 - accuracy: 0.7321 - val_loss: 0.7106 - val_accuracy: 0.9211\n",
      "Epoch 34/50\n",
      "112/112 [==============================] - 0s 281us/sample - loss: 0.7797 - accuracy: 0.7500 - val_loss: 0.7020 - val_accuracy: 0.9211\n",
      "Epoch 35/50\n",
      "112/112 [==============================] - 0s 279us/sample - loss: 0.7717 - accuracy: 0.7589 - val_loss: 0.6937 - val_accuracy: 0.9211\n",
      "Epoch 36/50\n",
      "112/112 [==============================] - 0s 272us/sample - loss: 0.7640 - accuracy: 0.7589 - val_loss: 0.6855 - val_accuracy: 0.9211\n",
      "Epoch 37/50\n",
      "112/112 [==============================] - 0s 302us/sample - loss: 0.7567 - accuracy: 0.7589 - val_loss: 0.6775 - val_accuracy: 0.9211\n",
      "Epoch 38/50\n",
      "112/112 [==============================] - 0s 264us/sample - loss: 0.7493 - accuracy: 0.7679 - val_loss: 0.6697 - val_accuracy: 0.9211\n",
      "Epoch 39/50\n",
      "112/112 [==============================] - 0s 316us/sample - loss: 0.7421 - accuracy: 0.7679 - val_loss: 0.6621 - val_accuracy: 0.9211\n",
      "Epoch 40/50\n",
      "112/112 [==============================] - 0s 267us/sample - loss: 0.7353 - accuracy: 0.7679 - val_loss: 0.6546 - val_accuracy: 0.9211\n",
      "Epoch 41/50\n",
      "112/112 [==============================] - 0s 283us/sample - loss: 0.7283 - accuracy: 0.7768 - val_loss: 0.6474 - val_accuracy: 0.9211\n",
      "Epoch 42/50\n",
      "112/112 [==============================] - 0s 283us/sample - loss: 0.7215 - accuracy: 0.7768 - val_loss: 0.6403 - val_accuracy: 0.9211\n",
      "Epoch 43/50\n",
      "112/112 [==============================] - 0s 271us/sample - loss: 0.7150 - accuracy: 0.7768 - val_loss: 0.6333 - val_accuracy: 0.9211\n",
      "Epoch 44/50\n",
      "112/112 [==============================] - 0s 290us/sample - loss: 0.7085 - accuracy: 0.7857 - val_loss: 0.6265 - val_accuracy: 0.9211\n",
      "Epoch 45/50\n",
      "112/112 [==============================] - 0s 266us/sample - loss: 0.7021 - accuracy: 0.7857 - val_loss: 0.6198 - val_accuracy: 0.9211\n",
      "Epoch 46/50\n",
      "112/112 [==============================] - 0s 279us/sample - loss: 0.6959 - accuracy: 0.7857 - val_loss: 0.6133 - val_accuracy: 0.9211\n",
      "Epoch 47/50\n",
      "112/112 [==============================] - 0s 278us/sample - loss: 0.6898 - accuracy: 0.7857 - val_loss: 0.6069 - val_accuracy: 0.9211\n",
      "Epoch 48/50\n",
      "112/112 [==============================] - 0s 264us/sample - loss: 0.6838 - accuracy: 0.7857 - val_loss: 0.6007 - val_accuracy: 0.9211\n",
      "Epoch 49/50\n",
      "112/112 [==============================] - 0s 277us/sample - loss: 0.6781 - accuracy: 0.7857 - val_loss: 0.5946 - val_accuracy: 0.9211\n",
      "Epoch 50/50\n",
      "112/112 [==============================] - 0s 347us/sample - loss: 0.6723 - accuracy: 0.7857 - val_loss: 0.5887 - val_accuracy: 0.9211\n",
      "\n",
      "Forming the grid-search model #14 using: optimizer=<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7fe1d6395290>, kernel=<tensorflow.python.ops.init_ops_v2.Orthogonal object at 0x7fe1b03bd4d0>, epochs=50, batch_size=128\n",
      "Train on 112 samples, validate on 38 samples\n",
      "Epoch 1/50\n",
      "112/112 [==============================] - 1s 9ms/sample - loss: 1.2377 - accuracy: 0.2679 - val_loss: 1.2107 - val_accuracy: 0.3421\n",
      "Epoch 2/50\n",
      "112/112 [==============================] - 0s 220us/sample - loss: 1.2314 - accuracy: 0.2768 - val_loss: 1.2012 - val_accuracy: 0.3421\n",
      "Epoch 3/50\n",
      "112/112 [==============================] - 0s 213us/sample - loss: 1.2229 - accuracy: 0.2946 - val_loss: 1.1903 - val_accuracy: 0.3421\n",
      "Epoch 4/50\n",
      "112/112 [==============================] - 0s 225us/sample - loss: 1.2131 - accuracy: 0.3036 - val_loss: 1.1784 - val_accuracy: 0.3421\n",
      "Epoch 5/50\n",
      "112/112 [==============================] - 0s 250us/sample - loss: 1.2025 - accuracy: 0.3214 - val_loss: 1.1659 - val_accuracy: 0.3684\n",
      "Epoch 6/50\n",
      "112/112 [==============================] - 0s 229us/sample - loss: 1.1912 - accuracy: 0.3304 - val_loss: 1.1529 - val_accuracy: 0.3947\n",
      "Epoch 7/50\n",
      "112/112 [==============================] - 0s 221us/sample - loss: 1.1796 - accuracy: 0.3393 - val_loss: 1.1399 - val_accuracy: 0.4211\n",
      "Epoch 8/50\n",
      "112/112 [==============================] - 0s 220us/sample - loss: 1.1679 - accuracy: 0.3393 - val_loss: 1.1269 - val_accuracy: 0.4211\n",
      "Epoch 9/50\n",
      "112/112 [==============================] - 0s 242us/sample - loss: 1.1562 - accuracy: 0.3571 - val_loss: 1.1138 - val_accuracy: 0.4211\n",
      "Epoch 10/50\n",
      "112/112 [==============================] - 0s 227us/sample - loss: 1.1444 - accuracy: 0.3750 - val_loss: 1.1008 - val_accuracy: 0.4211\n",
      "Epoch 11/50\n",
      "112/112 [==============================] - 0s 231us/sample - loss: 1.1327 - accuracy: 0.3929 - val_loss: 1.0880 - val_accuracy: 0.4211\n",
      "Epoch 12/50\n",
      "112/112 [==============================] - 0s 234us/sample - loss: 1.1212 - accuracy: 0.4107 - val_loss: 1.0753 - val_accuracy: 0.4211\n",
      "Epoch 13/50\n",
      "112/112 [==============================] - 0s 224us/sample - loss: 1.1098 - accuracy: 0.4107 - val_loss: 1.0629 - val_accuracy: 0.4474\n",
      "Epoch 14/50\n",
      "112/112 [==============================] - 0s 251us/sample - loss: 1.0986 - accuracy: 0.4107 - val_loss: 1.0506 - val_accuracy: 0.4474\n",
      "Epoch 15/50\n",
      "112/112 [==============================] - 0s 214us/sample - loss: 1.0876 - accuracy: 0.4107 - val_loss: 1.0386 - val_accuracy: 0.4474\n",
      "Epoch 16/50\n",
      "112/112 [==============================] - 0s 225us/sample - loss: 1.0768 - accuracy: 0.4286 - val_loss: 1.0268 - val_accuracy: 0.4737\n",
      "Epoch 17/50\n",
      "112/112 [==============================] - 0s 252us/sample - loss: 1.0663 - accuracy: 0.4464 - val_loss: 1.0153 - val_accuracy: 0.4737\n",
      "Epoch 18/50\n",
      "112/112 [==============================] - 0s 232us/sample - loss: 1.0559 - accuracy: 0.4464 - val_loss: 1.0041 - val_accuracy: 0.5000\n",
      "Epoch 19/50\n",
      "112/112 [==============================] - 0s 228us/sample - loss: 1.0458 - accuracy: 0.4464 - val_loss: 0.9931 - val_accuracy: 0.5526\n",
      "Epoch 20/50\n",
      "112/112 [==============================] - 0s 231us/sample - loss: 1.0359 - accuracy: 0.4554 - val_loss: 0.9824 - val_accuracy: 0.5789\n",
      "Epoch 21/50\n",
      "112/112 [==============================] - 0s 237us/sample - loss: 1.0262 - accuracy: 0.4821 - val_loss: 0.9720 - val_accuracy: 0.6053\n",
      "Epoch 22/50\n",
      "112/112 [==============================] - 0s 231us/sample - loss: 1.0167 - accuracy: 0.5000 - val_loss: 0.9619 - val_accuracy: 0.6316\n",
      "Epoch 23/50\n",
      "112/112 [==============================] - 0s 214us/sample - loss: 1.0075 - accuracy: 0.5268 - val_loss: 0.9519 - val_accuracy: 0.6842\n",
      "Epoch 24/50\n",
      "112/112 [==============================] - 0s 224us/sample - loss: 0.9985 - accuracy: 0.5804 - val_loss: 0.9421 - val_accuracy: 0.6842\n",
      "Epoch 25/50\n",
      "112/112 [==============================] - 0s 239us/sample - loss: 0.9898 - accuracy: 0.5982 - val_loss: 0.9326 - val_accuracy: 0.7632\n",
      "Epoch 26/50\n",
      "112/112 [==============================] - 0s 238us/sample - loss: 0.9812 - accuracy: 0.6071 - val_loss: 0.9233 - val_accuracy: 0.7632\n",
      "Epoch 27/50\n",
      "112/112 [==============================] - 0s 223us/sample - loss: 0.9729 - accuracy: 0.6339 - val_loss: 0.9143 - val_accuracy: 0.7895\n",
      "Epoch 28/50\n",
      "112/112 [==============================] - 0s 224us/sample - loss: 0.9648 - accuracy: 0.6429 - val_loss: 0.9054 - val_accuracy: 0.8158\n",
      "Epoch 29/50\n",
      "112/112 [==============================] - 0s 223us/sample - loss: 0.9569 - accuracy: 0.6696 - val_loss: 0.8967 - val_accuracy: 0.8421\n",
      "Epoch 30/50\n",
      "112/112 [==============================] - 0s 237us/sample - loss: 0.9491 - accuracy: 0.6786 - val_loss: 0.8882 - val_accuracy: 0.8684\n",
      "Epoch 31/50\n",
      "112/112 [==============================] - 0s 234us/sample - loss: 0.9415 - accuracy: 0.6964 - val_loss: 0.8799 - val_accuracy: 0.8684\n",
      "Epoch 32/50\n",
      "112/112 [==============================] - 0s 223us/sample - loss: 0.9340 - accuracy: 0.7143 - val_loss: 0.8718 - val_accuracy: 0.8947\n",
      "Epoch 33/50\n",
      "112/112 [==============================] - 0s 405us/sample - loss: 0.9267 - accuracy: 0.7143 - val_loss: 0.8638 - val_accuracy: 0.8947\n",
      "Epoch 34/50\n",
      "112/112 [==============================] - 0s 225us/sample - loss: 0.9196 - accuracy: 0.7321 - val_loss: 0.8559 - val_accuracy: 0.8947\n",
      "Epoch 35/50\n",
      "112/112 [==============================] - 0s 242us/sample - loss: 0.9126 - accuracy: 0.7411 - val_loss: 0.8483 - val_accuracy: 0.9211\n",
      "Epoch 36/50\n",
      "112/112 [==============================] - 0s 223us/sample - loss: 0.9058 - accuracy: 0.7500 - val_loss: 0.8408 - val_accuracy: 0.9211\n",
      "Epoch 37/50\n",
      "112/112 [==============================] - 0s 236us/sample - loss: 0.8991 - accuracy: 0.7500 - val_loss: 0.8334 - val_accuracy: 0.9211\n",
      "Epoch 38/50\n",
      "112/112 [==============================] - 0s 223us/sample - loss: 0.8926 - accuracy: 0.7500 - val_loss: 0.8261 - val_accuracy: 0.9211\n",
      "Epoch 39/50\n",
      "112/112 [==============================] - 0s 220us/sample - loss: 0.8861 - accuracy: 0.7500 - val_loss: 0.8189 - val_accuracy: 0.9211\n",
      "Epoch 40/50\n",
      "112/112 [==============================] - 0s 231us/sample - loss: 0.8798 - accuracy: 0.7500 - val_loss: 0.8119 - val_accuracy: 0.9211\n",
      "Epoch 41/50\n",
      "112/112 [==============================] - 0s 230us/sample - loss: 0.8736 - accuracy: 0.7500 - val_loss: 0.8049 - val_accuracy: 0.9211\n",
      "Epoch 42/50\n",
      "112/112 [==============================] - 0s 222us/sample - loss: 0.8675 - accuracy: 0.7500 - val_loss: 0.7982 - val_accuracy: 0.9211\n",
      "Epoch 43/50\n",
      "112/112 [==============================] - 0s 228us/sample - loss: 0.8615 - accuracy: 0.7500 - val_loss: 0.7915 - val_accuracy: 0.9211\n",
      "Epoch 44/50\n",
      "112/112 [==============================] - 0s 231us/sample - loss: 0.8556 - accuracy: 0.7500 - val_loss: 0.7850 - val_accuracy: 0.9211\n",
      "Epoch 45/50\n",
      "112/112 [==============================] - 0s 227us/sample - loss: 0.8498 - accuracy: 0.7500 - val_loss: 0.7785 - val_accuracy: 0.9211\n",
      "Epoch 46/50\n",
      "112/112 [==============================] - 0s 221us/sample - loss: 0.8441 - accuracy: 0.7500 - val_loss: 0.7722 - val_accuracy: 0.9211\n",
      "Epoch 47/50\n",
      "112/112 [==============================] - 0s 228us/sample - loss: 0.8385 - accuracy: 0.7500 - val_loss: 0.7660 - val_accuracy: 0.9211\n",
      "Epoch 48/50\n",
      "112/112 [==============================] - 0s 234us/sample - loss: 0.8330 - accuracy: 0.7500 - val_loss: 0.7599 - val_accuracy: 0.9211\n",
      "Epoch 49/50\n",
      "112/112 [==============================] - 0s 235us/sample - loss: 0.8276 - accuracy: 0.7500 - val_loss: 0.7538 - val_accuracy: 0.9211\n",
      "Epoch 50/50\n",
      "112/112 [==============================] - 0s 230us/sample - loss: 0.8222 - accuracy: 0.7500 - val_loss: 0.7479 - val_accuracy: 0.9211\n",
      "\n",
      "Forming the grid-search model #15 using: optimizer=<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7fe1d6395290>, kernel=<tensorflow.python.ops.init_ops_v2.GlorotNormal object at 0x7fe1b03bd290>, epochs=50, batch_size=32\n",
      "Train on 112 samples, validate on 38 samples\n",
      "Epoch 1/50\n",
      "112/112 [==============================] - 1s 9ms/sample - loss: 1.3493 - accuracy: 0.4196 - val_loss: 1.2355 - val_accuracy: 0.5000\n",
      "Epoch 2/50\n",
      "112/112 [==============================] - 0s 345us/sample - loss: 1.2837 - accuracy: 0.4375 - val_loss: 1.1587 - val_accuracy: 0.5000\n",
      "Epoch 3/50\n",
      "112/112 [==============================] - 0s 342us/sample - loss: 1.2035 - accuracy: 0.4464 - val_loss: 1.0805 - val_accuracy: 0.5263\n",
      "Epoch 4/50\n",
      "112/112 [==============================] - 0s 354us/sample - loss: 1.1333 - accuracy: 0.4643 - val_loss: 1.0047 - val_accuracy: 0.5263\n",
      "Epoch 5/50\n",
      "112/112 [==============================] - 0s 333us/sample - loss: 1.0570 - accuracy: 0.4643 - val_loss: 0.9370 - val_accuracy: 0.5263\n",
      "Epoch 6/50\n",
      "112/112 [==============================] - 0s 328us/sample - loss: 0.9866 - accuracy: 0.4732 - val_loss: 0.8765 - val_accuracy: 0.5526\n",
      "Epoch 7/50\n",
      "112/112 [==============================] - 0s 333us/sample - loss: 0.9281 - accuracy: 0.4911 - val_loss: 0.8222 - val_accuracy: 0.5789\n",
      "Epoch 8/50\n",
      "112/112 [==============================] - 0s 338us/sample - loss: 0.8757 - accuracy: 0.5625 - val_loss: 0.7744 - val_accuracy: 0.6842\n",
      "Epoch 9/50\n",
      "112/112 [==============================] - 0s 339us/sample - loss: 0.8288 - accuracy: 0.6429 - val_loss: 0.7326 - val_accuracy: 0.7895\n",
      "Epoch 10/50\n",
      "112/112 [==============================] - 0s 352us/sample - loss: 0.7891 - accuracy: 0.7143 - val_loss: 0.6966 - val_accuracy: 0.8684\n",
      "Epoch 11/50\n",
      "112/112 [==============================] - 0s 344us/sample - loss: 0.7541 - accuracy: 0.7321 - val_loss: 0.6653 - val_accuracy: 0.8684\n",
      "Epoch 12/50\n",
      "112/112 [==============================] - 0s 337us/sample - loss: 0.7233 - accuracy: 0.7768 - val_loss: 0.6380 - val_accuracy: 0.8684\n",
      "Epoch 13/50\n",
      "112/112 [==============================] - 0s 334us/sample - loss: 0.6963 - accuracy: 0.8125 - val_loss: 0.6143 - val_accuracy: 0.8684\n",
      "Epoch 14/50\n",
      "112/112 [==============================] - 0s 418us/sample - loss: 0.6734 - accuracy: 0.8125 - val_loss: 0.5929 - val_accuracy: 0.8684\n",
      "Epoch 15/50\n",
      "112/112 [==============================] - 0s 353us/sample - loss: 0.6525 - accuracy: 0.8125 - val_loss: 0.5742 - val_accuracy: 0.8684\n",
      "Epoch 16/50\n",
      "112/112 [==============================] - 0s 336us/sample - loss: 0.6340 - accuracy: 0.8125 - val_loss: 0.5572 - val_accuracy: 0.8684\n",
      "Epoch 17/50\n",
      "112/112 [==============================] - 0s 349us/sample - loss: 0.6168 - accuracy: 0.8125 - val_loss: 0.5421 - val_accuracy: 0.8684\n",
      "Epoch 18/50\n",
      "112/112 [==============================] - 0s 338us/sample - loss: 0.6016 - accuracy: 0.8125 - val_loss: 0.5286 - val_accuracy: 0.8684\n",
      "Epoch 19/50\n",
      "112/112 [==============================] - 0s 330us/sample - loss: 0.5875 - accuracy: 0.8125 - val_loss: 0.5164 - val_accuracy: 0.8684\n",
      "Epoch 20/50\n",
      "112/112 [==============================] - 0s 335us/sample - loss: 0.5750 - accuracy: 0.8125 - val_loss: 0.5051 - val_accuracy: 0.8684\n",
      "Epoch 21/50\n",
      "112/112 [==============================] - 0s 338us/sample - loss: 0.5634 - accuracy: 0.8125 - val_loss: 0.4948 - val_accuracy: 0.8684\n",
      "Epoch 22/50\n",
      "112/112 [==============================] - 0s 324us/sample - loss: 0.5523 - accuracy: 0.8125 - val_loss: 0.4852 - val_accuracy: 0.8684\n",
      "Epoch 23/50\n",
      "112/112 [==============================] - 0s 351us/sample - loss: 0.5424 - accuracy: 0.8125 - val_loss: 0.4762 - val_accuracy: 0.8684\n",
      "Epoch 24/50\n",
      "112/112 [==============================] - 0s 330us/sample - loss: 0.5330 - accuracy: 0.8214 - val_loss: 0.4678 - val_accuracy: 0.8684\n",
      "Epoch 25/50\n",
      "112/112 [==============================] - 0s 353us/sample - loss: 0.5241 - accuracy: 0.8214 - val_loss: 0.4600 - val_accuracy: 0.8684\n",
      "Epoch 26/50\n",
      "112/112 [==============================] - 0s 340us/sample - loss: 0.5161 - accuracy: 0.8214 - val_loss: 0.4526 - val_accuracy: 0.8684\n",
      "Epoch 27/50\n",
      "112/112 [==============================] - 0s 341us/sample - loss: 0.5081 - accuracy: 0.8214 - val_loss: 0.4458 - val_accuracy: 0.8684\n",
      "Epoch 28/50\n",
      "112/112 [==============================] - 0s 336us/sample - loss: 0.5009 - accuracy: 0.8214 - val_loss: 0.4392 - val_accuracy: 0.8684\n",
      "Epoch 29/50\n",
      "112/112 [==============================] - 0s 345us/sample - loss: 0.4941 - accuracy: 0.8304 - val_loss: 0.4332 - val_accuracy: 0.8684\n",
      "Epoch 30/50\n",
      "112/112 [==============================] - 0s 361us/sample - loss: 0.4875 - accuracy: 0.8304 - val_loss: 0.4275 - val_accuracy: 0.8684\n",
      "Epoch 31/50\n",
      "112/112 [==============================] - 0s 341us/sample - loss: 0.4813 - accuracy: 0.8304 - val_loss: 0.4223 - val_accuracy: 0.8684\n",
      "Epoch 32/50\n",
      "112/112 [==============================] - 0s 353us/sample - loss: 0.4753 - accuracy: 0.8304 - val_loss: 0.4174 - val_accuracy: 0.8684\n",
      "Epoch 33/50\n",
      "112/112 [==============================] - 0s 355us/sample - loss: 0.4698 - accuracy: 0.8304 - val_loss: 0.4125 - val_accuracy: 0.8684\n",
      "Epoch 34/50\n",
      "112/112 [==============================] - 0s 354us/sample - loss: 0.4644 - accuracy: 0.8214 - val_loss: 0.4077 - val_accuracy: 0.8684\n",
      "Epoch 35/50\n",
      "112/112 [==============================] - 0s 440us/sample - loss: 0.4594 - accuracy: 0.8304 - val_loss: 0.4032 - val_accuracy: 0.8684\n",
      "Epoch 36/50\n",
      "112/112 [==============================] - 0s 338us/sample - loss: 0.4542 - accuracy: 0.8304 - val_loss: 0.3989 - val_accuracy: 0.8684\n",
      "Epoch 37/50\n",
      "112/112 [==============================] - 0s 343us/sample - loss: 0.4495 - accuracy: 0.8304 - val_loss: 0.3948 - val_accuracy: 0.8684\n",
      "Epoch 38/50\n",
      "112/112 [==============================] - 0s 333us/sample - loss: 0.4449 - accuracy: 0.8304 - val_loss: 0.3907 - val_accuracy: 0.8684\n",
      "Epoch 39/50\n",
      "112/112 [==============================] - 0s 350us/sample - loss: 0.4405 - accuracy: 0.8214 - val_loss: 0.3870 - val_accuracy: 0.8684\n",
      "Epoch 40/50\n",
      "112/112 [==============================] - 0s 339us/sample - loss: 0.4364 - accuracy: 0.8214 - val_loss: 0.3832 - val_accuracy: 0.8684\n",
      "Epoch 41/50\n",
      "112/112 [==============================] - 0s 344us/sample - loss: 0.4323 - accuracy: 0.8214 - val_loss: 0.3797 - val_accuracy: 0.8684\n",
      "Epoch 42/50\n",
      "112/112 [==============================] - 0s 338us/sample - loss: 0.4285 - accuracy: 0.8214 - val_loss: 0.3762 - val_accuracy: 0.8684\n",
      "Epoch 43/50\n",
      "112/112 [==============================] - 0s 342us/sample - loss: 0.4245 - accuracy: 0.8214 - val_loss: 0.3728 - val_accuracy: 0.8684\n",
      "Epoch 44/50\n",
      "112/112 [==============================] - 0s 331us/sample - loss: 0.4209 - accuracy: 0.8214 - val_loss: 0.3696 - val_accuracy: 0.8684\n",
      "Epoch 45/50\n",
      "112/112 [==============================] - 0s 342us/sample - loss: 0.4175 - accuracy: 0.8214 - val_loss: 0.3664 - val_accuracy: 0.8684\n",
      "Epoch 46/50\n",
      "112/112 [==============================] - 0s 441us/sample - loss: 0.4139 - accuracy: 0.8214 - val_loss: 0.3633 - val_accuracy: 0.8947\n",
      "Epoch 47/50\n",
      "112/112 [==============================] - 0s 331us/sample - loss: 0.4106 - accuracy: 0.8214 - val_loss: 0.3602 - val_accuracy: 0.8947\n",
      "Epoch 48/50\n",
      "112/112 [==============================] - 0s 338us/sample - loss: 0.4073 - accuracy: 0.8214 - val_loss: 0.3574 - val_accuracy: 0.8947\n",
      "Epoch 49/50\n",
      "112/112 [==============================] - 0s 336us/sample - loss: 0.4043 - accuracy: 0.8214 - val_loss: 0.3545 - val_accuracy: 0.8947\n",
      "Epoch 50/50\n",
      "112/112 [==============================] - 0s 343us/sample - loss: 0.4012 - accuracy: 0.8214 - val_loss: 0.3520 - val_accuracy: 0.8947\n",
      "\n",
      "Forming the grid-search model #16 using: optimizer=<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7fe1d6395290>, kernel=<tensorflow.python.ops.init_ops_v2.GlorotNormal object at 0x7fe1b03bd290>, epochs=50, batch_size=64\n",
      "Train on 112 samples, validate on 38 samples\n",
      "Epoch 1/50\n",
      "112/112 [==============================] - 1s 12ms/sample - loss: 1.3577 - accuracy: 0.4196 - val_loss: 1.2648 - val_accuracy: 0.4737\n",
      "Epoch 2/50\n",
      "112/112 [==============================] - 0s 284us/sample - loss: 1.3281 - accuracy: 0.4196 - val_loss: 1.2269 - val_accuracy: 0.5000\n",
      "Epoch 3/50\n",
      "112/112 [==============================] - 0s 264us/sample - loss: 1.2881 - accuracy: 0.4375 - val_loss: 1.1847 - val_accuracy: 0.5000\n",
      "Epoch 4/50\n",
      "112/112 [==============================] - 0s 283us/sample - loss: 1.2502 - accuracy: 0.4375 - val_loss: 1.1409 - val_accuracy: 0.5000\n",
      "Epoch 5/50\n",
      "112/112 [==============================] - 0s 267us/sample - loss: 1.2061 - accuracy: 0.4375 - val_loss: 1.0974 - val_accuracy: 0.5263\n",
      "Epoch 6/50\n",
      "112/112 [==============================] - 0s 272us/sample - loss: 1.1595 - accuracy: 0.4554 - val_loss: 1.0546 - val_accuracy: 0.5263\n",
      "Epoch 7/50\n",
      "112/112 [==============================] - 0s 276us/sample - loss: 1.1187 - accuracy: 0.4643 - val_loss: 1.0129 - val_accuracy: 0.5263\n",
      "Epoch 8/50\n",
      "112/112 [==============================] - 0s 271us/sample - loss: 1.0779 - accuracy: 0.4643 - val_loss: 0.9733 - val_accuracy: 0.5263\n",
      "Epoch 9/50\n",
      "112/112 [==============================] - ETA: 0s - loss: 1.0171 - accuracy: 0.51 - 0s 291us/sample - loss: 1.0369 - accuracy: 0.4732 - val_loss: 0.9356 - val_accuracy: 0.5263\n",
      "Epoch 10/50\n",
      "112/112 [==============================] - 0s 362us/sample - loss: 1.0008 - accuracy: 0.4732 - val_loss: 0.8998 - val_accuracy: 0.5526\n",
      "Epoch 11/50\n",
      "112/112 [==============================] - 0s 301us/sample - loss: 0.9641 - accuracy: 0.4732 - val_loss: 0.8663 - val_accuracy: 0.5526\n",
      "Epoch 12/50\n",
      "112/112 [==============================] - 0s 277us/sample - loss: 0.9297 - accuracy: 0.4821 - val_loss: 0.8347 - val_accuracy: 0.5789\n",
      "Epoch 13/50\n",
      "112/112 [==============================] - 0s 268us/sample - loss: 0.8979 - accuracy: 0.5179 - val_loss: 0.8051 - val_accuracy: 0.6316\n",
      "Epoch 14/50\n",
      "112/112 [==============================] - 0s 273us/sample - loss: 0.8687 - accuracy: 0.5625 - val_loss: 0.7773 - val_accuracy: 0.6842\n",
      "Epoch 15/50\n",
      "112/112 [==============================] - 0s 325us/sample - loss: 0.8414 - accuracy: 0.5982 - val_loss: 0.7516 - val_accuracy: 0.7105\n",
      "Epoch 16/50\n",
      "112/112 [==============================] - 0s 273us/sample - loss: 0.8160 - accuracy: 0.6607 - val_loss: 0.7277 - val_accuracy: 0.7895\n",
      "Epoch 17/50\n",
      "112/112 [==============================] - 0s 274us/sample - loss: 0.7914 - accuracy: 0.7054 - val_loss: 0.7060 - val_accuracy: 0.8421\n",
      "Epoch 18/50\n",
      "112/112 [==============================] - 0s 271us/sample - loss: 0.7706 - accuracy: 0.7321 - val_loss: 0.6858 - val_accuracy: 0.8684\n",
      "Epoch 19/50\n",
      "112/112 [==============================] - 0s 266us/sample - loss: 0.7491 - accuracy: 0.7589 - val_loss: 0.6673 - val_accuracy: 0.8684\n",
      "Epoch 20/50\n",
      "112/112 [==============================] - 0s 268us/sample - loss: 0.7317 - accuracy: 0.7679 - val_loss: 0.6499 - val_accuracy: 0.8684\n",
      "Epoch 21/50\n",
      "112/112 [==============================] - 0s 353us/sample - loss: 0.7143 - accuracy: 0.7946 - val_loss: 0.6339 - val_accuracy: 0.8684\n",
      "Epoch 22/50\n",
      "112/112 [==============================] - 0s 290us/sample - loss: 0.6974 - accuracy: 0.8036 - val_loss: 0.6191 - val_accuracy: 0.8684\n",
      "Epoch 23/50\n",
      "112/112 [==============================] - 0s 266us/sample - loss: 0.6831 - accuracy: 0.8125 - val_loss: 0.6052 - val_accuracy: 0.8684\n",
      "Epoch 24/50\n",
      "112/112 [==============================] - 0s 266us/sample - loss: 0.6690 - accuracy: 0.8125 - val_loss: 0.5923 - val_accuracy: 0.8684\n",
      "Epoch 25/50\n",
      "112/112 [==============================] - 0s 276us/sample - loss: 0.6558 - accuracy: 0.8125 - val_loss: 0.5803 - val_accuracy: 0.8684\n",
      "Epoch 26/50\n",
      "112/112 [==============================] - 0s 264us/sample - loss: 0.6442 - accuracy: 0.8125 - val_loss: 0.5690 - val_accuracy: 0.8684\n",
      "Epoch 27/50\n",
      "112/112 [==============================] - 0s 264us/sample - loss: 0.6321 - accuracy: 0.8125 - val_loss: 0.5586 - val_accuracy: 0.8684\n",
      "Epoch 28/50\n",
      "112/112 [==============================] - 0s 284us/sample - loss: 0.6215 - accuracy: 0.8125 - val_loss: 0.5488 - val_accuracy: 0.8684\n",
      "Epoch 29/50\n",
      "112/112 [==============================] - 0s 276us/sample - loss: 0.6116 - accuracy: 0.8125 - val_loss: 0.5396 - val_accuracy: 0.8684\n",
      "Epoch 30/50\n",
      "112/112 [==============================] - 0s 281us/sample - loss: 0.6017 - accuracy: 0.8125 - val_loss: 0.5309 - val_accuracy: 0.8684\n",
      "Epoch 31/50\n",
      "112/112 [==============================] - 0s 288us/sample - loss: 0.5927 - accuracy: 0.8125 - val_loss: 0.5228 - val_accuracy: 0.8684\n",
      "Epoch 32/50\n",
      "112/112 [==============================] - 0s 278us/sample - loss: 0.5839 - accuracy: 0.8125 - val_loss: 0.5151 - val_accuracy: 0.8684\n",
      "Epoch 33/50\n",
      "112/112 [==============================] - 0s 264us/sample - loss: 0.5759 - accuracy: 0.8125 - val_loss: 0.5078 - val_accuracy: 0.8684\n",
      "Epoch 34/50\n",
      "112/112 [==============================] - 0s 294us/sample - loss: 0.5682 - accuracy: 0.8125 - val_loss: 0.5009 - val_accuracy: 0.8684\n",
      "Epoch 35/50\n",
      "112/112 [==============================] - 0s 280us/sample - loss: 0.5609 - accuracy: 0.8125 - val_loss: 0.4944 - val_accuracy: 0.8684\n",
      "Epoch 36/50\n",
      "112/112 [==============================] - 0s 268us/sample - loss: 0.5540 - accuracy: 0.8125 - val_loss: 0.4882 - val_accuracy: 0.8684\n",
      "Epoch 37/50\n",
      "112/112 [==============================] - 0s 281us/sample - loss: 0.5472 - accuracy: 0.8214 - val_loss: 0.4823 - val_accuracy: 0.8684\n",
      "Epoch 38/50\n",
      "112/112 [==============================] - 0s 284us/sample - loss: 0.5409 - accuracy: 0.8214 - val_loss: 0.4767 - val_accuracy: 0.8684\n",
      "Epoch 39/50\n",
      "112/112 [==============================] - 0s 266us/sample - loss: 0.5348 - accuracy: 0.8214 - val_loss: 0.4712 - val_accuracy: 0.8684\n",
      "Epoch 40/50\n",
      "112/112 [==============================] - 0s 259us/sample - loss: 0.5291 - accuracy: 0.8214 - val_loss: 0.4660 - val_accuracy: 0.8684\n",
      "Epoch 41/50\n",
      "112/112 [==============================] - 0s 271us/sample - loss: 0.5235 - accuracy: 0.8214 - val_loss: 0.4611 - val_accuracy: 0.8684\n",
      "Epoch 42/50\n",
      "112/112 [==============================] - 0s 266us/sample - loss: 0.5182 - accuracy: 0.8214 - val_loss: 0.4563 - val_accuracy: 0.8684\n",
      "Epoch 43/50\n",
      "112/112 [==============================] - 0s 275us/sample - loss: 0.5130 - accuracy: 0.8214 - val_loss: 0.4518 - val_accuracy: 0.8684\n",
      "Epoch 44/50\n",
      "112/112 [==============================] - 0s 327us/sample - loss: 0.5081 - accuracy: 0.8304 - val_loss: 0.4474 - val_accuracy: 0.8684\n",
      "Epoch 45/50\n",
      "112/112 [==============================] - 0s 276us/sample - loss: 0.5034 - accuracy: 0.8304 - val_loss: 0.4431 - val_accuracy: 0.8684\n",
      "Epoch 46/50\n",
      "112/112 [==============================] - 0s 282us/sample - loss: 0.4987 - accuracy: 0.8304 - val_loss: 0.4390 - val_accuracy: 0.8684\n",
      "Epoch 47/50\n",
      "112/112 [==============================] - 0s 274us/sample - loss: 0.4943 - accuracy: 0.8304 - val_loss: 0.4351 - val_accuracy: 0.8684\n",
      "Epoch 48/50\n",
      "112/112 [==============================] - 0s 270us/sample - loss: 0.4900 - accuracy: 0.8304 - val_loss: 0.4314 - val_accuracy: 0.8684\n",
      "Epoch 49/50\n",
      "112/112 [==============================] - 0s 289us/sample - loss: 0.4859 - accuracy: 0.8214 - val_loss: 0.4278 - val_accuracy: 0.8684\n",
      "Epoch 50/50\n",
      "112/112 [==============================] - 0s 354us/sample - loss: 0.4819 - accuracy: 0.8214 - val_loss: 0.4244 - val_accuracy: 0.8684\n",
      "\n",
      "Forming the grid-search model #17 using: optimizer=<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7fe1d6395290>, kernel=<tensorflow.python.ops.init_ops_v2.GlorotNormal object at 0x7fe1b03bd290>, epochs=50, batch_size=128\n",
      "Train on 112 samples, validate on 38 samples\n",
      "Epoch 1/50\n",
      "112/112 [==============================] - 1s 9ms/sample - loss: 1.3623 - accuracy: 0.4196 - val_loss: 1.2802 - val_accuracy: 0.4737\n",
      "Epoch 2/50\n",
      "112/112 [==============================] - 0s 213us/sample - loss: 1.3503 - accuracy: 0.4196 - val_loss: 1.2637 - val_accuracy: 0.5000\n",
      "Epoch 3/50\n",
      "112/112 [==============================] - 0s 214us/sample - loss: 1.3344 - accuracy: 0.4196 - val_loss: 1.2447 - val_accuracy: 0.5000\n",
      "Epoch 4/50\n",
      "112/112 [==============================] - 0s 221us/sample - loss: 1.3159 - accuracy: 0.4375 - val_loss: 1.2240 - val_accuracy: 0.5000\n",
      "Epoch 5/50\n",
      "112/112 [==============================] - 0s 228us/sample - loss: 1.2957 - accuracy: 0.4375 - val_loss: 1.2021 - val_accuracy: 0.5000\n",
      "Epoch 6/50\n",
      "112/112 [==============================] - 0s 216us/sample - loss: 1.2744 - accuracy: 0.4375 - val_loss: 1.1797 - val_accuracy: 0.5000\n",
      "Epoch 7/50\n",
      "112/112 [==============================] - 0s 236us/sample - loss: 1.2523 - accuracy: 0.4375 - val_loss: 1.1568 - val_accuracy: 0.5000\n",
      "Epoch 8/50\n",
      "112/112 [==============================] - 0s 225us/sample - loss: 1.2298 - accuracy: 0.4375 - val_loss: 1.1338 - val_accuracy: 0.5263\n",
      "Epoch 9/50\n",
      "112/112 [==============================] - 0s 219us/sample - loss: 1.2069 - accuracy: 0.4464 - val_loss: 1.1108 - val_accuracy: 0.5263\n",
      "Epoch 10/50\n",
      "112/112 [==============================] - 0s 233us/sample - loss: 1.1840 - accuracy: 0.4554 - val_loss: 1.0878 - val_accuracy: 0.5263\n",
      "Epoch 11/50\n",
      "112/112 [==============================] - 0s 230us/sample - loss: 1.1611 - accuracy: 0.4554 - val_loss: 1.0650 - val_accuracy: 0.5263\n",
      "Epoch 12/50\n",
      "112/112 [==============================] - 0s 218us/sample - loss: 1.1383 - accuracy: 0.4554 - val_loss: 1.0425 - val_accuracy: 0.5263\n",
      "Epoch 13/50\n",
      "112/112 [==============================] - 0s 228us/sample - loss: 1.1159 - accuracy: 0.4643 - val_loss: 1.0206 - val_accuracy: 0.5263\n",
      "Epoch 14/50\n",
      "112/112 [==============================] - 0s 223us/sample - loss: 1.0938 - accuracy: 0.4643 - val_loss: 0.9990 - val_accuracy: 0.5526\n",
      "Epoch 15/50\n",
      "112/112 [==============================] - 0s 226us/sample - loss: 1.0721 - accuracy: 0.4732 - val_loss: 0.9779 - val_accuracy: 0.5526\n",
      "Epoch 16/50\n",
      "112/112 [==============================] - 0s 233us/sample - loss: 1.0508 - accuracy: 0.4732 - val_loss: 0.9573 - val_accuracy: 0.5526\n",
      "Epoch 17/50\n",
      "112/112 [==============================] - 0s 278us/sample - loss: 1.0299 - accuracy: 0.4732 - val_loss: 0.9372 - val_accuracy: 0.5526\n",
      "Epoch 18/50\n",
      "112/112 [==============================] - 0s 223us/sample - loss: 1.0096 - accuracy: 0.4732 - val_loss: 0.9177 - val_accuracy: 0.5526\n",
      "Epoch 19/50\n",
      "112/112 [==============================] - 0s 236us/sample - loss: 0.9897 - accuracy: 0.4821 - val_loss: 0.8987 - val_accuracy: 0.5526\n",
      "Epoch 20/50\n",
      "112/112 [==============================] - 0s 236us/sample - loss: 0.9705 - accuracy: 0.4821 - val_loss: 0.8803 - val_accuracy: 0.5526\n",
      "Epoch 21/50\n",
      "112/112 [==============================] - 0s 222us/sample - loss: 0.9518 - accuracy: 0.4821 - val_loss: 0.8624 - val_accuracy: 0.5526\n",
      "Epoch 22/50\n",
      "112/112 [==============================] - 0s 233us/sample - loss: 0.9337 - accuracy: 0.4911 - val_loss: 0.8451 - val_accuracy: 0.5789\n",
      "Epoch 23/50\n",
      "112/112 [==============================] - 0s 233us/sample - loss: 0.9162 - accuracy: 0.5000 - val_loss: 0.8284 - val_accuracy: 0.5789\n",
      "Epoch 24/50\n",
      "112/112 [==============================] - 0s 217us/sample - loss: 0.8992 - accuracy: 0.5179 - val_loss: 0.8122 - val_accuracy: 0.5789\n",
      "Epoch 25/50\n",
      "112/112 [==============================] - 0s 225us/sample - loss: 0.8828 - accuracy: 0.5357 - val_loss: 0.7966 - val_accuracy: 0.6316\n",
      "Epoch 26/50\n",
      "112/112 [==============================] - 0s 230us/sample - loss: 0.8669 - accuracy: 0.5446 - val_loss: 0.7816 - val_accuracy: 0.6579\n",
      "Epoch 27/50\n",
      "112/112 [==============================] - 0s 229us/sample - loss: 0.8515 - accuracy: 0.5804 - val_loss: 0.7671 - val_accuracy: 0.6842\n",
      "Epoch 28/50\n",
      "112/112 [==============================] - 0s 235us/sample - loss: 0.8368 - accuracy: 0.5893 - val_loss: 0.7532 - val_accuracy: 0.7105\n",
      "Epoch 29/50\n",
      "112/112 [==============================] - 0s 243us/sample - loss: 0.8226 - accuracy: 0.6250 - val_loss: 0.7398 - val_accuracy: 0.7368\n",
      "Epoch 30/50\n",
      "112/112 [==============================] - 0s 235us/sample - loss: 0.8090 - accuracy: 0.6607 - val_loss: 0.7269 - val_accuracy: 0.7632\n",
      "Epoch 31/50\n",
      "112/112 [==============================] - 0s 231us/sample - loss: 0.7959 - accuracy: 0.6875 - val_loss: 0.7146 - val_accuracy: 0.8158\n",
      "Epoch 32/50\n",
      "112/112 [==============================] - 0s 254us/sample - loss: 0.7835 - accuracy: 0.7054 - val_loss: 0.7029 - val_accuracy: 0.8158\n",
      "Epoch 33/50\n",
      "112/112 [==============================] - 0s 265us/sample - loss: 0.7715 - accuracy: 0.7232 - val_loss: 0.6916 - val_accuracy: 0.8684\n",
      "Epoch 34/50\n",
      "112/112 [==============================] - 0s 227us/sample - loss: 0.7600 - accuracy: 0.7321 - val_loss: 0.6807 - val_accuracy: 0.8684\n",
      "Epoch 35/50\n",
      "112/112 [==============================] - 0s 236us/sample - loss: 0.7490 - accuracy: 0.7411 - val_loss: 0.6703 - val_accuracy: 0.8684\n",
      "Epoch 36/50\n",
      "112/112 [==============================] - 0s 244us/sample - loss: 0.7384 - accuracy: 0.7589 - val_loss: 0.6604 - val_accuracy: 0.8684\n",
      "Epoch 37/50\n",
      "112/112 [==============================] - 0s 229us/sample - loss: 0.7282 - accuracy: 0.7768 - val_loss: 0.6507 - val_accuracy: 0.8684\n",
      "Epoch 38/50\n",
      "112/112 [==============================] - 0s 246us/sample - loss: 0.7184 - accuracy: 0.7768 - val_loss: 0.6415 - val_accuracy: 0.8684\n",
      "Epoch 39/50\n",
      "112/112 [==============================] - 0s 241us/sample - loss: 0.7089 - accuracy: 0.7946 - val_loss: 0.6327 - val_accuracy: 0.8684\n",
      "Epoch 40/50\n",
      "112/112 [==============================] - 0s 230us/sample - loss: 0.6999 - accuracy: 0.7946 - val_loss: 0.6242 - val_accuracy: 0.8684\n",
      "Epoch 41/50\n",
      "112/112 [==============================] - 0s 241us/sample - loss: 0.6912 - accuracy: 0.8036 - val_loss: 0.6161 - val_accuracy: 0.8684\n",
      "Epoch 42/50\n",
      "112/112 [==============================] - 0s 240us/sample - loss: 0.6828 - accuracy: 0.8125 - val_loss: 0.6083 - val_accuracy: 0.8684\n",
      "Epoch 43/50\n",
      "112/112 [==============================] - 0s 248us/sample - loss: 0.6747 - accuracy: 0.8125 - val_loss: 0.6009 - val_accuracy: 0.8684\n",
      "Epoch 44/50\n",
      "112/112 [==============================] - 0s 227us/sample - loss: 0.6669 - accuracy: 0.8125 - val_loss: 0.5937 - val_accuracy: 0.8684\n",
      "Epoch 45/50\n",
      "112/112 [==============================] - 0s 225us/sample - loss: 0.6594 - accuracy: 0.8125 - val_loss: 0.5867 - val_accuracy: 0.8684\n",
      "Epoch 46/50\n",
      "112/112 [==============================] - 0s 228us/sample - loss: 0.6521 - accuracy: 0.8125 - val_loss: 0.5801 - val_accuracy: 0.8684\n",
      "Epoch 47/50\n",
      "112/112 [==============================] - 0s 223us/sample - loss: 0.6451 - accuracy: 0.8125 - val_loss: 0.5737 - val_accuracy: 0.8684\n",
      "Epoch 48/50\n",
      "112/112 [==============================] - 0s 229us/sample - loss: 0.6383 - accuracy: 0.8125 - val_loss: 0.5676 - val_accuracy: 0.8684\n",
      "Epoch 49/50\n",
      "112/112 [==============================] - 0s 227us/sample - loss: 0.6318 - accuracy: 0.8125 - val_loss: 0.5617 - val_accuracy: 0.8684\n",
      "Epoch 50/50\n",
      "112/112 [==============================] - 0s 411us/sample - loss: 0.6254 - accuracy: 0.8125 - val_loss: 0.5559 - val_accuracy: 0.8684\n",
      "\n",
      "Forming the grid-search model #18 using: optimizer=<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7fe1d6395cd0>, kernel=<tensorflow.python.ops.init_ops_v2.RandomNormal object at 0x7fe1b03bde50>, epochs=50, batch_size=32\n",
      "Train on 112 samples, validate on 38 samples\n",
      "Epoch 1/50\n",
      "112/112 [==============================] - 1s 9ms/sample - loss: 1.0964 - accuracy: 0.4286 - val_loss: 1.0945 - val_accuracy: 0.6053\n",
      "Epoch 2/50\n",
      "112/112 [==============================] - 0s 332us/sample - loss: 1.0961 - accuracy: 0.4643 - val_loss: 1.0942 - val_accuracy: 0.6316\n",
      "Epoch 3/50\n",
      "112/112 [==============================] - 0s 326us/sample - loss: 1.0958 - accuracy: 0.4911 - val_loss: 1.0938 - val_accuracy: 0.6842\n",
      "Epoch 4/50\n",
      "112/112 [==============================] - 0s 338us/sample - loss: 1.0955 - accuracy: 0.5089 - val_loss: 1.0935 - val_accuracy: 0.7368\n",
      "Epoch 5/50\n",
      "112/112 [==============================] - 0s 332us/sample - loss: 1.0951 - accuracy: 0.5357 - val_loss: 1.0931 - val_accuracy: 0.7632\n",
      "Epoch 6/50\n",
      "112/112 [==============================] - 0s 346us/sample - loss: 1.0948 - accuracy: 0.5446 - val_loss: 1.0928 - val_accuracy: 0.7632\n",
      "Epoch 7/50\n",
      "112/112 [==============================] - 0s 333us/sample - loss: 1.0945 - accuracy: 0.5536 - val_loss: 1.0924 - val_accuracy: 0.7632\n",
      "Epoch 8/50\n",
      "112/112 [==============================] - 0s 342us/sample - loss: 1.0942 - accuracy: 0.5714 - val_loss: 1.0921 - val_accuracy: 0.7895\n",
      "Epoch 9/50\n",
      "112/112 [==============================] - 0s 350us/sample - loss: 1.0939 - accuracy: 0.5714 - val_loss: 1.0917 - val_accuracy: 0.7895\n",
      "Epoch 10/50\n",
      "112/112 [==============================] - 0s 331us/sample - loss: 1.0936 - accuracy: 0.5804 - val_loss: 1.0914 - val_accuracy: 0.7895\n",
      "Epoch 11/50\n",
      "112/112 [==============================] - 0s 333us/sample - loss: 1.0932 - accuracy: 0.6161 - val_loss: 1.0910 - val_accuracy: 0.8947\n",
      "Epoch 12/50\n",
      "112/112 [==============================] - 0s 341us/sample - loss: 1.0929 - accuracy: 0.6429 - val_loss: 1.0906 - val_accuracy: 0.8947\n",
      "Epoch 13/50\n",
      "112/112 [==============================] - 0s 345us/sample - loss: 1.0925 - accuracy: 0.6786 - val_loss: 1.0902 - val_accuracy: 0.9211\n",
      "Epoch 14/50\n",
      "112/112 [==============================] - 0s 466us/sample - loss: 1.0922 - accuracy: 0.6964 - val_loss: 1.0898 - val_accuracy: 0.8947\n",
      "Epoch 15/50\n",
      "112/112 [==============================] - 0s 346us/sample - loss: 1.0918 - accuracy: 0.7054 - val_loss: 1.0894 - val_accuracy: 0.8947\n",
      "Epoch 16/50\n",
      "112/112 [==============================] - 0s 360us/sample - loss: 1.0915 - accuracy: 0.7143 - val_loss: 1.0890 - val_accuracy: 0.8947\n",
      "Epoch 17/50\n",
      "112/112 [==============================] - 0s 350us/sample - loss: 1.0911 - accuracy: 0.7232 - val_loss: 1.0886 - val_accuracy: 0.8947\n",
      "Epoch 18/50\n",
      "112/112 [==============================] - 0s 348us/sample - loss: 1.0907 - accuracy: 0.7321 - val_loss: 1.0882 - val_accuracy: 0.9211\n",
      "Epoch 19/50\n",
      "112/112 [==============================] - 0s 331us/sample - loss: 1.0903 - accuracy: 0.7321 - val_loss: 1.0878 - val_accuracy: 0.9211\n",
      "Epoch 20/50\n",
      "112/112 [==============================] - 0s 542us/sample - loss: 1.0899 - accuracy: 0.7321 - val_loss: 1.0874 - val_accuracy: 0.9211\n",
      "Epoch 21/50\n",
      "112/112 [==============================] - 0s 333us/sample - loss: 1.0895 - accuracy: 0.7411 - val_loss: 1.0869 - val_accuracy: 0.9211\n",
      "Epoch 22/50\n",
      "112/112 [==============================] - 0s 335us/sample - loss: 1.0891 - accuracy: 0.7411 - val_loss: 1.0865 - val_accuracy: 0.9211\n",
      "Epoch 23/50\n",
      "112/112 [==============================] - 0s 323us/sample - loss: 1.0886 - accuracy: 0.7411 - val_loss: 1.0860 - val_accuracy: 0.9211\n",
      "Epoch 24/50\n",
      "112/112 [==============================] - 0s 333us/sample - loss: 1.0882 - accuracy: 0.7411 - val_loss: 1.0856 - val_accuracy: 0.9211\n",
      "Epoch 25/50\n",
      "112/112 [==============================] - 0s 330us/sample - loss: 1.0878 - accuracy: 0.7500 - val_loss: 1.0851 - val_accuracy: 0.8947\n",
      "Epoch 26/50\n",
      "112/112 [==============================] - 0s 341us/sample - loss: 1.0873 - accuracy: 0.7500 - val_loss: 1.0846 - val_accuracy: 0.8947\n",
      "Epoch 27/50\n",
      "112/112 [==============================] - 0s 336us/sample - loss: 1.0869 - accuracy: 0.7500 - val_loss: 1.0842 - val_accuracy: 0.8947\n",
      "Epoch 28/50\n",
      "112/112 [==============================] - 0s 348us/sample - loss: 1.0864 - accuracy: 0.7679 - val_loss: 1.0837 - val_accuracy: 0.8947\n",
      "Epoch 29/50\n",
      "112/112 [==============================] - 0s 349us/sample - loss: 1.0860 - accuracy: 0.7589 - val_loss: 1.0832 - val_accuracy: 0.8947\n",
      "Epoch 30/50\n",
      "112/112 [==============================] - 0s 356us/sample - loss: 1.0855 - accuracy: 0.7768 - val_loss: 1.0827 - val_accuracy: 0.8947\n",
      "Epoch 31/50\n",
      "112/112 [==============================] - 0s 346us/sample - loss: 1.0850 - accuracy: 0.7857 - val_loss: 1.0822 - val_accuracy: 0.8947\n",
      "Epoch 32/50\n",
      "112/112 [==============================] - 0s 350us/sample - loss: 1.0845 - accuracy: 0.7857 - val_loss: 1.0817 - val_accuracy: 0.8947\n",
      "Epoch 33/50\n",
      "112/112 [==============================] - 0s 338us/sample - loss: 1.0840 - accuracy: 0.7857 - val_loss: 1.0812 - val_accuracy: 0.8947\n",
      "Epoch 34/50\n",
      "112/112 [==============================] - 0s 348us/sample - loss: 1.0835 - accuracy: 0.7857 - val_loss: 1.0806 - val_accuracy: 0.8947\n",
      "Epoch 35/50\n",
      "112/112 [==============================] - 0s 337us/sample - loss: 1.0830 - accuracy: 0.7857 - val_loss: 1.0801 - val_accuracy: 0.8947\n",
      "Epoch 36/50\n",
      "112/112 [==============================] - 0s 337us/sample - loss: 1.0825 - accuracy: 0.7946 - val_loss: 1.0796 - val_accuracy: 0.8947\n",
      "Epoch 37/50\n",
      "112/112 [==============================] - 0s 352us/sample - loss: 1.0820 - accuracy: 0.7946 - val_loss: 1.0790 - val_accuracy: 0.8947\n",
      "Epoch 38/50\n",
      "112/112 [==============================] - 0s 335us/sample - loss: 1.0815 - accuracy: 0.7946 - val_loss: 1.0784 - val_accuracy: 0.8947\n",
      "Epoch 39/50\n",
      "112/112 [==============================] - 0s 411us/sample - loss: 1.0809 - accuracy: 0.7946 - val_loss: 1.0779 - val_accuracy: 0.9211\n",
      "Epoch 40/50\n",
      "112/112 [==============================] - 0s 344us/sample - loss: 1.0804 - accuracy: 0.8036 - val_loss: 1.0773 - val_accuracy: 0.9211\n",
      "Epoch 41/50\n",
      "112/112 [==============================] - 0s 340us/sample - loss: 1.0798 - accuracy: 0.8036 - val_loss: 1.0767 - val_accuracy: 0.9211\n",
      "Epoch 42/50\n",
      "112/112 [==============================] - 0s 341us/sample - loss: 1.0793 - accuracy: 0.8036 - val_loss: 1.0762 - val_accuracy: 0.9211\n",
      "Epoch 43/50\n",
      "112/112 [==============================] - 0s 452us/sample - loss: 1.0787 - accuracy: 0.8036 - val_loss: 1.0756 - val_accuracy: 0.9211\n",
      "Epoch 44/50\n",
      "112/112 [==============================] - 0s 370us/sample - loss: 1.0781 - accuracy: 0.8036 - val_loss: 1.0750 - val_accuracy: 0.9211\n",
      "Epoch 45/50\n",
      "112/112 [==============================] - 0s 348us/sample - loss: 1.0775 - accuracy: 0.8036 - val_loss: 1.0744 - val_accuracy: 0.9211\n",
      "Epoch 46/50\n",
      "112/112 [==============================] - 0s 340us/sample - loss: 1.0769 - accuracy: 0.8036 - val_loss: 1.0738 - val_accuracy: 0.9211\n",
      "Epoch 47/50\n",
      "112/112 [==============================] - 0s 338us/sample - loss: 1.0764 - accuracy: 0.8036 - val_loss: 1.0731 - val_accuracy: 0.9211\n",
      "Epoch 48/50\n",
      "112/112 [==============================] - 0s 345us/sample - loss: 1.0758 - accuracy: 0.8036 - val_loss: 1.0725 - val_accuracy: 0.9211\n",
      "Epoch 49/50\n",
      "112/112 [==============================] - 0s 351us/sample - loss: 1.0751 - accuracy: 0.8036 - val_loss: 1.0719 - val_accuracy: 0.9211\n",
      "Epoch 50/50\n",
      "112/112 [==============================] - 0s 397us/sample - loss: 1.0745 - accuracy: 0.8036 - val_loss: 1.0712 - val_accuracy: 0.9211\n",
      "\n",
      "Forming the grid-search model #19 using: optimizer=<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7fe1d6395cd0>, kernel=<tensorflow.python.ops.init_ops_v2.RandomNormal object at 0x7fe1b03bde50>, epochs=50, batch_size=64\n",
      "Train on 112 samples, validate on 38 samples\n",
      "Epoch 1/50\n",
      "112/112 [==============================] - 1s 12ms/sample - loss: 1.0964 - accuracy: 0.4196 - val_loss: 1.0945 - val_accuracy: 0.6053\n",
      "Epoch 2/50\n",
      "112/112 [==============================] - 0s 270us/sample - loss: 1.0962 - accuracy: 0.4554 - val_loss: 1.0942 - val_accuracy: 0.6316\n",
      "Epoch 3/50\n",
      "112/112 [==============================] - 0s 255us/sample - loss: 1.0958 - accuracy: 0.4911 - val_loss: 1.0937 - val_accuracy: 0.6842\n",
      "Epoch 4/50\n",
      "112/112 [==============================] - 0s 266us/sample - loss: 1.0954 - accuracy: 0.5179 - val_loss: 1.0932 - val_accuracy: 0.7632\n",
      "Epoch 5/50\n",
      "112/112 [==============================] - 0s 284us/sample - loss: 1.0949 - accuracy: 0.5446 - val_loss: 1.0927 - val_accuracy: 0.7632\n",
      "Epoch 6/50\n",
      "112/112 [==============================] - 0s 264us/sample - loss: 1.0945 - accuracy: 0.5536 - val_loss: 1.0922 - val_accuracy: 0.7895\n",
      "Epoch 7/50\n",
      "112/112 [==============================] - 0s 297us/sample - loss: 1.0940 - accuracy: 0.5714 - val_loss: 1.0917 - val_accuracy: 0.7895\n",
      "Epoch 8/50\n",
      "112/112 [==============================] - 0s 270us/sample - loss: 1.0935 - accuracy: 0.6161 - val_loss: 1.0911 - val_accuracy: 0.8947\n",
      "Epoch 9/50\n",
      "112/112 [==============================] - 0s 274us/sample - loss: 1.0930 - accuracy: 0.6429 - val_loss: 1.0906 - val_accuracy: 0.8947\n",
      "Epoch 10/50\n",
      "112/112 [==============================] - 0s 275us/sample - loss: 1.0925 - accuracy: 0.6607 - val_loss: 1.0900 - val_accuracy: 0.9211\n",
      "Epoch 11/50\n",
      "112/112 [==============================] - 0s 261us/sample - loss: 1.0920 - accuracy: 0.6875 - val_loss: 1.0895 - val_accuracy: 0.9211\n",
      "Epoch 12/50\n",
      "112/112 [==============================] - 0s 298us/sample - loss: 1.0915 - accuracy: 0.7054 - val_loss: 1.0890 - val_accuracy: 0.8947\n",
      "Epoch 13/50\n",
      "112/112 [==============================] - 0s 265us/sample - loss: 1.0910 - accuracy: 0.7232 - val_loss: 1.0884 - val_accuracy: 0.9211\n",
      "Epoch 14/50\n",
      "112/112 [==============================] - 0s 273us/sample - loss: 1.0905 - accuracy: 0.7321 - val_loss: 1.0879 - val_accuracy: 0.9211\n",
      "Epoch 15/50\n",
      "112/112 [==============================] - 0s 271us/sample - loss: 1.0900 - accuracy: 0.7321 - val_loss: 1.0873 - val_accuracy: 0.9211\n",
      "Epoch 16/50\n",
      "112/112 [==============================] - 0s 293us/sample - loss: 1.0895 - accuracy: 0.7411 - val_loss: 1.0868 - val_accuracy: 0.9211\n",
      "Epoch 17/50\n",
      "112/112 [==============================] - 0s 259us/sample - loss: 1.0890 - accuracy: 0.7500 - val_loss: 1.0862 - val_accuracy: 0.9211\n",
      "Epoch 18/50\n",
      "112/112 [==============================] - 0s 269us/sample - loss: 1.0885 - accuracy: 0.7500 - val_loss: 1.0857 - val_accuracy: 0.9211\n",
      "Epoch 19/50\n",
      "112/112 [==============================] - 0s 270us/sample - loss: 1.0879 - accuracy: 0.7589 - val_loss: 1.0851 - val_accuracy: 0.9211\n",
      "Epoch 20/50\n",
      "112/112 [==============================] - 0s 271us/sample - loss: 1.0874 - accuracy: 0.7589 - val_loss: 1.0846 - val_accuracy: 0.9211\n",
      "Epoch 21/50\n",
      "112/112 [==============================] - 0s 261us/sample - loss: 1.0869 - accuracy: 0.7589 - val_loss: 1.0841 - val_accuracy: 0.9211\n",
      "Epoch 22/50\n",
      "112/112 [==============================] - 0s 277us/sample - loss: 1.0864 - accuracy: 0.7679 - val_loss: 1.0835 - val_accuracy: 0.8947\n",
      "Epoch 23/50\n",
      "112/112 [==============================] - 0s 283us/sample - loss: 1.0859 - accuracy: 0.7679 - val_loss: 1.0830 - val_accuracy: 0.8947\n",
      "Epoch 24/50\n",
      "112/112 [==============================] - 0s 270us/sample - loss: 1.0854 - accuracy: 0.7679 - val_loss: 1.0825 - val_accuracy: 0.8947\n",
      "Epoch 25/50\n",
      "112/112 [==============================] - 0s 268us/sample - loss: 1.0849 - accuracy: 0.7679 - val_loss: 1.0819 - val_accuracy: 0.8947\n",
      "Epoch 26/50\n",
      "112/112 [==============================] - 0s 275us/sample - loss: 1.0844 - accuracy: 0.7857 - val_loss: 1.0814 - val_accuracy: 0.8947\n",
      "Epoch 27/50\n",
      "112/112 [==============================] - 0s 281us/sample - loss: 1.0838 - accuracy: 0.7946 - val_loss: 1.0809 - val_accuracy: 0.8947\n",
      "Epoch 28/50\n",
      "112/112 [==============================] - 0s 265us/sample - loss: 1.0833 - accuracy: 0.7946 - val_loss: 1.0803 - val_accuracy: 0.8947\n",
      "Epoch 29/50\n",
      "112/112 [==============================] - 0s 273us/sample - loss: 1.0828 - accuracy: 0.7946 - val_loss: 1.0798 - val_accuracy: 0.8947\n",
      "Epoch 30/50\n",
      "112/112 [==============================] - 0s 276us/sample - loss: 1.0823 - accuracy: 0.7946 - val_loss: 1.0793 - val_accuracy: 0.8947\n",
      "Epoch 31/50\n",
      "112/112 [==============================] - 0s 283us/sample - loss: 1.0818 - accuracy: 0.7946 - val_loss: 1.0787 - val_accuracy: 0.8947\n",
      "Epoch 32/50\n",
      "112/112 [==============================] - 0s 283us/sample - loss: 1.0813 - accuracy: 0.7946 - val_loss: 1.0782 - val_accuracy: 0.8947\n",
      "Epoch 33/50\n",
      "112/112 [==============================] - 0s 283us/sample - loss: 1.0807 - accuracy: 0.7946 - val_loss: 1.0777 - val_accuracy: 0.8947\n",
      "Epoch 34/50\n",
      "112/112 [==============================] - 0s 284us/sample - loss: 1.0802 - accuracy: 0.7946 - val_loss: 1.0771 - val_accuracy: 0.8947\n",
      "Epoch 35/50\n",
      "112/112 [==============================] - 0s 301us/sample - loss: 1.0797 - accuracy: 0.7946 - val_loss: 1.0766 - val_accuracy: 0.8947\n",
      "Epoch 36/50\n",
      "112/112 [==============================] - 0s 278us/sample - loss: 1.0792 - accuracy: 0.7946 - val_loss: 1.0761 - val_accuracy: 0.8947\n",
      "Epoch 37/50\n",
      "112/112 [==============================] - 0s 278us/sample - loss: 1.0787 - accuracy: 0.7946 - val_loss: 1.0755 - val_accuracy: 0.8947\n",
      "Epoch 38/50\n",
      "112/112 [==============================] - 0s 276us/sample - loss: 1.0782 - accuracy: 0.8036 - val_loss: 1.0750 - val_accuracy: 0.9211\n",
      "Epoch 39/50\n",
      "112/112 [==============================] - 0s 272us/sample - loss: 1.0776 - accuracy: 0.8036 - val_loss: 1.0745 - val_accuracy: 0.9211\n",
      "Epoch 40/50\n",
      "112/112 [==============================] - 0s 268us/sample - loss: 1.0771 - accuracy: 0.8036 - val_loss: 1.0739 - val_accuracy: 0.9211\n",
      "Epoch 41/50\n",
      "112/112 [==============================] - 0s 274us/sample - loss: 1.0766 - accuracy: 0.8036 - val_loss: 1.0734 - val_accuracy: 0.9211\n",
      "Epoch 42/50\n",
      "112/112 [==============================] - 0s 282us/sample - loss: 1.0761 - accuracy: 0.8036 - val_loss: 1.0729 - val_accuracy: 0.9211\n",
      "Epoch 43/50\n",
      "112/112 [==============================] - 0s 264us/sample - loss: 1.0756 - accuracy: 0.8036 - val_loss: 1.0723 - val_accuracy: 0.9211\n",
      "Epoch 44/50\n",
      "112/112 [==============================] - 0s 255us/sample - loss: 1.0750 - accuracy: 0.8036 - val_loss: 1.0718 - val_accuracy: 0.9211\n",
      "Epoch 45/50\n",
      "112/112 [==============================] - 0s 325us/sample - loss: 1.0745 - accuracy: 0.8036 - val_loss: 1.0712 - val_accuracy: 0.9211\n",
      "Epoch 46/50\n",
      "112/112 [==============================] - 0s 268us/sample - loss: 1.0739 - accuracy: 0.8036 - val_loss: 1.0707 - val_accuracy: 0.9211\n",
      "Epoch 47/50\n",
      "112/112 [==============================] - 0s 276us/sample - loss: 1.0734 - accuracy: 0.8036 - val_loss: 1.0701 - val_accuracy: 0.9211\n",
      "Epoch 48/50\n",
      "112/112 [==============================] - 0s 282us/sample - loss: 1.0729 - accuracy: 0.8036 - val_loss: 1.0696 - val_accuracy: 0.9211\n",
      "Epoch 49/50\n",
      "112/112 [==============================] - 0s 347us/sample - loss: 1.0724 - accuracy: 0.8036 - val_loss: 1.0690 - val_accuracy: 0.9211\n",
      "Epoch 50/50\n",
      "112/112 [==============================] - 0s 252us/sample - loss: 1.0718 - accuracy: 0.8036 - val_loss: 1.0685 - val_accuracy: 0.9211\n",
      "\n",
      "Forming the grid-search model #20 using: optimizer=<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7fe1d6395cd0>, kernel=<tensorflow.python.ops.init_ops_v2.RandomNormal object at 0x7fe1b03bde50>, epochs=50, batch_size=128\n",
      "Train on 112 samples, validate on 38 samples\n",
      "Epoch 1/50\n",
      "112/112 [==============================] - 1s 9ms/sample - loss: 1.0965 - accuracy: 0.4196 - val_loss: 1.0947 - val_accuracy: 0.5526\n",
      "Epoch 2/50\n",
      "112/112 [==============================] - 0s 261us/sample - loss: 1.0963 - accuracy: 0.4196 - val_loss: 1.0945 - val_accuracy: 0.5263\n",
      "Epoch 3/50\n",
      "112/112 [==============================] - 0s 226us/sample - loss: 1.0962 - accuracy: 0.4375 - val_loss: 1.0943 - val_accuracy: 0.5263\n",
      "Epoch 4/50\n",
      "112/112 [==============================] - 0s 213us/sample - loss: 1.0960 - accuracy: 0.4732 - val_loss: 1.0941 - val_accuracy: 0.5263\n",
      "Epoch 5/50\n",
      "112/112 [==============================] - 0s 269us/sample - loss: 1.0957 - accuracy: 0.4643 - val_loss: 1.0938 - val_accuracy: 0.5526\n",
      "Epoch 6/50\n",
      "112/112 [==============================] - 0s 232us/sample - loss: 1.0955 - accuracy: 0.4821 - val_loss: 1.0935 - val_accuracy: 0.5789\n",
      "Epoch 7/50\n",
      "112/112 [==============================] - 0s 221us/sample - loss: 1.0952 - accuracy: 0.4821 - val_loss: 1.0932 - val_accuracy: 0.5789\n",
      "Epoch 8/50\n",
      "112/112 [==============================] - 0s 248us/sample - loss: 1.0950 - accuracy: 0.5268 - val_loss: 1.0930 - val_accuracy: 0.5789\n",
      "Epoch 9/50\n",
      "112/112 [==============================] - 0s 258us/sample - loss: 1.0947 - accuracy: 0.5357 - val_loss: 1.0927 - val_accuracy: 0.5789\n",
      "Epoch 10/50\n",
      "112/112 [==============================] - 0s 234us/sample - loss: 1.0944 - accuracy: 0.5357 - val_loss: 1.0923 - val_accuracy: 0.5789\n",
      "Epoch 11/50\n",
      "112/112 [==============================] - 0s 256us/sample - loss: 1.0941 - accuracy: 0.5357 - val_loss: 1.0920 - val_accuracy: 0.5789\n",
      "Epoch 12/50\n",
      "112/112 [==============================] - 0s 235us/sample - loss: 1.0938 - accuracy: 0.5446 - val_loss: 1.0917 - val_accuracy: 0.5789\n",
      "Epoch 13/50\n",
      "112/112 [==============================] - 0s 232us/sample - loss: 1.0935 - accuracy: 0.5536 - val_loss: 1.0914 - val_accuracy: 0.6053\n",
      "Epoch 14/50\n",
      "112/112 [==============================] - 0s 228us/sample - loss: 1.0932 - accuracy: 0.5714 - val_loss: 1.0911 - val_accuracy: 0.5789\n",
      "Epoch 15/50\n",
      "112/112 [==============================] - 0s 226us/sample - loss: 1.0929 - accuracy: 0.5625 - val_loss: 1.0908 - val_accuracy: 0.5789\n",
      "Epoch 16/50\n",
      "112/112 [==============================] - 0s 214us/sample - loss: 1.0926 - accuracy: 0.5625 - val_loss: 1.0904 - val_accuracy: 0.5789\n",
      "Epoch 17/50\n",
      "112/112 [==============================] - 0s 216us/sample - loss: 1.0923 - accuracy: 0.5536 - val_loss: 1.0901 - val_accuracy: 0.5789\n",
      "Epoch 18/50\n",
      "112/112 [==============================] - 0s 223us/sample - loss: 1.0920 - accuracy: 0.5625 - val_loss: 1.0898 - val_accuracy: 0.5789\n",
      "Epoch 19/50\n",
      "112/112 [==============================] - 0s 235us/sample - loss: 1.0917 - accuracy: 0.5536 - val_loss: 1.0894 - val_accuracy: 0.5789\n",
      "Epoch 20/50\n",
      "112/112 [==============================] - 0s 226us/sample - loss: 1.0913 - accuracy: 0.5536 - val_loss: 1.0891 - val_accuracy: 0.5789\n",
      "Epoch 21/50\n",
      "112/112 [==============================] - 0s 252us/sample - loss: 1.0910 - accuracy: 0.5536 - val_loss: 1.0888 - val_accuracy: 0.5789\n",
      "Epoch 22/50\n",
      "112/112 [==============================] - 0s 221us/sample - loss: 1.0907 - accuracy: 0.5536 - val_loss: 1.0884 - val_accuracy: 0.5789\n",
      "Epoch 23/50\n",
      "112/112 [==============================] - 0s 230us/sample - loss: 1.0904 - accuracy: 0.5446 - val_loss: 1.0881 - val_accuracy: 0.5526\n",
      "Epoch 24/50\n",
      "112/112 [==============================] - 0s 266us/sample - loss: 1.0900 - accuracy: 0.5446 - val_loss: 1.0878 - val_accuracy: 0.5526\n",
      "Epoch 25/50\n",
      "112/112 [==============================] - 0s 241us/sample - loss: 1.0897 - accuracy: 0.5446 - val_loss: 1.0874 - val_accuracy: 0.5526\n",
      "Epoch 26/50\n",
      "112/112 [==============================] - 0s 224us/sample - loss: 1.0894 - accuracy: 0.5446 - val_loss: 1.0871 - val_accuracy: 0.5526\n",
      "Epoch 27/50\n",
      "112/112 [==============================] - 0s 240us/sample - loss: 1.0891 - accuracy: 0.5446 - val_loss: 1.0868 - val_accuracy: 0.5526\n",
      "Epoch 28/50\n",
      "112/112 [==============================] - 0s 235us/sample - loss: 1.0887 - accuracy: 0.5446 - val_loss: 1.0864 - val_accuracy: 0.5526\n",
      "Epoch 29/50\n",
      "112/112 [==============================] - 0s 232us/sample - loss: 1.0884 - accuracy: 0.5625 - val_loss: 1.0861 - val_accuracy: 0.5789\n",
      "Epoch 30/50\n",
      "112/112 [==============================] - 0s 226us/sample - loss: 1.0881 - accuracy: 0.5625 - val_loss: 1.0858 - val_accuracy: 0.5789\n",
      "Epoch 31/50\n",
      "112/112 [==============================] - 0s 214us/sample - loss: 1.0877 - accuracy: 0.5625 - val_loss: 1.0854 - val_accuracy: 0.5789\n",
      "Epoch 32/50\n",
      "112/112 [==============================] - 0s 226us/sample - loss: 1.0874 - accuracy: 0.5625 - val_loss: 1.0851 - val_accuracy: 0.5789\n",
      "Epoch 33/50\n",
      "112/112 [==============================] - 0s 224us/sample - loss: 1.0871 - accuracy: 0.5625 - val_loss: 1.0847 - val_accuracy: 0.5789\n",
      "Epoch 34/50\n",
      "112/112 [==============================] - 0s 231us/sample - loss: 1.0868 - accuracy: 0.5625 - val_loss: 1.0844 - val_accuracy: 0.5789\n",
      "Epoch 35/50\n",
      "112/112 [==============================] - 0s 231us/sample - loss: 1.0864 - accuracy: 0.5625 - val_loss: 1.0841 - val_accuracy: 0.6053\n",
      "Epoch 36/50\n",
      "112/112 [==============================] - 0s 230us/sample - loss: 1.0861 - accuracy: 0.5714 - val_loss: 1.0837 - val_accuracy: 0.6053\n",
      "Epoch 37/50\n",
      "112/112 [==============================] - 0s 230us/sample - loss: 1.0858 - accuracy: 0.5804 - val_loss: 1.0834 - val_accuracy: 0.6053\n",
      "Epoch 38/50\n",
      "112/112 [==============================] - 0s 255us/sample - loss: 1.0855 - accuracy: 0.5804 - val_loss: 1.0831 - val_accuracy: 0.6316\n",
      "Epoch 39/50\n",
      "112/112 [==============================] - 0s 223us/sample - loss: 1.0851 - accuracy: 0.5982 - val_loss: 1.0827 - val_accuracy: 0.6316\n",
      "Epoch 40/50\n",
      "112/112 [==============================] - 0s 223us/sample - loss: 1.0848 - accuracy: 0.5982 - val_loss: 1.0824 - val_accuracy: 0.6316\n",
      "Epoch 41/50\n",
      "112/112 [==============================] - 0s 224us/sample - loss: 1.0845 - accuracy: 0.5982 - val_loss: 1.0821 - val_accuracy: 0.6316\n",
      "Epoch 42/50\n",
      "112/112 [==============================] - 0s 215us/sample - loss: 1.0842 - accuracy: 0.5982 - val_loss: 1.0817 - val_accuracy: 0.6579\n",
      "Epoch 43/50\n",
      "112/112 [==============================] - 0s 258us/sample - loss: 1.0838 - accuracy: 0.5982 - val_loss: 1.0814 - val_accuracy: 0.6579\n",
      "Epoch 44/50\n",
      "112/112 [==============================] - 0s 215us/sample - loss: 1.0835 - accuracy: 0.6071 - val_loss: 1.0811 - val_accuracy: 0.6842\n",
      "Epoch 45/50\n",
      "112/112 [==============================] - 0s 225us/sample - loss: 1.0832 - accuracy: 0.6161 - val_loss: 1.0807 - val_accuracy: 0.6842\n",
      "Epoch 46/50\n",
      "112/112 [==============================] - 0s 258us/sample - loss: 1.0828 - accuracy: 0.6250 - val_loss: 1.0804 - val_accuracy: 0.6842\n",
      "Epoch 47/50\n",
      "112/112 [==============================] - 0s 224us/sample - loss: 1.0825 - accuracy: 0.6250 - val_loss: 1.0801 - val_accuracy: 0.6842\n",
      "Epoch 48/50\n",
      "112/112 [==============================] - 0s 253us/sample - loss: 1.0822 - accuracy: 0.6429 - val_loss: 1.0797 - val_accuracy: 0.6842\n",
      "Epoch 49/50\n",
      "112/112 [==============================] - 0s 238us/sample - loss: 1.0819 - accuracy: 0.6339 - val_loss: 1.0794 - val_accuracy: 0.6842\n",
      "Epoch 50/50\n",
      "112/112 [==============================] - 0s 224us/sample - loss: 1.0815 - accuracy: 0.6339 - val_loss: 1.0790 - val_accuracy: 0.6842\n",
      "\n",
      "Forming the grid-search model #21 using: optimizer=<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7fe1d6395cd0>, kernel=<tensorflow.python.ops.init_ops_v2.Orthogonal object at 0x7fe1b03bd4d0>, epochs=50, batch_size=32\n",
      "Train on 112 samples, validate on 38 samples\n",
      "Epoch 1/50\n",
      "112/112 [==============================] - 1s 9ms/sample - loss: 1.2365 - accuracy: 0.2679 - val_loss: 1.2121 - val_accuracy: 0.3158\n",
      "Epoch 2/50\n",
      "112/112 [==============================] - 0s 344us/sample - loss: 1.2303 - accuracy: 0.2768 - val_loss: 1.2043 - val_accuracy: 0.3421\n",
      "Epoch 3/50\n",
      "112/112 [==============================] - 0s 337us/sample - loss: 1.2230 - accuracy: 0.3036 - val_loss: 1.1959 - val_accuracy: 0.3421\n",
      "Epoch 4/50\n",
      "112/112 [==============================] - 0s 347us/sample - loss: 1.2158 - accuracy: 0.3036 - val_loss: 1.1875 - val_accuracy: 0.3421\n",
      "Epoch 5/50\n",
      "112/112 [==============================] - 0s 336us/sample - loss: 1.2078 - accuracy: 0.3125 - val_loss: 1.1795 - val_accuracy: 0.3421\n",
      "Epoch 6/50\n",
      "112/112 [==============================] - 0s 352us/sample - loss: 1.2009 - accuracy: 0.3214 - val_loss: 1.1717 - val_accuracy: 0.3684\n",
      "Epoch 7/50\n",
      "112/112 [==============================] - 0s 371us/sample - loss: 1.1940 - accuracy: 0.3304 - val_loss: 1.1643 - val_accuracy: 0.3947\n",
      "Epoch 8/50\n",
      "112/112 [==============================] - 0s 336us/sample - loss: 1.1879 - accuracy: 0.3393 - val_loss: 1.1573 - val_accuracy: 0.3947\n",
      "Epoch 9/50\n",
      "112/112 [==============================] - 0s 352us/sample - loss: 1.1814 - accuracy: 0.3482 - val_loss: 1.1508 - val_accuracy: 0.4211\n",
      "Epoch 10/50\n",
      "112/112 [==============================] - 0s 327us/sample - loss: 1.1757 - accuracy: 0.3482 - val_loss: 1.1445 - val_accuracy: 0.4211\n",
      "Epoch 11/50\n",
      "112/112 [==============================] - 0s 332us/sample - loss: 1.1701 - accuracy: 0.3482 - val_loss: 1.1387 - val_accuracy: 0.4211\n",
      "Epoch 12/50\n",
      "112/112 [==============================] - 0s 339us/sample - loss: 1.1650 - accuracy: 0.3571 - val_loss: 1.1330 - val_accuracy: 0.4211\n",
      "Epoch 13/50\n",
      "112/112 [==============================] - 0s 366us/sample - loss: 1.1600 - accuracy: 0.3661 - val_loss: 1.1276 - val_accuracy: 0.4211\n",
      "Epoch 14/50\n",
      "112/112 [==============================] - 0s 400us/sample - loss: 1.1553 - accuracy: 0.3661 - val_loss: 1.1225 - val_accuracy: 0.4211\n",
      "Epoch 15/50\n",
      "112/112 [==============================] - 0s 331us/sample - loss: 1.1504 - accuracy: 0.3750 - val_loss: 1.1176 - val_accuracy: 0.4211\n",
      "Epoch 16/50\n",
      "112/112 [==============================] - 0s 359us/sample - loss: 1.1462 - accuracy: 0.3839 - val_loss: 1.1128 - val_accuracy: 0.4211\n",
      "Epoch 17/50\n",
      "112/112 [==============================] - 0s 328us/sample - loss: 1.1418 - accuracy: 0.3839 - val_loss: 1.1082 - val_accuracy: 0.4211\n",
      "Epoch 18/50\n",
      "112/112 [==============================] - 0s 344us/sample - loss: 1.1377 - accuracy: 0.3929 - val_loss: 1.1037 - val_accuracy: 0.4211\n",
      "Epoch 19/50\n",
      "112/112 [==============================] - 0s 344us/sample - loss: 1.1334 - accuracy: 0.3929 - val_loss: 1.0994 - val_accuracy: 0.4211\n",
      "Epoch 20/50\n",
      "112/112 [==============================] - 0s 329us/sample - loss: 1.1297 - accuracy: 0.3929 - val_loss: 1.0950 - val_accuracy: 0.4211\n",
      "Epoch 21/50\n",
      "112/112 [==============================] - 0s 329us/sample - loss: 1.1258 - accuracy: 0.3929 - val_loss: 1.0909 - val_accuracy: 0.4211\n",
      "Epoch 22/50\n",
      "112/112 [==============================] - 0s 352us/sample - loss: 1.1221 - accuracy: 0.3929 - val_loss: 1.0869 - val_accuracy: 0.4474\n",
      "Epoch 23/50\n",
      "112/112 [==============================] - 0s 350us/sample - loss: 1.1184 - accuracy: 0.3929 - val_loss: 1.0830 - val_accuracy: 0.4474\n",
      "Epoch 24/50\n",
      "112/112 [==============================] - 0s 331us/sample - loss: 1.1149 - accuracy: 0.3929 - val_loss: 1.0791 - val_accuracy: 0.4474\n",
      "Epoch 25/50\n",
      "112/112 [==============================] - 0s 340us/sample - loss: 1.1114 - accuracy: 0.3929 - val_loss: 1.0753 - val_accuracy: 0.4474\n",
      "Epoch 26/50\n",
      "112/112 [==============================] - 0s 347us/sample - loss: 1.1081 - accuracy: 0.3929 - val_loss: 1.0715 - val_accuracy: 0.4474\n",
      "Epoch 27/50\n",
      "112/112 [==============================] - 0s 342us/sample - loss: 1.1045 - accuracy: 0.3929 - val_loss: 1.0679 - val_accuracy: 0.4474\n",
      "Epoch 28/50\n",
      "112/112 [==============================] - 0s 333us/sample - loss: 1.1014 - accuracy: 0.3929 - val_loss: 1.0643 - val_accuracy: 0.4474\n",
      "Epoch 29/50\n",
      "112/112 [==============================] - 0s 345us/sample - loss: 1.0980 - accuracy: 0.4018 - val_loss: 1.0608 - val_accuracy: 0.4474\n",
      "Epoch 30/50\n",
      "112/112 [==============================] - 0s 352us/sample - loss: 1.0950 - accuracy: 0.4018 - val_loss: 1.0572 - val_accuracy: 0.4474\n",
      "Epoch 31/50\n",
      "112/112 [==============================] - 0s 334us/sample - loss: 1.0917 - accuracy: 0.4018 - val_loss: 1.0539 - val_accuracy: 0.4474\n",
      "Epoch 32/50\n",
      "112/112 [==============================] - 0s 352us/sample - loss: 1.0886 - accuracy: 0.4018 - val_loss: 1.0506 - val_accuracy: 0.4474\n",
      "Epoch 33/50\n",
      "112/112 [==============================] - 0s 336us/sample - loss: 1.0856 - accuracy: 0.4018 - val_loss: 1.0473 - val_accuracy: 0.4474\n",
      "Epoch 34/50\n",
      "112/112 [==============================] - 0s 345us/sample - loss: 1.0827 - accuracy: 0.4018 - val_loss: 1.0440 - val_accuracy: 0.4474\n",
      "Epoch 35/50\n",
      "112/112 [==============================] - 0s 335us/sample - loss: 1.0796 - accuracy: 0.4018 - val_loss: 1.0408 - val_accuracy: 0.4474\n",
      "Epoch 36/50\n",
      "112/112 [==============================] - 0s 345us/sample - loss: 1.0767 - accuracy: 0.4018 - val_loss: 1.0377 - val_accuracy: 0.4474\n",
      "Epoch 37/50\n",
      "112/112 [==============================] - 0s 346us/sample - loss: 1.0739 - accuracy: 0.4018 - val_loss: 1.0345 - val_accuracy: 0.4474\n",
      "Epoch 38/50\n",
      "112/112 [==============================] - 0s 336us/sample - loss: 1.0710 - accuracy: 0.4018 - val_loss: 1.0314 - val_accuracy: 0.4474\n",
      "Epoch 39/50\n",
      "112/112 [==============================] - 0s 332us/sample - loss: 1.0683 - accuracy: 0.4018 - val_loss: 1.0284 - val_accuracy: 0.4474\n",
      "Epoch 40/50\n",
      "112/112 [==============================] - 0s 327us/sample - loss: 1.0654 - accuracy: 0.4018 - val_loss: 1.0253 - val_accuracy: 0.4474\n",
      "Epoch 41/50\n",
      "112/112 [==============================] - 0s 334us/sample - loss: 1.0627 - accuracy: 0.4107 - val_loss: 1.0223 - val_accuracy: 0.4474\n",
      "Epoch 42/50\n",
      "112/112 [==============================] - 0s 336us/sample - loss: 1.0599 - accuracy: 0.4107 - val_loss: 1.0193 - val_accuracy: 0.4474\n",
      "Epoch 43/50\n",
      "112/112 [==============================] - 0s 339us/sample - loss: 1.0573 - accuracy: 0.4107 - val_loss: 1.0164 - val_accuracy: 0.4474\n",
      "Epoch 44/50\n",
      "112/112 [==============================] - 0s 322us/sample - loss: 1.0546 - accuracy: 0.4107 - val_loss: 1.0134 - val_accuracy: 0.4737\n",
      "Epoch 45/50\n",
      "112/112 [==============================] - 0s 338us/sample - loss: 1.0520 - accuracy: 0.4107 - val_loss: 1.0105 - val_accuracy: 0.4737\n",
      "Epoch 46/50\n",
      "112/112 [==============================] - 0s 322us/sample - loss: 1.0493 - accuracy: 0.4107 - val_loss: 1.0077 - val_accuracy: 0.4737\n",
      "Epoch 47/50\n",
      "112/112 [==============================] - 0s 360us/sample - loss: 1.0468 - accuracy: 0.4107 - val_loss: 1.0048 - val_accuracy: 0.4737\n",
      "Epoch 48/50\n",
      "112/112 [==============================] - 0s 357us/sample - loss: 1.0442 - accuracy: 0.4107 - val_loss: 1.0020 - val_accuracy: 0.4737\n",
      "Epoch 49/50\n",
      "112/112 [==============================] - 0s 372us/sample - loss: 1.0417 - accuracy: 0.4107 - val_loss: 0.9992 - val_accuracy: 0.4737\n",
      "Epoch 50/50\n",
      "112/112 [==============================] - 0s 373us/sample - loss: 1.0392 - accuracy: 0.4107 - val_loss: 0.9966 - val_accuracy: 0.5000\n",
      "\n",
      "Forming the grid-search model #22 using: optimizer=<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7fe1d6395cd0>, kernel=<tensorflow.python.ops.init_ops_v2.Orthogonal object at 0x7fe1b03bd4d0>, epochs=50, batch_size=64\n",
      "Train on 112 samples, validate on 38 samples\n",
      "Epoch 1/50\n",
      "112/112 [==============================] - 1s 9ms/sample - loss: 1.2373 - accuracy: 0.2679 - val_loss: 1.2148 - val_accuracy: 0.3158\n",
      "Epoch 2/50\n",
      "112/112 [==============================] - 0s 277us/sample - loss: 1.2342 - accuracy: 0.2768 - val_loss: 1.2104 - val_accuracy: 0.3421\n",
      "Epoch 3/50\n",
      "112/112 [==============================] - 0s 271us/sample - loss: 1.2301 - accuracy: 0.2768 - val_loss: 1.2056 - val_accuracy: 0.3421\n",
      "Epoch 4/50\n",
      "112/112 [==============================] - 0s 262us/sample - loss: 1.2260 - accuracy: 0.2946 - val_loss: 1.2005 - val_accuracy: 0.3421\n",
      "Epoch 5/50\n",
      "112/112 [==============================] - 0s 260us/sample - loss: 1.2211 - accuracy: 0.2946 - val_loss: 1.1953 - val_accuracy: 0.3421\n",
      "Epoch 6/50\n",
      "112/112 [==============================] - 0s 272us/sample - loss: 1.2166 - accuracy: 0.3036 - val_loss: 1.1901 - val_accuracy: 0.3421\n",
      "Epoch 7/50\n",
      "112/112 [==============================] - 0s 273us/sample - loss: 1.2117 - accuracy: 0.3036 - val_loss: 1.1849 - val_accuracy: 0.3421\n",
      "Epoch 8/50\n",
      "112/112 [==============================] - 0s 280us/sample - loss: 1.2075 - accuracy: 0.3125 - val_loss: 1.1798 - val_accuracy: 0.3421\n",
      "Epoch 9/50\n",
      "112/112 [==============================] - 0s 274us/sample - loss: 1.2027 - accuracy: 0.3214 - val_loss: 1.1749 - val_accuracy: 0.3421\n",
      "Epoch 10/50\n",
      "112/112 [==============================] - 0s 260us/sample - loss: 1.1982 - accuracy: 0.3214 - val_loss: 1.1700 - val_accuracy: 0.3684\n",
      "Epoch 11/50\n",
      "112/112 [==============================] - 0s 269us/sample - loss: 1.1938 - accuracy: 0.3304 - val_loss: 1.1653 - val_accuracy: 0.3947\n",
      "Epoch 12/50\n",
      "112/112 [==============================] - 0s 265us/sample - loss: 1.1897 - accuracy: 0.3393 - val_loss: 1.1606 - val_accuracy: 0.3947\n",
      "Epoch 13/50\n",
      "112/112 [==============================] - 0s 258us/sample - loss: 1.1855 - accuracy: 0.3393 - val_loss: 1.1561 - val_accuracy: 0.3947\n",
      "Epoch 14/50\n",
      "112/112 [==============================] - 0s 271us/sample - loss: 1.1816 - accuracy: 0.3393 - val_loss: 1.1517 - val_accuracy: 0.4211\n",
      "Epoch 15/50\n",
      "112/112 [==============================] - 0s 259us/sample - loss: 1.1775 - accuracy: 0.3482 - val_loss: 1.1475 - val_accuracy: 0.4211\n",
      "Epoch 16/50\n",
      "112/112 [==============================] - 0s 272us/sample - loss: 1.1739 - accuracy: 0.3482 - val_loss: 1.1434 - val_accuracy: 0.4211\n",
      "Epoch 17/50\n",
      "112/112 [==============================] - 0s 281us/sample - loss: 1.1702 - accuracy: 0.3482 - val_loss: 1.1394 - val_accuracy: 0.4211\n",
      "Epoch 18/50\n",
      "112/112 [==============================] - 0s 273us/sample - loss: 1.1666 - accuracy: 0.3482 - val_loss: 1.1355 - val_accuracy: 0.4211\n",
      "Epoch 19/50\n",
      "112/112 [==============================] - 0s 271us/sample - loss: 1.1630 - accuracy: 0.3482 - val_loss: 1.1317 - val_accuracy: 0.4211\n",
      "Epoch 20/50\n",
      "112/112 [==============================] - 0s 291us/sample - loss: 1.1597 - accuracy: 0.3482 - val_loss: 1.1281 - val_accuracy: 0.4211\n",
      "Epoch 21/50\n",
      "112/112 [==============================] - 0s 273us/sample - loss: 1.1563 - accuracy: 0.3661 - val_loss: 1.1245 - val_accuracy: 0.4211\n",
      "Epoch 22/50\n",
      "112/112 [==============================] - 0s 288us/sample - loss: 1.1532 - accuracy: 0.3661 - val_loss: 1.1210 - val_accuracy: 0.4211\n",
      "Epoch 23/50\n",
      "112/112 [==============================] - 0s 263us/sample - loss: 1.1500 - accuracy: 0.3661 - val_loss: 1.1175 - val_accuracy: 0.4211\n",
      "Epoch 24/50\n",
      "112/112 [==============================] - 0s 282us/sample - loss: 1.1469 - accuracy: 0.3661 - val_loss: 1.1141 - val_accuracy: 0.4211\n",
      "Epoch 25/50\n",
      "112/112 [==============================] - 0s 280us/sample - loss: 1.1439 - accuracy: 0.3661 - val_loss: 1.1108 - val_accuracy: 0.4211\n",
      "Epoch 26/50\n",
      "112/112 [==============================] - 0s 285us/sample - loss: 1.1410 - accuracy: 0.3750 - val_loss: 1.1076 - val_accuracy: 0.4211\n",
      "Epoch 27/50\n",
      "112/112 [==============================] - 0s 269us/sample - loss: 1.1380 - accuracy: 0.3929 - val_loss: 1.1044 - val_accuracy: 0.4211\n",
      "Epoch 28/50\n",
      "112/112 [==============================] - 0s 289us/sample - loss: 1.1353 - accuracy: 0.3929 - val_loss: 1.1013 - val_accuracy: 0.4211\n",
      "Epoch 29/50\n",
      "112/112 [==============================] - 0s 279us/sample - loss: 1.1324 - accuracy: 0.3929 - val_loss: 1.0983 - val_accuracy: 0.4211\n",
      "Epoch 30/50\n",
      "112/112 [==============================] - 0s 272us/sample - loss: 1.1298 - accuracy: 0.3929 - val_loss: 1.0954 - val_accuracy: 0.4211\n",
      "Epoch 31/50\n",
      "112/112 [==============================] - 0s 272us/sample - loss: 1.1271 - accuracy: 0.3929 - val_loss: 1.0924 - val_accuracy: 0.4211\n",
      "Epoch 32/50\n",
      "112/112 [==============================] - ETA: 0s - loss: 1.1527 - accuracy: 0.32 - 0s 274us/sample - loss: 1.1245 - accuracy: 0.3929 - val_loss: 1.0896 - val_accuracy: 0.4211\n",
      "Epoch 33/50\n",
      "112/112 [==============================] - 0s 350us/sample - loss: 1.1219 - accuracy: 0.3929 - val_loss: 1.0868 - val_accuracy: 0.4211\n",
      "Epoch 34/50\n",
      "112/112 [==============================] - 0s 266us/sample - loss: 1.1194 - accuracy: 0.3929 - val_loss: 1.0840 - val_accuracy: 0.4211\n",
      "Epoch 35/50\n",
      "112/112 [==============================] - 0s 286us/sample - loss: 1.1169 - accuracy: 0.3929 - val_loss: 1.0813 - val_accuracy: 0.4211\n",
      "Epoch 36/50\n",
      "112/112 [==============================] - 0s 285us/sample - loss: 1.1144 - accuracy: 0.3929 - val_loss: 1.0787 - val_accuracy: 0.4211\n",
      "Epoch 37/50\n",
      "112/112 [==============================] - 0s 278us/sample - loss: 1.1122 - accuracy: 0.3929 - val_loss: 1.0760 - val_accuracy: 0.4474\n",
      "Epoch 38/50\n",
      "112/112 [==============================] - 0s 280us/sample - loss: 1.1097 - accuracy: 0.3929 - val_loss: 1.0734 - val_accuracy: 0.4474\n",
      "Epoch 39/50\n",
      "112/112 [==============================] - 0s 277us/sample - loss: 1.1074 - accuracy: 0.3929 - val_loss: 1.0709 - val_accuracy: 0.4474\n",
      "Epoch 40/50\n",
      "112/112 [==============================] - 0s 267us/sample - loss: 1.1051 - accuracy: 0.3929 - val_loss: 1.0683 - val_accuracy: 0.4474\n",
      "Epoch 41/50\n",
      "112/112 [==============================] - 0s 281us/sample - loss: 1.1028 - accuracy: 0.3929 - val_loss: 1.0658 - val_accuracy: 0.4474\n",
      "Epoch 42/50\n",
      "112/112 [==============================] - 0s 256us/sample - loss: 1.1006 - accuracy: 0.3929 - val_loss: 1.0634 - val_accuracy: 0.4474\n",
      "Epoch 43/50\n",
      "112/112 [==============================] - 0s 244us/sample - loss: 1.0984 - accuracy: 0.4018 - val_loss: 1.0609 - val_accuracy: 0.4474\n",
      "Epoch 44/50\n",
      "112/112 [==============================] - 0s 279us/sample - loss: 1.0962 - accuracy: 0.4018 - val_loss: 1.0585 - val_accuracy: 0.4474\n",
      "Epoch 45/50\n",
      "112/112 [==============================] - 0s 283us/sample - loss: 1.0940 - accuracy: 0.4018 - val_loss: 1.0561 - val_accuracy: 0.4474\n",
      "Epoch 46/50\n",
      "112/112 [==============================] - 0s 234us/sample - loss: 1.0919 - accuracy: 0.4018 - val_loss: 1.0537 - val_accuracy: 0.4474\n",
      "Epoch 47/50\n",
      "112/112 [==============================] - 0s 251us/sample - loss: 1.0898 - accuracy: 0.4018 - val_loss: 1.0514 - val_accuracy: 0.4474\n",
      "Epoch 48/50\n",
      "112/112 [==============================] - 0s 280us/sample - loss: 1.0877 - accuracy: 0.4018 - val_loss: 1.0491 - val_accuracy: 0.4474\n",
      "Epoch 49/50\n",
      "112/112 [==============================] - 0s 259us/sample - loss: 1.0857 - accuracy: 0.4018 - val_loss: 1.0468 - val_accuracy: 0.4474\n",
      "Epoch 50/50\n",
      "112/112 [==============================] - 0s 254us/sample - loss: 1.0836 - accuracy: 0.4018 - val_loss: 1.0445 - val_accuracy: 0.4474\n",
      "\n",
      "Forming the grid-search model #23 using: optimizer=<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7fe1d6395cd0>, kernel=<tensorflow.python.ops.init_ops_v2.Orthogonal object at 0x7fe1b03bd4d0>, epochs=50, batch_size=128\n",
      "Train on 112 samples, validate on 38 samples\n",
      "Epoch 1/50\n",
      "112/112 [==============================] - 1s 9ms/sample - loss: 1.2377 - accuracy: 0.2679 - val_loss: 1.2164 - val_accuracy: 0.3158\n",
      "Epoch 2/50\n",
      "112/112 [==============================] - 0s 269us/sample - loss: 1.2364 - accuracy: 0.2679 - val_loss: 1.2145 - val_accuracy: 0.3158\n",
      "Epoch 3/50\n",
      "112/112 [==============================] - 0s 216us/sample - loss: 1.2347 - accuracy: 0.2768 - val_loss: 1.2123 - val_accuracy: 0.3158\n",
      "Epoch 4/50\n",
      "112/112 [==============================] - 0s 209us/sample - loss: 1.2328 - accuracy: 0.2768 - val_loss: 1.2098 - val_accuracy: 0.3421\n",
      "Epoch 5/50\n",
      "112/112 [==============================] - 0s 244us/sample - loss: 1.2306 - accuracy: 0.2768 - val_loss: 1.2072 - val_accuracy: 0.3421\n",
      "Epoch 6/50\n",
      "112/112 [==============================] - 0s 222us/sample - loss: 1.2283 - accuracy: 0.2768 - val_loss: 1.2045 - val_accuracy: 0.3421\n",
      "Epoch 7/50\n",
      "112/112 [==============================] - 0s 224us/sample - loss: 1.2258 - accuracy: 0.2946 - val_loss: 1.2017 - val_accuracy: 0.3421\n",
      "Epoch 8/50\n",
      "112/112 [==============================] - 0s 240us/sample - loss: 1.2233 - accuracy: 0.2946 - val_loss: 1.1989 - val_accuracy: 0.3421\n",
      "Epoch 9/50\n",
      "112/112 [==============================] - 0s 245us/sample - loss: 1.2208 - accuracy: 0.2946 - val_loss: 1.1960 - val_accuracy: 0.3421\n",
      "Epoch 10/50\n",
      "112/112 [==============================] - 0s 236us/sample - loss: 1.2182 - accuracy: 0.3036 - val_loss: 1.1931 - val_accuracy: 0.3421\n",
      "Epoch 11/50\n",
      "112/112 [==============================] - 0s 212us/sample - loss: 1.2157 - accuracy: 0.3036 - val_loss: 1.1902 - val_accuracy: 0.3421\n",
      "Epoch 12/50\n",
      "112/112 [==============================] - 0s 233us/sample - loss: 1.2131 - accuracy: 0.3036 - val_loss: 1.1873 - val_accuracy: 0.3421\n",
      "Epoch 13/50\n",
      "112/112 [==============================] - 0s 223us/sample - loss: 1.2105 - accuracy: 0.3125 - val_loss: 1.1845 - val_accuracy: 0.3421\n",
      "Epoch 14/50\n",
      "112/112 [==============================] - 0s 225us/sample - loss: 1.2079 - accuracy: 0.3125 - val_loss: 1.1816 - val_accuracy: 0.3421\n",
      "Epoch 15/50\n",
      "112/112 [==============================] - 0s 231us/sample - loss: 1.2053 - accuracy: 0.3214 - val_loss: 1.1787 - val_accuracy: 0.3421\n",
      "Epoch 16/50\n",
      "112/112 [==============================] - 0s 228us/sample - loss: 1.2028 - accuracy: 0.3214 - val_loss: 1.1759 - val_accuracy: 0.3421\n",
      "Epoch 17/50\n",
      "112/112 [==============================] - 0s 220us/sample - loss: 1.2002 - accuracy: 0.3214 - val_loss: 1.1731 - val_accuracy: 0.3421\n",
      "Epoch 18/50\n",
      "112/112 [==============================] - 0s 223us/sample - loss: 1.1977 - accuracy: 0.3214 - val_loss: 1.1703 - val_accuracy: 0.3684\n",
      "Epoch 19/50\n",
      "112/112 [==============================] - 0s 243us/sample - loss: 1.1953 - accuracy: 0.3214 - val_loss: 1.1676 - val_accuracy: 0.3684\n",
      "Epoch 20/50\n",
      "112/112 [==============================] - 0s 228us/sample - loss: 1.1928 - accuracy: 0.3304 - val_loss: 1.1649 - val_accuracy: 0.3684\n",
      "Epoch 21/50\n",
      "112/112 [==============================] - 0s 227us/sample - loss: 1.1904 - accuracy: 0.3304 - val_loss: 1.1622 - val_accuracy: 0.3947\n",
      "Epoch 22/50\n",
      "112/112 [==============================] - 0s 232us/sample - loss: 1.1880 - accuracy: 0.3304 - val_loss: 1.1596 - val_accuracy: 0.3947\n",
      "Epoch 23/50\n",
      "112/112 [==============================] - 0s 227us/sample - loss: 1.1857 - accuracy: 0.3304 - val_loss: 1.1570 - val_accuracy: 0.3947\n",
      "Epoch 24/50\n",
      "112/112 [==============================] - 0s 222us/sample - loss: 1.1834 - accuracy: 0.3393 - val_loss: 1.1544 - val_accuracy: 0.3947\n",
      "Epoch 25/50\n",
      "112/112 [==============================] - 0s 218us/sample - loss: 1.1811 - accuracy: 0.3393 - val_loss: 1.1519 - val_accuracy: 0.3947\n",
      "Epoch 26/50\n",
      "112/112 [==============================] - 0s 225us/sample - loss: 1.1788 - accuracy: 0.3393 - val_loss: 1.1495 - val_accuracy: 0.3947\n",
      "Epoch 27/50\n",
      "112/112 [==============================] - 0s 229us/sample - loss: 1.1766 - accuracy: 0.3393 - val_loss: 1.1470 - val_accuracy: 0.3947\n",
      "Epoch 28/50\n",
      "112/112 [==============================] - 0s 217us/sample - loss: 1.1745 - accuracy: 0.3393 - val_loss: 1.1447 - val_accuracy: 0.4211\n",
      "Epoch 29/50\n",
      "112/112 [==============================] - 0s 233us/sample - loss: 1.1723 - accuracy: 0.3393 - val_loss: 1.1423 - val_accuracy: 0.4211\n",
      "Epoch 30/50\n",
      "112/112 [==============================] - 0s 237us/sample - loss: 1.1702 - accuracy: 0.3393 - val_loss: 1.1400 - val_accuracy: 0.4211\n",
      "Epoch 31/50\n",
      "112/112 [==============================] - 0s 235us/sample - loss: 1.1681 - accuracy: 0.3393 - val_loss: 1.1377 - val_accuracy: 0.4211\n",
      "Epoch 32/50\n",
      "112/112 [==============================] - 0s 238us/sample - loss: 1.1661 - accuracy: 0.3393 - val_loss: 1.1355 - val_accuracy: 0.4211\n",
      "Epoch 33/50\n",
      "112/112 [==============================] - 0s 227us/sample - loss: 1.1641 - accuracy: 0.3393 - val_loss: 1.1332 - val_accuracy: 0.4211\n",
      "Epoch 34/50\n",
      "112/112 [==============================] - 0s 231us/sample - loss: 1.1621 - accuracy: 0.3482 - val_loss: 1.1310 - val_accuracy: 0.4211\n",
      "Epoch 35/50\n",
      "112/112 [==============================] - 0s 225us/sample - loss: 1.1601 - accuracy: 0.3482 - val_loss: 1.1289 - val_accuracy: 0.4211\n",
      "Epoch 36/50\n",
      "112/112 [==============================] - 0s 236us/sample - loss: 1.1582 - accuracy: 0.3571 - val_loss: 1.1268 - val_accuracy: 0.4211\n",
      "Epoch 37/50\n",
      "112/112 [==============================] - 0s 226us/sample - loss: 1.1563 - accuracy: 0.3571 - val_loss: 1.1247 - val_accuracy: 0.4211\n",
      "Epoch 38/50\n",
      "112/112 [==============================] - 0s 230us/sample - loss: 1.1544 - accuracy: 0.3571 - val_loss: 1.1226 - val_accuracy: 0.4211\n",
      "Epoch 39/50\n",
      "112/112 [==============================] - 0s 232us/sample - loss: 1.1525 - accuracy: 0.3571 - val_loss: 1.1205 - val_accuracy: 0.4211\n",
      "Epoch 40/50\n",
      "112/112 [==============================] - 0s 236us/sample - loss: 1.1507 - accuracy: 0.3750 - val_loss: 1.1185 - val_accuracy: 0.4211\n",
      "Epoch 41/50\n",
      "112/112 [==============================] - 0s 220us/sample - loss: 1.1489 - accuracy: 0.3750 - val_loss: 1.1165 - val_accuracy: 0.4211\n",
      "Epoch 42/50\n",
      "112/112 [==============================] - 0s 234us/sample - loss: 1.1471 - accuracy: 0.3750 - val_loss: 1.1145 - val_accuracy: 0.4211\n",
      "Epoch 43/50\n",
      "112/112 [==============================] - 0s 221us/sample - loss: 1.1453 - accuracy: 0.3750 - val_loss: 1.1126 - val_accuracy: 0.4211\n",
      "Epoch 44/50\n",
      "112/112 [==============================] - 0s 239us/sample - loss: 1.1435 - accuracy: 0.3750 - val_loss: 1.1107 - val_accuracy: 0.4211\n",
      "Epoch 45/50\n",
      "112/112 [==============================] - 0s 227us/sample - loss: 1.1418 - accuracy: 0.3750 - val_loss: 1.1088 - val_accuracy: 0.4211\n",
      "Epoch 46/50\n",
      "112/112 [==============================] - 0s 239us/sample - loss: 1.1401 - accuracy: 0.3839 - val_loss: 1.1069 - val_accuracy: 0.4211\n",
      "Epoch 47/50\n",
      "112/112 [==============================] - 0s 226us/sample - loss: 1.1384 - accuracy: 0.3839 - val_loss: 1.1050 - val_accuracy: 0.4211\n",
      "Epoch 48/50\n",
      "112/112 [==============================] - 0s 244us/sample - loss: 1.1368 - accuracy: 0.3839 - val_loss: 1.1032 - val_accuracy: 0.4211\n",
      "Epoch 49/50\n",
      "112/112 [==============================] - 0s 235us/sample - loss: 1.1351 - accuracy: 0.3929 - val_loss: 1.1013 - val_accuracy: 0.4211\n",
      "Epoch 50/50\n",
      "112/112 [==============================] - 0s 232us/sample - loss: 1.1335 - accuracy: 0.3929 - val_loss: 1.0995 - val_accuracy: 0.4211\n",
      "\n",
      "Forming the grid-search model #24 using: optimizer=<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7fe1d6395cd0>, kernel=<tensorflow.python.ops.init_ops_v2.GlorotNormal object at 0x7fe1b03bd290>, epochs=50, batch_size=32\n",
      "Train on 112 samples, validate on 38 samples\n",
      "Epoch 1/50\n",
      "112/112 [==============================] - 1s 9ms/sample - loss: 1.3596 - accuracy: 0.4196 - val_loss: 1.2810 - val_accuracy: 0.4737\n",
      "Epoch 2/50\n",
      "112/112 [==============================] - 0s 370us/sample - loss: 1.3464 - accuracy: 0.4196 - val_loss: 1.2650 - val_accuracy: 0.4737\n",
      "Epoch 3/50\n",
      "112/112 [==============================] - 0s 340us/sample - loss: 1.3297 - accuracy: 0.4196 - val_loss: 1.2481 - val_accuracy: 0.5000\n",
      "Epoch 4/50\n",
      "112/112 [==============================] - 0s 335us/sample - loss: 1.3147 - accuracy: 0.4286 - val_loss: 1.2311 - val_accuracy: 0.5000\n",
      "Epoch 5/50\n",
      "112/112 [==============================] - 0s 323us/sample - loss: 1.2978 - accuracy: 0.4375 - val_loss: 1.2148 - val_accuracy: 0.5000\n",
      "Epoch 6/50\n",
      "112/112 [==============================] - 0s 317us/sample - loss: 1.2812 - accuracy: 0.4375 - val_loss: 1.1995 - val_accuracy: 0.5000\n",
      "Epoch 7/50\n",
      "112/112 [==============================] - 0s 354us/sample - loss: 1.2667 - accuracy: 0.4375 - val_loss: 1.1848 - val_accuracy: 0.5000\n",
      "Epoch 8/50\n",
      "112/112 [==============================] - 0s 342us/sample - loss: 1.2527 - accuracy: 0.4375 - val_loss: 1.1709 - val_accuracy: 0.5000\n",
      "Epoch 9/50\n",
      "112/112 [==============================] - 0s 325us/sample - loss: 1.2393 - accuracy: 0.4375 - val_loss: 1.1578 - val_accuracy: 0.5000\n",
      "Epoch 10/50\n",
      "112/112 [==============================] - 0s 331us/sample - loss: 1.2268 - accuracy: 0.4375 - val_loss: 1.1453 - val_accuracy: 0.5000\n",
      "Epoch 11/50\n",
      "112/112 [==============================] - 0s 354us/sample - loss: 1.2146 - accuracy: 0.4375 - val_loss: 1.1336 - val_accuracy: 0.5000\n",
      "Epoch 12/50\n",
      "112/112 [==============================] - 0s 347us/sample - loss: 1.2029 - accuracy: 0.4375 - val_loss: 1.1224 - val_accuracy: 0.5000\n",
      "Epoch 13/50\n",
      "112/112 [==============================] - 0s 337us/sample - loss: 1.1918 - accuracy: 0.4375 - val_loss: 1.1118 - val_accuracy: 0.5263\n",
      "Epoch 14/50\n",
      "112/112 [==============================] - 0s 340us/sample - loss: 1.1816 - accuracy: 0.4375 - val_loss: 1.1014 - val_accuracy: 0.5263\n",
      "Epoch 15/50\n",
      "112/112 [==============================] - 0s 337us/sample - loss: 1.1715 - accuracy: 0.4464 - val_loss: 1.0915 - val_accuracy: 0.5263\n",
      "Epoch 16/50\n",
      "112/112 [==============================] - 0s 341us/sample - loss: 1.1618 - accuracy: 0.4554 - val_loss: 1.0818 - val_accuracy: 0.5263\n",
      "Epoch 17/50\n",
      "112/112 [==============================] - 0s 328us/sample - loss: 1.1522 - accuracy: 0.4554 - val_loss: 1.0726 - val_accuracy: 0.5263\n",
      "Epoch 18/50\n",
      "112/112 [==============================] - 0s 350us/sample - loss: 1.1434 - accuracy: 0.4554 - val_loss: 1.0638 - val_accuracy: 0.5263\n",
      "Epoch 19/50\n",
      "112/112 [==============================] - 0s 375us/sample - loss: 1.1342 - accuracy: 0.4554 - val_loss: 1.0554 - val_accuracy: 0.5263\n",
      "Epoch 20/50\n",
      "112/112 [==============================] - 0s 350us/sample - loss: 1.1262 - accuracy: 0.4554 - val_loss: 1.0471 - val_accuracy: 0.5263\n",
      "Epoch 21/50\n",
      "112/112 [==============================] - 0s 351us/sample - loss: 1.1182 - accuracy: 0.4554 - val_loss: 1.0390 - val_accuracy: 0.5263\n",
      "Epoch 22/50\n",
      "112/112 [==============================] - 0s 386us/sample - loss: 1.1095 - accuracy: 0.4554 - val_loss: 1.0312 - val_accuracy: 0.5263\n",
      "Epoch 23/50\n",
      "112/112 [==============================] - 0s 350us/sample - loss: 1.1020 - accuracy: 0.4643 - val_loss: 1.0234 - val_accuracy: 0.5263\n",
      "Epoch 24/50\n",
      "112/112 [==============================] - 0s 342us/sample - loss: 1.0942 - accuracy: 0.4643 - val_loss: 1.0158 - val_accuracy: 0.5263\n",
      "Epoch 25/50\n",
      "112/112 [==============================] - 0s 396us/sample - loss: 1.0864 - accuracy: 0.4643 - val_loss: 1.0086 - val_accuracy: 0.5263\n",
      "Epoch 26/50\n",
      "112/112 [==============================] - 0s 383us/sample - loss: 1.0798 - accuracy: 0.4643 - val_loss: 1.0012 - val_accuracy: 0.5263\n",
      "Epoch 27/50\n",
      "112/112 [==============================] - 0s 336us/sample - loss: 1.0719 - accuracy: 0.4643 - val_loss: 0.9943 - val_accuracy: 0.5263\n",
      "Epoch 28/50\n",
      "112/112 [==============================] - 0s 332us/sample - loss: 1.0651 - accuracy: 0.4643 - val_loss: 0.9873 - val_accuracy: 0.5263\n",
      "Epoch 29/50\n",
      "112/112 [==============================] - 0s 413us/sample - loss: 1.0584 - accuracy: 0.4643 - val_loss: 0.9805 - val_accuracy: 0.5263\n",
      "Epoch 30/50\n",
      "112/112 [==============================] - 0s 339us/sample - loss: 1.0511 - accuracy: 0.4643 - val_loss: 0.9740 - val_accuracy: 0.5263\n",
      "Epoch 31/50\n",
      "112/112 [==============================] - 0s 331us/sample - loss: 1.0446 - accuracy: 0.4643 - val_loss: 0.9676 - val_accuracy: 0.5263\n",
      "Epoch 32/50\n",
      "112/112 [==============================] - 0s 341us/sample - loss: 1.0380 - accuracy: 0.4643 - val_loss: 0.9614 - val_accuracy: 0.5263\n",
      "Epoch 33/50\n",
      "112/112 [==============================] - 0s 347us/sample - loss: 1.0317 - accuracy: 0.4643 - val_loss: 0.9552 - val_accuracy: 0.5263\n",
      "Epoch 34/50\n",
      "112/112 [==============================] - 0s 344us/sample - loss: 1.0256 - accuracy: 0.4732 - val_loss: 0.9490 - val_accuracy: 0.5263\n",
      "Epoch 35/50\n",
      "112/112 [==============================] - 0s 345us/sample - loss: 1.0194 - accuracy: 0.4732 - val_loss: 0.9431 - val_accuracy: 0.5263\n",
      "Epoch 36/50\n",
      "112/112 [==============================] - 0s 356us/sample - loss: 1.0135 - accuracy: 0.4732 - val_loss: 0.9371 - val_accuracy: 0.5263\n",
      "Epoch 37/50\n",
      "112/112 [==============================] - 0s 540us/sample - loss: 1.0071 - accuracy: 0.4732 - val_loss: 0.9314 - val_accuracy: 0.5263\n",
      "Epoch 38/50\n",
      "112/112 [==============================] - 0s 330us/sample - loss: 1.0017 - accuracy: 0.4732 - val_loss: 0.9257 - val_accuracy: 0.5263\n",
      "Epoch 39/50\n",
      "112/112 [==============================] - 0s 335us/sample - loss: 0.9955 - accuracy: 0.4732 - val_loss: 0.9202 - val_accuracy: 0.5263\n",
      "Epoch 40/50\n",
      "112/112 [==============================] - 0s 368us/sample - loss: 0.9904 - accuracy: 0.4732 - val_loss: 0.9146 - val_accuracy: 0.5263\n",
      "Epoch 41/50\n",
      "112/112 [==============================] - 0s 330us/sample - loss: 0.9845 - accuracy: 0.4732 - val_loss: 0.9093 - val_accuracy: 0.5263\n",
      "Epoch 42/50\n",
      "112/112 [==============================] - 0s 333us/sample - loss: 0.9793 - accuracy: 0.4732 - val_loss: 0.9041 - val_accuracy: 0.5263\n",
      "Epoch 43/50\n",
      "112/112 [==============================] - 0s 331us/sample - loss: 0.9741 - accuracy: 0.4732 - val_loss: 0.8990 - val_accuracy: 0.5263\n",
      "Epoch 44/50\n",
      "112/112 [==============================] - 0s 338us/sample - loss: 0.9689 - accuracy: 0.4732 - val_loss: 0.8938 - val_accuracy: 0.5263\n",
      "Epoch 45/50\n",
      "112/112 [==============================] - 0s 336us/sample - loss: 0.9634 - accuracy: 0.4732 - val_loss: 0.8889 - val_accuracy: 0.5263\n",
      "Epoch 46/50\n",
      "112/112 [==============================] - 0s 345us/sample - loss: 0.9584 - accuracy: 0.4732 - val_loss: 0.8840 - val_accuracy: 0.5263\n",
      "Epoch 47/50\n",
      "112/112 [==============================] - 0s 351us/sample - loss: 0.9536 - accuracy: 0.4732 - val_loss: 0.8790 - val_accuracy: 0.5263\n",
      "Epoch 48/50\n",
      "112/112 [==============================] - 0s 328us/sample - loss: 0.9485 - accuracy: 0.4732 - val_loss: 0.8742 - val_accuracy: 0.5263\n",
      "Epoch 49/50\n",
      "112/112 [==============================] - 0s 374us/sample - loss: 0.9435 - accuracy: 0.4732 - val_loss: 0.8694 - val_accuracy: 0.5263\n",
      "Epoch 50/50\n",
      "112/112 [==============================] - 0s 361us/sample - loss: 0.9389 - accuracy: 0.4821 - val_loss: 0.8647 - val_accuracy: 0.5263\n",
      "\n",
      "Forming the grid-search model #25 using: optimizer=<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7fe1d6395cd0>, kernel=<tensorflow.python.ops.init_ops_v2.GlorotNormal object at 0x7fe1b03bd290>, epochs=50, batch_size=64\n",
      "Train on 112 samples, validate on 38 samples\n",
      "Epoch 1/50\n",
      "112/112 [==============================] - 1s 9ms/sample - loss: 1.3613 - accuracy: 0.4196 - val_loss: 1.2870 - val_accuracy: 0.4737\n",
      "Epoch 2/50\n",
      "112/112 [==============================] - 0s 260us/sample - loss: 1.3554 - accuracy: 0.4196 - val_loss: 1.2792 - val_accuracy: 0.4737\n",
      "Epoch 3/50\n",
      "112/112 [==============================] - 0s 262us/sample - loss: 1.3473 - accuracy: 0.4196 - val_loss: 1.2704 - val_accuracy: 0.4737\n",
      "Epoch 4/50\n",
      "112/112 [==============================] - 0s 248us/sample - loss: 1.3395 - accuracy: 0.4196 - val_loss: 1.2612 - val_accuracy: 0.5000\n",
      "Epoch 5/50\n",
      "112/112 [==============================] - 0s 276us/sample - loss: 1.3303 - accuracy: 0.4196 - val_loss: 1.2518 - val_accuracy: 0.5000\n",
      "Epoch 6/50\n",
      "112/112 [==============================] - 0s 275us/sample - loss: 1.3204 - accuracy: 0.4196 - val_loss: 1.2424 - val_accuracy: 0.5000\n",
      "Epoch 7/50\n",
      "112/112 [==============================] - 0s 250us/sample - loss: 1.3116 - accuracy: 0.4375 - val_loss: 1.2330 - val_accuracy: 0.5000\n",
      "Epoch 8/50\n",
      "112/112 [==============================] - 0s 267us/sample - loss: 1.3025 - accuracy: 0.4375 - val_loss: 1.2237 - val_accuracy: 0.5000\n",
      "Epoch 9/50\n",
      "112/112 [==============================] - 0s 257us/sample - loss: 1.2932 - accuracy: 0.4375 - val_loss: 1.2146 - val_accuracy: 0.5000\n",
      "Epoch 10/50\n",
      "112/112 [==============================] - 0s 254us/sample - loss: 1.2848 - accuracy: 0.4375 - val_loss: 1.2056 - val_accuracy: 0.5000\n",
      "Epoch 11/50\n",
      "112/112 [==============================] - 0s 270us/sample - loss: 1.2760 - accuracy: 0.4375 - val_loss: 1.1970 - val_accuracy: 0.5000\n",
      "Epoch 12/50\n",
      "112/112 [==============================] - 0s 255us/sample - loss: 1.2673 - accuracy: 0.4375 - val_loss: 1.1885 - val_accuracy: 0.5000\n",
      "Epoch 13/50\n",
      "112/112 [==============================] - 0s 270us/sample - loss: 1.2591 - accuracy: 0.4375 - val_loss: 1.1803 - val_accuracy: 0.5000\n",
      "Epoch 14/50\n",
      "112/112 [==============================] - 0s 271us/sample - loss: 1.2512 - accuracy: 0.4375 - val_loss: 1.1723 - val_accuracy: 0.5000\n",
      "Epoch 15/50\n",
      "112/112 [==============================] - 0s 276us/sample - loss: 1.2436 - accuracy: 0.4375 - val_loss: 1.1646 - val_accuracy: 0.5000\n",
      "Epoch 16/50\n",
      "112/112 [==============================] - 0s 358us/sample - loss: 1.2360 - accuracy: 0.4375 - val_loss: 1.1570 - val_accuracy: 0.5000\n",
      "Epoch 17/50\n",
      "112/112 [==============================] - 0s 283us/sample - loss: 1.2283 - accuracy: 0.4375 - val_loss: 1.1497 - val_accuracy: 0.5000\n",
      "Epoch 18/50\n",
      "112/112 [==============================] - 0s 280us/sample - loss: 1.2215 - accuracy: 0.4375 - val_loss: 1.1426 - val_accuracy: 0.5000\n",
      "Epoch 19/50\n",
      "112/112 [==============================] - 0s 266us/sample - loss: 1.2139 - accuracy: 0.4375 - val_loss: 1.1357 - val_accuracy: 0.5000\n",
      "Epoch 20/50\n",
      "112/112 [==============================] - 0s 272us/sample - loss: 1.2076 - accuracy: 0.4375 - val_loss: 1.1290 - val_accuracy: 0.5000\n",
      "Epoch 21/50\n",
      "112/112 [==============================] - 0s 265us/sample - loss: 1.2009 - accuracy: 0.4375 - val_loss: 1.1224 - val_accuracy: 0.5000\n",
      "Epoch 22/50\n",
      "112/112 [==============================] - 0s 248us/sample - loss: 1.1940 - accuracy: 0.4375 - val_loss: 1.1160 - val_accuracy: 0.5263\n",
      "Epoch 23/50\n",
      "112/112 [==============================] - 0s 277us/sample - loss: 1.1879 - accuracy: 0.4464 - val_loss: 1.1097 - val_accuracy: 0.5263\n",
      "Epoch 24/50\n",
      "112/112 [==============================] - 0s 279us/sample - loss: 1.1816 - accuracy: 0.4464 - val_loss: 1.1035 - val_accuracy: 0.5263\n",
      "Epoch 25/50\n",
      "112/112 [==============================] - 0s 275us/sample - loss: 1.1754 - accuracy: 0.4464 - val_loss: 1.0975 - val_accuracy: 0.5263\n",
      "Epoch 26/50\n",
      "112/112 [==============================] - 0s 272us/sample - loss: 1.1698 - accuracy: 0.4554 - val_loss: 1.0915 - val_accuracy: 0.5263\n",
      "Epoch 27/50\n",
      "112/112 [==============================] - 0s 256us/sample - loss: 1.1636 - accuracy: 0.4554 - val_loss: 1.0858 - val_accuracy: 0.5263\n",
      "Epoch 28/50\n",
      "112/112 [==============================] - 0s 271us/sample - loss: 1.1579 - accuracy: 0.4554 - val_loss: 1.0801 - val_accuracy: 0.5263\n",
      "Epoch 29/50\n",
      "112/112 [==============================] - 0s 282us/sample - loss: 1.1525 - accuracy: 0.4554 - val_loss: 1.0745 - val_accuracy: 0.5263\n",
      "Epoch 30/50\n",
      "112/112 [==============================] - 0s 273us/sample - loss: 1.1466 - accuracy: 0.4554 - val_loss: 1.0691 - val_accuracy: 0.5263\n",
      "Epoch 31/50\n",
      "112/112 [==============================] - 0s 257us/sample - loss: 1.1413 - accuracy: 0.4554 - val_loss: 1.0637 - val_accuracy: 0.5263\n",
      "Epoch 32/50\n",
      "112/112 [==============================] - 0s 281us/sample - loss: 1.1357 - accuracy: 0.4554 - val_loss: 1.0585 - val_accuracy: 0.5263\n",
      "Epoch 33/50\n",
      "112/112 [==============================] - 0s 283us/sample - loss: 1.1305 - accuracy: 0.4554 - val_loss: 1.0533 - val_accuracy: 0.5263\n",
      "Epoch 34/50\n",
      "112/112 [==============================] - 0s 265us/sample - loss: 1.1255 - accuracy: 0.4554 - val_loss: 1.0482 - val_accuracy: 0.5263\n",
      "Epoch 35/50\n",
      "112/112 [==============================] - 0s 276us/sample - loss: 1.1205 - accuracy: 0.4554 - val_loss: 1.0432 - val_accuracy: 0.5263\n",
      "Epoch 36/50\n",
      "112/112 [==============================] - 0s 282us/sample - loss: 1.1156 - accuracy: 0.4554 - val_loss: 1.0382 - val_accuracy: 0.5263\n",
      "Epoch 37/50\n",
      "112/112 [==============================] - 0s 283us/sample - loss: 1.1104 - accuracy: 0.4554 - val_loss: 1.0334 - val_accuracy: 0.5263\n",
      "Epoch 38/50\n",
      "112/112 [==============================] - 0s 267us/sample - loss: 1.1058 - accuracy: 0.4554 - val_loss: 1.0286 - val_accuracy: 0.5263\n",
      "Epoch 39/50\n",
      "112/112 [==============================] - 0s 280us/sample - loss: 1.1009 - accuracy: 0.4643 - val_loss: 1.0239 - val_accuracy: 0.5263\n",
      "Epoch 40/50\n",
      "112/112 [==============================] - 0s 271us/sample - loss: 1.0966 - accuracy: 0.4643 - val_loss: 1.0193 - val_accuracy: 0.5263\n",
      "Epoch 41/50\n",
      "112/112 [==============================] - 0s 279us/sample - loss: 1.0918 - accuracy: 0.4643 - val_loss: 1.0147 - val_accuracy: 0.5263\n",
      "Epoch 42/50\n",
      "112/112 [==============================] - 0s 278us/sample - loss: 1.0872 - accuracy: 0.4643 - val_loss: 1.0103 - val_accuracy: 0.5263\n",
      "Epoch 43/50\n",
      "112/112 [==============================] - 0s 292us/sample - loss: 1.0830 - accuracy: 0.4643 - val_loss: 1.0059 - val_accuracy: 0.5263\n",
      "Epoch 44/50\n",
      "112/112 [==============================] - 0s 300us/sample - loss: 1.0786 - accuracy: 0.4643 - val_loss: 1.0016 - val_accuracy: 0.5263\n",
      "Epoch 45/50\n",
      "112/112 [==============================] - 0s 287us/sample - loss: 1.0740 - accuracy: 0.4643 - val_loss: 0.9974 - val_accuracy: 0.5263\n",
      "Epoch 46/50\n",
      "112/112 [==============================] - 0s 291us/sample - loss: 1.0698 - accuracy: 0.4643 - val_loss: 0.9932 - val_accuracy: 0.5263\n",
      "Epoch 47/50\n",
      "112/112 [==============================] - 0s 281us/sample - loss: 1.0657 - accuracy: 0.4643 - val_loss: 0.9890 - val_accuracy: 0.5263\n",
      "Epoch 48/50\n",
      "112/112 [==============================] - 0s 263us/sample - loss: 1.0615 - accuracy: 0.4643 - val_loss: 0.9850 - val_accuracy: 0.5263\n",
      "Epoch 49/50\n",
      "112/112 [==============================] - 0s 291us/sample - loss: 1.0574 - accuracy: 0.4643 - val_loss: 0.9809 - val_accuracy: 0.5263\n",
      "Epoch 50/50\n",
      "112/112 [==============================] - 0s 269us/sample - loss: 1.0535 - accuracy: 0.4643 - val_loss: 0.9770 - val_accuracy: 0.5263\n",
      "\n",
      "Forming the grid-search model #26 using: optimizer=<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7fe1d6395cd0>, kernel=<tensorflow.python.ops.init_ops_v2.GlorotNormal object at 0x7fe1b03bd290>, epochs=50, batch_size=128\n",
      "Train on 112 samples, validate on 38 samples\n",
      "Epoch 1/50\n",
      "112/112 [==============================] - 1s 12ms/sample - loss: 1.3623 - accuracy: 0.4196 - val_loss: 1.2901 - val_accuracy: 0.4737\n",
      "Epoch 2/50\n",
      "112/112 [==============================] - 0s 227us/sample - loss: 1.3599 - accuracy: 0.4196 - val_loss: 1.2867 - val_accuracy: 0.4737\n",
      "Epoch 3/50\n",
      "112/112 [==============================] - 0s 214us/sample - loss: 1.3567 - accuracy: 0.4196 - val_loss: 1.2829 - val_accuracy: 0.4737\n",
      "Epoch 4/50\n",
      "112/112 [==============================] - 0s 215us/sample - loss: 1.3529 - accuracy: 0.4196 - val_loss: 1.2786 - val_accuracy: 0.4737\n",
      "Epoch 5/50\n",
      "112/112 [==============================] - 0s 236us/sample - loss: 1.3488 - accuracy: 0.4196 - val_loss: 1.2741 - val_accuracy: 0.4737\n",
      "Epoch 6/50\n",
      "112/112 [==============================] - 0s 229us/sample - loss: 1.3445 - accuracy: 0.4196 - val_loss: 1.2694 - val_accuracy: 0.4737\n",
      "Epoch 7/50\n",
      "112/112 [==============================] - 0s 226us/sample - loss: 1.3399 - accuracy: 0.4196 - val_loss: 1.2646 - val_accuracy: 0.5000\n",
      "Epoch 8/50\n",
      "112/112 [==============================] - 0s 219us/sample - loss: 1.3353 - accuracy: 0.4196 - val_loss: 1.2596 - val_accuracy: 0.5000\n",
      "Epoch 9/50\n",
      "112/112 [==============================] - 0s 245us/sample - loss: 1.3305 - accuracy: 0.4196 - val_loss: 1.2547 - val_accuracy: 0.5000\n",
      "Epoch 10/50\n",
      "112/112 [==============================] - 0s 234us/sample - loss: 1.3257 - accuracy: 0.4196 - val_loss: 1.2497 - val_accuracy: 0.5000\n",
      "Epoch 11/50\n",
      "112/112 [==============================] - 0s 234us/sample - loss: 1.3208 - accuracy: 0.4286 - val_loss: 1.2447 - val_accuracy: 0.5000\n",
      "Epoch 12/50\n",
      "112/112 [==============================] - 0s 241us/sample - loss: 1.3159 - accuracy: 0.4375 - val_loss: 1.2397 - val_accuracy: 0.5000\n",
      "Epoch 13/50\n",
      "112/112 [==============================] - 0s 228us/sample - loss: 1.3110 - accuracy: 0.4375 - val_loss: 1.2347 - val_accuracy: 0.5000\n",
      "Epoch 14/50\n",
      "112/112 [==============================] - 0s 260us/sample - loss: 1.3061 - accuracy: 0.4375 - val_loss: 1.2297 - val_accuracy: 0.5000\n",
      "Epoch 15/50\n",
      "112/112 [==============================] - 0s 216us/sample - loss: 1.3012 - accuracy: 0.4375 - val_loss: 1.2247 - val_accuracy: 0.5000\n",
      "Epoch 16/50\n",
      "112/112 [==============================] - 0s 217us/sample - loss: 1.2964 - accuracy: 0.4375 - val_loss: 1.2198 - val_accuracy: 0.5000\n",
      "Epoch 17/50\n",
      "112/112 [==============================] - 0s 237us/sample - loss: 1.2916 - accuracy: 0.4375 - val_loss: 1.2149 - val_accuracy: 0.5000\n",
      "Epoch 18/50\n",
      "112/112 [==============================] - 0s 230us/sample - loss: 1.2869 - accuracy: 0.4375 - val_loss: 1.2101 - val_accuracy: 0.5000\n",
      "Epoch 19/50\n",
      "112/112 [==============================] - 0s 219us/sample - loss: 1.2822 - accuracy: 0.4375 - val_loss: 1.2054 - val_accuracy: 0.5000\n",
      "Epoch 20/50\n",
      "112/112 [==============================] - 0s 212us/sample - loss: 1.2775 - accuracy: 0.4375 - val_loss: 1.2007 - val_accuracy: 0.5000\n",
      "Epoch 21/50\n",
      "112/112 [==============================] - 0s 231us/sample - loss: 1.2730 - accuracy: 0.4375 - val_loss: 1.1961 - val_accuracy: 0.5000\n",
      "Epoch 22/50\n",
      "112/112 [==============================] - 0s 241us/sample - loss: 1.2684 - accuracy: 0.4375 - val_loss: 1.1915 - val_accuracy: 0.5000\n",
      "Epoch 23/50\n",
      "112/112 [==============================] - 0s 209us/sample - loss: 1.2640 - accuracy: 0.4375 - val_loss: 1.1870 - val_accuracy: 0.5000\n",
      "Epoch 24/50\n",
      "112/112 [==============================] - 0s 229us/sample - loss: 1.2596 - accuracy: 0.4375 - val_loss: 1.1826 - val_accuracy: 0.5000\n",
      "Epoch 25/50\n",
      "112/112 [==============================] - 0s 257us/sample - loss: 1.2552 - accuracy: 0.4375 - val_loss: 1.1782 - val_accuracy: 0.5000\n",
      "Epoch 26/50\n",
      "112/112 [==============================] - 0s 222us/sample - loss: 1.2509 - accuracy: 0.4375 - val_loss: 1.1739 - val_accuracy: 0.5000\n",
      "Epoch 27/50\n",
      "112/112 [==============================] - 0s 227us/sample - loss: 1.2467 - accuracy: 0.4375 - val_loss: 1.1697 - val_accuracy: 0.5000\n",
      "Epoch 28/50\n",
      "112/112 [==============================] - 0s 219us/sample - loss: 1.2425 - accuracy: 0.4375 - val_loss: 1.1655 - val_accuracy: 0.5000\n",
      "Epoch 29/50\n",
      "112/112 [==============================] - 0s 222us/sample - loss: 1.2384 - accuracy: 0.4375 - val_loss: 1.1614 - val_accuracy: 0.5000\n",
      "Epoch 30/50\n",
      "112/112 [==============================] - 0s 210us/sample - loss: 1.2343 - accuracy: 0.4375 - val_loss: 1.1573 - val_accuracy: 0.5000\n",
      "Epoch 31/50\n",
      "112/112 [==============================] - 0s 203us/sample - loss: 1.2303 - accuracy: 0.4375 - val_loss: 1.1533 - val_accuracy: 0.5000\n",
      "Epoch 32/50\n",
      "112/112 [==============================] - 0s 216us/sample - loss: 1.2264 - accuracy: 0.4375 - val_loss: 1.1494 - val_accuracy: 0.5000\n",
      "Epoch 33/50\n",
      "112/112 [==============================] - 0s 218us/sample - loss: 1.2225 - accuracy: 0.4375 - val_loss: 1.1455 - val_accuracy: 0.5000\n",
      "Epoch 34/50\n",
      "112/112 [==============================] - 0s 224us/sample - loss: 1.2186 - accuracy: 0.4375 - val_loss: 1.1417 - val_accuracy: 0.5000\n",
      "Epoch 35/50\n",
      "112/112 [==============================] - 0s 213us/sample - loss: 1.2148 - accuracy: 0.4375 - val_loss: 1.1379 - val_accuracy: 0.5000\n",
      "Epoch 36/50\n",
      "112/112 [==============================] - 0s 229us/sample - loss: 1.2110 - accuracy: 0.4375 - val_loss: 1.1342 - val_accuracy: 0.5263\n",
      "Epoch 37/50\n",
      "112/112 [==============================] - 0s 242us/sample - loss: 1.2073 - accuracy: 0.4464 - val_loss: 1.1305 - val_accuracy: 0.5263\n",
      "Epoch 38/50\n",
      "112/112 [==============================] - 0s 221us/sample - loss: 1.2037 - accuracy: 0.4464 - val_loss: 1.1269 - val_accuracy: 0.5263\n",
      "Epoch 39/50\n",
      "112/112 [==============================] - 0s 226us/sample - loss: 1.2001 - accuracy: 0.4464 - val_loss: 1.1233 - val_accuracy: 0.5263\n",
      "Epoch 40/50\n",
      "112/112 [==============================] - 0s 236us/sample - loss: 1.1965 - accuracy: 0.4464 - val_loss: 1.1197 - val_accuracy: 0.5263\n",
      "Epoch 41/50\n",
      "112/112 [==============================] - 0s 238us/sample - loss: 1.1930 - accuracy: 0.4464 - val_loss: 1.1162 - val_accuracy: 0.5263\n",
      "Epoch 42/50\n",
      "112/112 [==============================] - 0s 223us/sample - loss: 1.1895 - accuracy: 0.4554 - val_loss: 1.1128 - val_accuracy: 0.5263\n",
      "Epoch 43/50\n",
      "112/112 [==============================] - 0s 235us/sample - loss: 1.1861 - accuracy: 0.4554 - val_loss: 1.1094 - val_accuracy: 0.5263\n",
      "Epoch 44/50\n",
      "112/112 [==============================] - 0s 239us/sample - loss: 1.1827 - accuracy: 0.4554 - val_loss: 1.1060 - val_accuracy: 0.5263\n",
      "Epoch 45/50\n",
      "112/112 [==============================] - 0s 237us/sample - loss: 1.1793 - accuracy: 0.4554 - val_loss: 1.1026 - val_accuracy: 0.5263\n",
      "Epoch 46/50\n",
      "112/112 [==============================] - 0s 211us/sample - loss: 1.1760 - accuracy: 0.4554 - val_loss: 1.0993 - val_accuracy: 0.5263\n",
      "Epoch 47/50\n",
      "112/112 [==============================] - 0s 229us/sample - loss: 1.1727 - accuracy: 0.4554 - val_loss: 1.0961 - val_accuracy: 0.5263\n",
      "Epoch 48/50\n",
      "112/112 [==============================] - 0s 239us/sample - loss: 1.1695 - accuracy: 0.4554 - val_loss: 1.0928 - val_accuracy: 0.5263\n",
      "Epoch 49/50\n",
      "112/112 [==============================] - 0s 230us/sample - loss: 1.1663 - accuracy: 0.4554 - val_loss: 1.0896 - val_accuracy: 0.5263\n",
      "Epoch 50/50\n",
      "112/112 [==============================] - 0s 213us/sample - loss: 1.1631 - accuracy: 0.4554 - val_loss: 1.0865 - val_accuracy: 0.5263\n",
      "\n",
      "Best score (highest validation accuracy) found via grid search: accuracy=0.947368 from model iteration #3\n",
      "The best modeling parameters are: optimizer=<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7fe1d6395990>, kernel=<tensorflow.python.ops.init_ops_v2.Orthogonal object at 0x7fe1b03bd4d0>, epochs=50, batch_size=32\n",
      "Total time for performing grid-search of the best parameters: 0:01:22.575904\n"
     ]
    }
   ],
   "source": [
    "startTimeModule = datetime.now()\n",
    "\n",
    "# Set up grid search using different epochs, batch sizes, and optimizers\n",
    "optz_1 = tf.optimizers.Adam(learning_rate=0.0010)\n",
    "optz_2 = tf.optimizers.Adam(learning_rate=0.0005)\n",
    "optz_3 = tf.optimizers.Adam(learning_rate=0.0001)\n",
    "optimizer_grid = [optz_1, optz_2, optz_3]\n",
    "print('Optimizer candidate #1 has the object ID of', optz_1)\n",
    "print('Optimizer candidate #2 has the object ID of', optz_2)\n",
    "print('Optimizer candidate #3 has the object ID of', optz_3)\n",
    "\n",
    "init_1 = tf.initializers.RandomNormal(seed=seedNum)\n",
    "init_2 = tf.initializers.Orthogonal(seed=seedNum)\n",
    "init_3 = tf.initializers.GlorotNormal(seed=seedNum)\n",
    "init_grid = [init_1, init_2, init_3]\n",
    "print('Initializer candidate #1 has the object ID of', init_1)\n",
    "print('Initializer candidate #2 has the object ID of', init_2)\n",
    "print('Initializer candidate #2 has the object ID of', init_3)\n",
    "\n",
    "epoch_grid = [default_epoch]\n",
    "batch_grid = [default_batch, int(default_batch*2), int(default_batch*4)]\n",
    "\n",
    "best_score = 0\n",
    "grid_iteration = 0\n",
    "best_iteration = 0\n",
    "best_optimizer = default_optimizer\n",
    "best_kernel_init = default_kernel_init\n",
    "best_epoch = default_epoch\n",
    "best_batch = default_batch\n",
    "\n",
    "for optimizer in optimizer_grid:\n",
    "    for kernel_init in init_grid:\n",
    "        for epoch_num in epoch_grid:\n",
    "            for batch_num in batch_grid:\n",
    "                print('\\nForming the grid-search model #%d using: optimizer=%s, kernel=%s, epochs=%d, batch_size=%d'\n",
    "                      % (grid_iteration, optimizer, kernel_init, epoch_num, batch_num))\n",
    "                reset_random(seedNum)\n",
    "                grid_model = create_customized_model(optimizer, kernel_init)\n",
    "                grid_hist = grid_model.fit(X_train, y_train, epochs=epoch_num, batch_size=batch_num, \n",
    "                                       validation_data=(X_test, y_test), verbose=1)\n",
    "                if(grid_hist.history['val_accuracy'][-1] > best_score):\n",
    "                    best_score = grid_hist.history['val_accuracy'][-1]\n",
    "                    best_iteration = grid_iteration\n",
    "                    best_optimizer = optimizer\n",
    "                    best_kernel_init = kernel_init\n",
    "                    best_epoch = epoch_num\n",
    "                    best_batch = batch_num\n",
    "                grid_iteration = grid_iteration + 1\n",
    "\n",
    "# summarize results\n",
    "print(\"\\nBest score (highest validation accuracy) found via grid search: accuracy=%f from model iteration #%d\"\n",
    "      % (best_score, best_iteration))\n",
    "print('The best modeling parameters are: optimizer=%s, kernel=%s, epochs=%d, batch_size=%d'\n",
    "      % (best_optimizer, best_kernel_init, best_epoch, best_batch))\n",
    "print('Total time for performing grid-search of the best parameters:', (datetime.now() - startTimeModule))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forming the final model using: optimizer=<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7fe1d6395990>, kernel=<tensorflow.python.ops.init_ops_v2.Orthogonal object at 0x7fe1b03bd4d0>, epochs=50, batch_size=32\n",
      "Train on 112 samples, validate on 38 samples\n",
      "Epoch 1/50\n",
      "112/112 [==============================] - 1s 9ms/sample - loss: 1.2201 - accuracy: 0.3036 - val_loss: 1.1365 - val_accuracy: 0.4211\n",
      "Epoch 2/50\n",
      "112/112 [==============================] - 0s 342us/sample - loss: 1.1352 - accuracy: 0.3929 - val_loss: 1.0377 - val_accuracy: 0.4474\n",
      "Epoch 3/50\n",
      "112/112 [==============================] - 0s 348us/sample - loss: 1.0447 - accuracy: 0.4196 - val_loss: 0.9447 - val_accuracy: 0.6316\n",
      "Epoch 4/50\n",
      "112/112 [==============================] - 0s 351us/sample - loss: 0.9671 - accuracy: 0.5804 - val_loss: 0.8597 - val_accuracy: 0.8158\n",
      "Epoch 5/50\n",
      "112/112 [==============================] - 0s 345us/sample - loss: 0.8901 - accuracy: 0.6964 - val_loss: 0.7865 - val_accuracy: 0.9211\n",
      "Epoch 6/50\n",
      "112/112 [==============================] - 0s 359us/sample - loss: 0.8284 - accuracy: 0.7321 - val_loss: 0.7220 - val_accuracy: 0.9211\n",
      "Epoch 7/50\n",
      "112/112 [==============================] - 0s 341us/sample - loss: 0.7742 - accuracy: 0.7679 - val_loss: 0.6656 - val_accuracy: 0.9211\n",
      "Epoch 8/50\n",
      "112/112 [==============================] - 0s 370us/sample - loss: 0.7273 - accuracy: 0.7679 - val_loss: 0.6169 - val_accuracy: 0.8947\n",
      "Epoch 9/50\n",
      "112/112 [==============================] - 0s 344us/sample - loss: 0.6834 - accuracy: 0.7768 - val_loss: 0.5754 - val_accuracy: 0.8947\n",
      "Epoch 10/50\n",
      "112/112 [==============================] - 0s 358us/sample - loss: 0.6460 - accuracy: 0.7768 - val_loss: 0.5394 - val_accuracy: 0.8947\n",
      "Epoch 11/50\n",
      "112/112 [==============================] - 0s 355us/sample - loss: 0.6131 - accuracy: 0.7857 - val_loss: 0.5082 - val_accuracy: 0.9211\n",
      "Epoch 12/50\n",
      "112/112 [==============================] - 0s 343us/sample - loss: 0.5837 - accuracy: 0.7946 - val_loss: 0.4809 - val_accuracy: 0.9211\n",
      "Epoch 13/50\n",
      "112/112 [==============================] - 0s 342us/sample - loss: 0.5577 - accuracy: 0.7946 - val_loss: 0.4573 - val_accuracy: 0.9211\n",
      "Epoch 14/50\n",
      "112/112 [==============================] - 0s 349us/sample - loss: 0.5351 - accuracy: 0.8036 - val_loss: 0.4360 - val_accuracy: 0.9211\n",
      "Epoch 15/50\n",
      "112/112 [==============================] - 0s 346us/sample - loss: 0.5144 - accuracy: 0.8036 - val_loss: 0.4177 - val_accuracy: 0.9211\n",
      "Epoch 16/50\n",
      "112/112 [==============================] - 0s 341us/sample - loss: 0.4963 - accuracy: 0.8214 - val_loss: 0.4003 - val_accuracy: 0.9211\n",
      "Epoch 17/50\n",
      "112/112 [==============================] - 0s 334us/sample - loss: 0.4799 - accuracy: 0.8214 - val_loss: 0.3851 - val_accuracy: 0.9211\n",
      "Epoch 18/50\n",
      "112/112 [==============================] - 0s 343us/sample - loss: 0.4646 - accuracy: 0.8214 - val_loss: 0.3716 - val_accuracy: 0.9211\n",
      "Epoch 19/50\n",
      "112/112 [==============================] - 0s 339us/sample - loss: 0.4518 - accuracy: 0.8125 - val_loss: 0.3596 - val_accuracy: 0.9211\n",
      "Epoch 20/50\n",
      "112/112 [==============================] - 0s 356us/sample - loss: 0.4393 - accuracy: 0.8214 - val_loss: 0.3483 - val_accuracy: 0.9211\n",
      "Epoch 21/50\n",
      "112/112 [==============================] - 0s 360us/sample - loss: 0.4280 - accuracy: 0.8214 - val_loss: 0.3387 - val_accuracy: 0.9211\n",
      "Epoch 22/50\n",
      "112/112 [==============================] - 0s 333us/sample - loss: 0.4177 - accuracy: 0.8214 - val_loss: 0.3294 - val_accuracy: 0.9211\n",
      "Epoch 23/50\n",
      "112/112 [==============================] - 0s 360us/sample - loss: 0.4080 - accuracy: 0.8304 - val_loss: 0.3211 - val_accuracy: 0.9211\n",
      "Epoch 24/50\n",
      "112/112 [==============================] - 0s 392us/sample - loss: 0.3989 - accuracy: 0.8393 - val_loss: 0.3134 - val_accuracy: 0.9211\n",
      "Epoch 25/50\n",
      "112/112 [==============================] - 0s 338us/sample - loss: 0.3905 - accuracy: 0.8393 - val_loss: 0.3064 - val_accuracy: 0.9211\n",
      "Epoch 26/50\n",
      "112/112 [==============================] - 0s 331us/sample - loss: 0.3825 - accuracy: 0.8393 - val_loss: 0.2996 - val_accuracy: 0.9211\n",
      "Epoch 27/50\n",
      "112/112 [==============================] - 0s 404us/sample - loss: 0.3753 - accuracy: 0.8393 - val_loss: 0.2938 - val_accuracy: 0.9211\n",
      "Epoch 28/50\n",
      "112/112 [==============================] - 0s 353us/sample - loss: 0.3681 - accuracy: 0.8393 - val_loss: 0.2881 - val_accuracy: 0.9474\n",
      "Epoch 29/50\n",
      "112/112 [==============================] - 0s 350us/sample - loss: 0.3614 - accuracy: 0.8482 - val_loss: 0.2830 - val_accuracy: 0.9474\n",
      "Epoch 30/50\n",
      "112/112 [==============================] - 0s 388us/sample - loss: 0.3553 - accuracy: 0.8482 - val_loss: 0.2782 - val_accuracy: 0.9474\n",
      "Epoch 31/50\n",
      "112/112 [==============================] - 0s 347us/sample - loss: 0.3491 - accuracy: 0.8482 - val_loss: 0.2740 - val_accuracy: 0.9474\n",
      "Epoch 32/50\n",
      "112/112 [==============================] - 0s 336us/sample - loss: 0.3432 - accuracy: 0.8482 - val_loss: 0.2703 - val_accuracy: 0.9737\n",
      "Epoch 33/50\n",
      "112/112 [==============================] - 0s 345us/sample - loss: 0.3372 - accuracy: 0.8571 - val_loss: 0.2666 - val_accuracy: 0.9737\n",
      "Epoch 34/50\n",
      "112/112 [==============================] - 0s 353us/sample - loss: 0.3316 - accuracy: 0.8571 - val_loss: 0.2626 - val_accuracy: 0.9737\n",
      "Epoch 35/50\n",
      "112/112 [==============================] - 0s 337us/sample - loss: 0.3263 - accuracy: 0.8661 - val_loss: 0.2592 - val_accuracy: 0.9737\n",
      "Epoch 36/50\n",
      "112/112 [==============================] - 0s 348us/sample - loss: 0.3205 - accuracy: 0.8750 - val_loss: 0.2560 - val_accuracy: 0.9737\n",
      "Epoch 37/50\n",
      "112/112 [==============================] - 0s 349us/sample - loss: 0.3154 - accuracy: 0.8839 - val_loss: 0.2528 - val_accuracy: 0.9737\n",
      "Epoch 38/50\n",
      "112/112 [==============================] - 0s 357us/sample - loss: 0.3103 - accuracy: 0.9018 - val_loss: 0.2496 - val_accuracy: 0.9737\n",
      "Epoch 39/50\n",
      "112/112 [==============================] - 0s 332us/sample - loss: 0.3057 - accuracy: 0.9018 - val_loss: 0.2467 - val_accuracy: 0.9737\n",
      "Epoch 40/50\n",
      "112/112 [==============================] - 0s 363us/sample - loss: 0.3008 - accuracy: 0.9018 - val_loss: 0.2436 - val_accuracy: 0.9737\n",
      "Epoch 41/50\n",
      "112/112 [==============================] - 0s 341us/sample - loss: 0.2964 - accuracy: 0.9018 - val_loss: 0.2408 - val_accuracy: 0.9737\n",
      "Epoch 42/50\n",
      "112/112 [==============================] - 0s 348us/sample - loss: 0.2918 - accuracy: 0.9107 - val_loss: 0.2381 - val_accuracy: 0.9737\n",
      "Epoch 43/50\n",
      "112/112 [==============================] - 0s 341us/sample - loss: 0.2873 - accuracy: 0.9107 - val_loss: 0.2353 - val_accuracy: 0.9737\n",
      "Epoch 44/50\n",
      "112/112 [==============================] - 0s 332us/sample - loss: 0.2830 - accuracy: 0.9107 - val_loss: 0.2329 - val_accuracy: 0.9737\n",
      "Epoch 45/50\n",
      "112/112 [==============================] - 0s 332us/sample - loss: 0.2791 - accuracy: 0.9107 - val_loss: 0.2303 - val_accuracy: 0.9737\n",
      "Epoch 46/50\n",
      "112/112 [==============================] - 0s 339us/sample - loss: 0.2748 - accuracy: 0.9107 - val_loss: 0.2278 - val_accuracy: 0.9737\n",
      "Epoch 47/50\n",
      "112/112 [==============================] - 0s 337us/sample - loss: 0.2708 - accuracy: 0.9107 - val_loss: 0.2252 - val_accuracy: 0.9737\n",
      "Epoch 48/50\n",
      "112/112 [==============================] - 0s 352us/sample - loss: 0.2671 - accuracy: 0.9107 - val_loss: 0.2232 - val_accuracy: 0.9737\n",
      "Epoch 49/50\n",
      "112/112 [==============================] - 0s 339us/sample - loss: 0.2635 - accuracy: 0.9107 - val_loss: 0.2213 - val_accuracy: 0.9737\n",
      "Epoch 50/50\n",
      "112/112 [==============================] - 0s 344us/sample - loss: 0.2599 - accuracy: 0.9196 - val_loss: 0.2197 - val_accuracy: 0.9737\n"
     ]
    }
   ],
   "source": [
    "# Create the final model for evaluating the test dataset\n",
    "print('Forming the final model using: optimizer=%s, kernel=%s, epochs=%d, batch_size=%d'\n",
    "      % (best_optimizer, best_kernel_init, best_epoch, best_batch))\n",
    "reset_random(seedNum)\n",
    "final_model = create_customized_model(best_optimizer, best_kernel_init)\n",
    "final_hist = final_model.fit(X_train, y_train, epochs=best_epoch, batch_size=best_batch, validation_data=(X_test, y_test), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_34\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_68 (Dense)             (None, 10)                50        \n",
      "_________________________________________________________________\n",
      "dense_69 (Dense)             (None, 3)                 33        \n",
      "=================================================================\n",
      "Total params: 83\n",
      "Trainable params: 83\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Display a summary of the final model\n",
    "print(final_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'sequential_34', 'layers': [{'class_name': 'Dense', 'config': {'name': 'dense_68', 'trainable': True, 'batch_input_shape': (None, 4), 'dtype': 'float32', 'units': 10, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Orthogonal', 'config': {'gain': 1.0, 'seed': 888}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_69', 'trainable': True, 'dtype': 'float32', 'units': 3, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Orthogonal', 'config': {'gain': 1.0, 'seed': 888}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}]}\n"
     ]
    }
   ],
   "source": [
    "# Display the configuration of the final model\n",
    "print(final_model.get_config())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])\n"
     ]
    }
   ],
   "source": [
    "# List all data points in model training history\n",
    "print(final_hist.history.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x864 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Summarize model training hisotry for accuracy and loss\n",
    "fig, axs = plt.subplots(2, 1, figsize=(12,12))\n",
    "plt.subplot(211)\n",
    "plt.plot(final_hist.history['accuracy'], color='blue', label='train')\n",
    "plt.plot(final_hist.history['val_accuracy'], color='red', label='test')\n",
    "plt.title('Final Model Training Performance (Accuracy)')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper right')\n",
    "plt.subplot(212)\n",
    "plt.plot(final_hist.history['loss'], color='blue', label='train')\n",
    "plt.plot(final_hist.history['val_loss'], color='red', label='test')\n",
    "plt.title('Final Model Training Performance (Loss)')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38/1 [====================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 206us/sample - loss: 0.1963 - accuracy: 0.9737\n",
      "\n",
      "accuracy: 97.368419%\n",
      "\n",
      "loss: 0.219723\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the Keras model on previously unseen data\n",
    "scores = final_model.evaluate(X_test, y_test)\n",
    "print(\"\\n%s: %f%%\" % (final_model.metrics_names[1], scores[1]*100))\n",
    "print(\"\\n%s: %f\" % (final_model.metrics_names[0], scores[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (notifyStatus): email_notify(\"Phase 4 Optimize Model completed! \"+datetime.now().strftime('%a %B %d, %Y %I:%M:%S %p'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 5. Finalize Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (notifyStatus): email_notify(\"Phase 5 Finalize Model has begun! \"+datetime.now().strftime('%a %B %d, %Y %I:%M:%S %p'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data item #0 predicted to be ['Iris-setosa'] (expected ['Iris-setosa'])\n",
      "Data item #1 predicted to be ['Iris-setosa'] (expected ['Iris-setosa'])\n",
      "Data item #2 predicted to be ['Iris-setosa'] (expected ['Iris-setosa'])\n",
      "Data item #3 predicted to be ['Iris-versicolor'] (expected ['Iris-versicolor'])\n",
      "Data item #4 predicted to be ['Iris-virginica'] (expected ['Iris-virginica'])\n",
      "Data item #5 predicted to be ['Iris-virginica'] (expected ['Iris-virginica'])\n",
      "Data item #6 predicted to be ['Iris-setosa'] (expected ['Iris-setosa'])\n",
      "Data item #7 predicted to be ['Iris-setosa'] (expected ['Iris-setosa'])\n",
      "Data item #8 predicted to be ['Iris-versicolor'] (expected ['Iris-versicolor'])\n",
      "Data item #9 predicted to be ['Iris-setosa'] (expected ['Iris-setosa'])\n",
      "Data item #10 predicted to be ['Iris-versicolor'] (expected ['Iris-versicolor'])\n",
      "Data item #11 predicted to be ['Iris-versicolor'] (expected ['Iris-versicolor'])\n",
      "Data item #12 predicted to be ['Iris-virginica'] (expected ['Iris-versicolor'])\n",
      "Data item #13 predicted to be ['Iris-setosa'] (expected ['Iris-setosa'])\n",
      "Data item #14 predicted to be ['Iris-virginica'] (expected ['Iris-virginica'])\n",
      "Data item #15 predicted to be ['Iris-virginica'] (expected ['Iris-virginica'])\n",
      "Data item #16 predicted to be ['Iris-setosa'] (expected ['Iris-setosa'])\n",
      "Data item #17 predicted to be ['Iris-versicolor'] (expected ['Iris-versicolor'])\n",
      "Data item #18 predicted to be ['Iris-virginica'] (expected ['Iris-virginica'])\n",
      "Data item #19 predicted to be ['Iris-setosa'] (expected ['Iris-setosa'])\n"
     ]
    }
   ],
   "source": [
    "# Make class predictions with the model\n",
    "predictions = final_model.predict_classes(X_test)\n",
    "\n",
    "# Summarize the first 20 cases\n",
    "for i in range(20):\n",
    "\tprint('Data item #%d predicted to be %s (expected %s)' % (i, encoder.inverse_transform([predictions[i]]), encoder.inverse_transform([np.argmax(y_test[i])])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (notifyStatus): email_notify(\"Phase 5 Finalize Model completed! \"+datetime.now().strftime('%a %B %d, %Y %I:%M:%S %p'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time for the script: 0:02:42.531265\n"
     ]
    }
   ],
   "source": [
    "print ('Total time for the script:',(datetime.now() - startTimeScript))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
